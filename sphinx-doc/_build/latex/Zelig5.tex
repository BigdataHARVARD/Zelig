% Generated by Sphinx.
\def\sphinxdocclass{report}
\documentclass[letterpaper,10pt,english]{sphinxmanual}
\usepackage[utf8]{inputenc}
\DeclareUnicodeCharacter{00A0}{\nobreakspace}
\usepackage{cmap}
\usepackage[T1]{fontenc}
\usepackage{babel}
\usepackage{times}
\usepackage[Bjarne]{fncychap}
\usepackage{longtable}
\usepackage{sphinx}
\usepackage{multirow}


\title{Zelig5 Documentation}
\date{July 20, 2014}
\release{5.0}
\author{The Zelig Team}
\newcommand{\sphinxlogo}{}
\renewcommand{\releasename}{Release}
\makeindex

\makeatletter
\def\PYG@reset{\let\PYG@it=\relax \let\PYG@bf=\relax%
    \let\PYG@ul=\relax \let\PYG@tc=\relax%
    \let\PYG@bc=\relax \let\PYG@ff=\relax}
\def\PYG@tok#1{\csname PYG@tok@#1\endcsname}
\def\PYG@toks#1+{\ifx\relax#1\empty\else%
    \PYG@tok{#1}\expandafter\PYG@toks\fi}
\def\PYG@do#1{\PYG@bc{\PYG@tc{\PYG@ul{%
    \PYG@it{\PYG@bf{\PYG@ff{#1}}}}}}}
\def\PYG#1#2{\PYG@reset\PYG@toks#1+\relax+\PYG@do{#2}}

\expandafter\def\csname PYG@tok@gd\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.63,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gu\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.50,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@gt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.27,0.87}{##1}}}
\expandafter\def\csname PYG@tok@gs\endcsname{\let\PYG@bf=\textbf}
\expandafter\def\csname PYG@tok@gr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{1.00,0.00,0.00}{##1}}}
\expandafter\def\csname PYG@tok@cm\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@vg\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@m\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@cs\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\colorbox[rgb]{1.00,0.94,0.94}{\strut ##1}}}
\expandafter\def\csname PYG@tok@ge\endcsname{\let\PYG@it=\textit}
\expandafter\def\csname PYG@tok@vc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@il\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@go\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.20,0.20,0.20}{##1}}}
\expandafter\def\csname PYG@tok@cp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@gi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.63,0.00}{##1}}}
\expandafter\def\csname PYG@tok@gh\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.00,0.50}{##1}}}
\expandafter\def\csname PYG@tok@ni\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.84,0.33,0.22}{##1}}}
\expandafter\def\csname PYG@tok@nl\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.13,0.44}{##1}}}
\expandafter\def\csname PYG@tok@nn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@no\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.38,0.68,0.84}{##1}}}
\expandafter\def\csname PYG@tok@na\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@nb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.05,0.52,0.71}{##1}}}
\expandafter\def\csname PYG@tok@nd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.33,0.33,0.33}{##1}}}
\expandafter\def\csname PYG@tok@ne\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@nf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.49}{##1}}}
\expandafter\def\csname PYG@tok@si\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.44,0.63,0.82}{##1}}}
\expandafter\def\csname PYG@tok@s2\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@vi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@nt\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.02,0.16,0.45}{##1}}}
\expandafter\def\csname PYG@tok@nv\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.38,0.84}{##1}}}
\expandafter\def\csname PYG@tok@s1\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@gp\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@sh\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@ow\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@sx\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.78,0.36,0.04}{##1}}}
\expandafter\def\csname PYG@tok@bp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c1\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@kc\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@c\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.50,0.56}{##1}}}
\expandafter\def\csname PYG@tok@mf\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@err\endcsname{\def\PYG@bc##1{\setlength{\fboxsep}{0pt}\fcolorbox[rgb]{1.00,0.00,0.00}{1,1,1}{\strut ##1}}}
\expandafter\def\csname PYG@tok@kd\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@ss\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.32,0.47,0.09}{##1}}}
\expandafter\def\csname PYG@tok@sr\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.14,0.33,0.53}{##1}}}
\expandafter\def\csname PYG@tok@mo\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@mi\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.13,0.50,0.31}{##1}}}
\expandafter\def\csname PYG@tok@kn\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@o\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.40,0.40,0.40}{##1}}}
\expandafter\def\csname PYG@tok@kr\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@s\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@kp\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@w\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.73,0.73,0.73}{##1}}}
\expandafter\def\csname PYG@tok@kt\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.56,0.13,0.00}{##1}}}
\expandafter\def\csname PYG@tok@sc\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sb\endcsname{\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@k\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.00,0.44,0.13}{##1}}}
\expandafter\def\csname PYG@tok@se\endcsname{\let\PYG@bf=\textbf\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}
\expandafter\def\csname PYG@tok@sd\endcsname{\let\PYG@it=\textit\def\PYG@tc##1{\textcolor[rgb]{0.25,0.44,0.63}{##1}}}

\def\PYGZbs{\char`\\}
\def\PYGZus{\char`\_}
\def\PYGZob{\char`\{}
\def\PYGZcb{\char`\}}
\def\PYGZca{\char`\^}
\def\PYGZam{\char`\&}
\def\PYGZlt{\char`\<}
\def\PYGZgt{\char`\>}
\def\PYGZsh{\char`\#}
\def\PYGZpc{\char`\%}
\def\PYGZdl{\char`\$}
\def\PYGZhy{\char`\-}
\def\PYGZsq{\char`\'}
\def\PYGZdq{\char`\"}
\def\PYGZti{\char`\~}
% for compatibility with earlier versions
\def\PYGZat{@}
\def\PYGZlb{[}
\def\PYGZrb{]}
\makeatother

\begin{document}

\maketitle
\tableofcontents
\phantomsection\label{index::doc}

\phantomsection\label{index:about}
Zelig is a single, easy-to-use program that can estimate, help interpret, and present the results of a large range of statistical methods. It literally is ``everyone's statistical software'' because Zelig uses (R) code from many researchers. We also hope it will become ``everyone's statistical software'' for applications, and we have designed it so that anyone can use it or add their methods to it. Zelig comes with detailed, self-contained documentation that minimizes startup costs for Zelig and R (with all methods described in exactly the same notation, syntax, and style), automates graphics and summaries for all models, and, with only three simple required commands, makes the power of R accessible for all users. Zelig also works well for teaching, and is designed so that scholars can use the same program with students that they use for their research.

For more information about the goals and direction of the project, please
see the {\hyperref[index:technicalvision]{\emph{Technical Vision}}}.

To get started quickly, follow the {\hyperref[docs/quickstart:quickstart]{\emph{Quickstart}}}.

Visit the source repository: \href{https://github.com/IQSS/Zelig5}{https://github.com/IQSS/Zelig5}

Be sure to follow us on Twitter \href{https://twitter.com/IQSS}{@IQSS}!


\chapter{Contents}
\label{index:welcome-to-zelig}\label{index:contents}

\section{Quickstart}
\label{docs/quickstart::doc}\label{docs/quickstart:quickstart}\label{docs/quickstart:id1}

\subsection{TODO}
\label{docs/quickstart:todo}
Lorem ipsum dolor sit amet, consectetur adipisicing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. Duis aute irure dolor in reprehenderit in voluptate velit esse cillum dolore eu fugiat nulla pariatur. Excepteur sint occaecat cupidatat non proident, sunt in culpa qui officia deserunt mollit anim id est laborum.


\section{Installation}
\label{docs/installation:installation}\label{docs/installation::doc}\label{docs/installation:id1}
Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?


\section{User Guide}
\label{docs/user_guide:user-guide}\label{docs/user_guide:userguide}\label{docs/user_guide::doc}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\begin{itemize}
\item {} 
{\hyperref[docs/user_guide:introduction]{Introduction}}
\begin{itemize}
\item {} 
{\hyperref[docs/user_guide:what-r-and-zelig-do]{What R and Zelig do}}

\item {} 
{\hyperref[docs/user_guide:getting-help]{Getting Help}}

\item {} 
{\hyperref[docs/user_guide:how-to-cite-zelig]{How to Cite Zelig}}

\end{itemize}

\item {} 
{\hyperref[docs/user_guide:data-analysis-commands]{Data Analysis Commands}}
\begin{itemize}
\item {} 
{\hyperref[docs/user_guide:command-syntax]{Command Syntax}}

\item {} 
{\hyperref[docs/user_guide:variables]{Variables}}

\end{itemize}

\item {} 
{\hyperref[docs/user_guide:statistical-commands]{Statistical Commands}}
\begin{itemize}
\item {} 
{\hyperref[docs/user_guide:zelig-commands]{Zelig Commands}}

\item {} 
{\hyperref[docs/user_guide:describe-a-models-systematic-and-stochastic-parameters]{Describe a model’s systematic and stochastic parameters}}

\item {} 
{\hyperref[docs/user_guide:supported-models]{Supported Models}}

\item {} 
{\hyperref[docs/user_guide:replication-procedures]{Replication Procedures}}

\end{itemize}

\item {} 
{\hyperref[docs/user_guide:graphing-commands]{Graphing Commands}}
\begin{itemize}
\item {} 
{\hyperref[docs/user_guide:drawing-plots]{Drawing Plots}}

\item {} 
{\hyperref[docs/user_guide:adding-points-lines-and-legends-to-existing-plots]{Adding Points, Lines, and Legends to Existing Plots}}

\item {} 
{\hyperref[docs/user_guide:saving-graphs-to-files]{Saving Graphs to Files}}

\item {} 
{\hyperref[docs/user_guide:id17]{Examples}}

\end{itemize}

\item {} 
{\hyperref[docs/user_guide:r-objects]{R Objects}}
\begin{itemize}
\item {} 
{\hyperref[docs/user_guide:scalar-values]{Scalar Values}}

\item {} 
{\hyperref[docs/user_guide:id18]{Data Structures}}

\end{itemize}

\item {} 
{\hyperref[docs/user_guide:programming-statements]{Programming Statements}}
\begin{itemize}
\item {} 
{\hyperref[docs/user_guide:functions]{Functions}}

\item {} 
{\hyperref[docs/user_guide:if-statements]{If-Statements}}

\item {} 
{\hyperref[docs/user_guide:for-loops]{For-Loops}}

\end{itemize}

\end{itemize}
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\subsection{Introduction}
\label{docs/user_guide:introduction}\label{docs/user_guide:userguide-introduction}

\subsubsection{What R and Zelig do}
\label{docs/user_guide:what-r-and-zelig-do}
Zelig {\color{red}\bfseries{}{[}1{]}\_} is an easy-to-use program that can estimate and help
interpret the results of an enormous and growing range of statistical
models. It literally \emph{is} “everyone’s statistical software” because
Zelig’s unified framework incorporates everyone else’s (R) code. We also
hope it will \emph{become} “everyone’s statistical software” for
applications, and we have designed Zelig so that anyone can use it or
add their models to it.

When you are using Zelig, you are also using , a powerful statistical
software language. You do not need to learn R separately, however, since
this manual introduces you to R through Zelig, which simplifies R and
reduces the amount of programming knowledge you need to get started.
Because so many individuals contribute different packages to R (each
with their own syntax and documentation), estimating a statistical model
can be a frustrating experience. Users need to know which package
contains the model, find the modeling command within the package, and
refer to the manual page for the model-specific arguments. In contrast,
Zelig users can skip these start-up costs and move directly to data
analyses. Using Zelig’s unified command syntax, you gain the convenience
of a packaged program, without losing any of the power of R’s underlying
statistical procedures.

In addition to generalizing R packages and making existing methods
easier to use, Zelig includes infrastructure that can improve all
existing methods and R programs. Even if you know R, using Zelig greatly
simplifies your work. It mimics the popular program for Stata (and thus
the suggestions of ) by translating the raw output of existing
statistical procedures into quantities that are of direct interest to
researchers. Instead of trying to interpret coefficients parameterized
for modeling convenience, Zelig makes it easy to compute quantities of
real interest: probabilities, predicted values, expected values, first
differences, and risk ratios, along with confidence intervals, standard
errors, or full posterior (or sampling) densities for all quantities.
Zelig extends Clarify by seamlessly integrating an option for
bootstrapping into the simulation of quantities of interest. It also
integrates a full suite of nonparametric matching methods as a
preprocessing step to improve the performance of any parametric model
for causal inference (see ). For missing data, Zelig accepts multiply
imputed datasets created by (see ) and other programs, allowing users to
analyze them as if they were a single, fully observed dataset. Zelig
outputs replication data sets so that you (and if you wish, anyone else)
will always be able to replicate the results of your analyses (see ).
Several powerful Zelig commands also make running multiple analyses and
recoding variables simple.

Using R in combination with Zelig has several advantages over commercial
statistical software. R and Zelig are part of the open source movement,
which is roughly based on the principles of science. That is, anyone who
adds functionality to open source software or wishes to redistribute it
(legally) must provide the software accompanied by its source free of
charge. {\color{red}\bfseries{}{[}2{]}\_} If you find a bug in open source software and post a note
to the appropriate mailing list, a solution you can use will likely be
posted quickly by one of the thousands of people using the program all
over the world. Since you can see the source code, you might even be
able to fix it yourself. In contrast, if something goes wrong with
commercial software, you have to wait for the programmers at the company
to fix it (and speaking with them is probably out of the question), and
wait for a new version to be released.

We find that Zelig makes students and colleagues more amenable to using
R, since the startup costs are lower, and since the manual and software
are relatively self-contained. This manual even includes an appendix
devoted to the basics of advanced R programming, although you will not
need it to run most procedures in Zelig. A large and growing fraction of
the world’s quantitative methodologists and statisticians are moving to
R, and the base of programs available for R is quickly surpassing all
alternatives. In addition to built-in functions, R is a complete
programming language, which allows you to design new functions to suit
your needs. R has the dual advantage that you do not need to understand
how to program to use it, but if it turns out that you want to do
something more complicated, you do not need to learn another program. In
addition, methodologists all over the world add new functions all the
time, so if the function you need wasn’t there yesterday, it may be
available today.


\subsubsection{Getting Help}
\label{docs/user_guide:getting-help}
You may find documentation for Zelig on-line (and hence must be on-line
to access it). If you are unable to connect to the Internet, we
recommend that you print the pdf version of this document for your
reference.

If you are on-line, you may access comprehensive help files for Zelig
commands and for each of the models. For example, load the Zelig library
and then type at the R prompt:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZgt{} help.zelig(command)                \PYGZsh{} For help with all zelig commands.
\PYGZgt{} help.zelig(logit)                  \PYGZsh{} For help with the logit model.
\end{Verbatim}

{[}Rhelp{]}In addition, help.zelig() searches the manual pages for R in
addition to the Zelig specific pages. On certain rare occasions, the
name of the help topic in Zelig and in R are identical. In these cases,
help.zelig() will return the Zelig help page by default. If you wish to
access the R help page, you should use help(topic).

In addition, built-in examples with sample data and plots are available
for each model. For example, type demo(logit) to view the demo for the
logit model. Commented code for each model is available under the
examples section of each model reference page.

Please direct inquiries and problems about Zelig to our listserv at . We
suggest you subscribe to this mailing list while learning and using
Zelig: go to . (You can choose to receive email in digest form, so that
you will never receive more than one message per day.) You can also
browse or search our of previous messages before posting your query.


\subsubsection{How to Cite Zelig}
\label{docs/user_guide:how-to-cite-zelig}
To cite Zelig as a whole, please reference these two sources:
\begin{quote}

Kosuke Imai, Gary King, and Olivia Lau. 2007. “Zelig: Everyone’s
Statistical Software,” \href{http://GKing.harvard.edu/zelig}{http://GKing.harvard.edu/zelig}.

Imai, Kosuke, Gary King, and Olivia Lau. (2008). “Toward A Common
Framework for Statistical Analysis and Development.” Journal of
Computational and Graphical Statistics, Vol. 17, No. 4 (December),
pp. 892-913.
\end{quote}

To refer to a particular Zelig model, please refer to the “how to cite”
portion at the end of each model documentation section.


\subsection{Data Analysis Commands}
\label{docs/user_guide:userguide-data-analysis}\label{docs/user_guide:data-analysis-commands}

\subsubsection{Command Syntax}
\label{docs/user_guide:command-syntax}\begin{quote}

Once R is installed, you only need to know a few basic elements to get
started. It’s important to remember that R, like any spoken language,
has rules for proper syntax. Unlike English, however, the rules for
intelligible R are small in number and quite precise (see ).
\begin{enumerate}
\item {} 
To start R under Linux or Unix, type R at the terminal prompt or M-x
R under ESS.

\item {} 
The R prompt is \textgreater{}.

\item {} 
Type commands and hit enter to execute. (No additional characters,
such as semicolons or commas, are necessary at the end of lines.)

\item {} 
To quit from R, type \code{q()} and press enter.

\item {} 
The \# character makes R ignore the rest of the line, and is used in
this document to comment R code.

\item {} 
We highly recommend that you make a separate working directory or
folder for each project.

\item {} 
Each R session has a workspace, or working memory, to store the
\emph{objects} that you create or input. These objects may be:
\begin{enumerate}
\item {} 
\emph{values}, which include numerical, integer, character, and logical
values;

\item {} 
\emph{data structures} made up of variables (vectors), matrices, and
data frames; or

\item {} 
\emph{functions} that perform the desired tasks on user-specified
values or data structures.

\end{enumerate}

\end{enumerate}

After starting R, you may at any time use Zelig’s built-in help function
to access on-line help for any command. To see help for all Zelig
commands, type help.zelig(command), which will take you to the help page
for all Zelig commands. For help with a specific Zelig or R command
substitute the name of the command for the generic command. For example,
type help.zelig(logit) to view help for the logit model.
\end{quote}

.
\begin{quote}

Zelig uses the syntax of R, which has several essential elements:
\begin{enumerate}
\item {} 
R is case sensitive. \code{Zelig}, the package or library, is not the
same as \code{zelig}, the command.

\item {} 
R functions accept user-defined arguments: while some arguments are
required, other optional arguments modify the function’s default
behavior. Enclose arguments in parentheses and separate multiple
arguments with commas. For example, print(x) or print(x, digits = 2)
prints the contents of the object x using the default number of
digits or rounds to two digits to the right of the decimal point,
respectively. You may nest commands as long as each has its own set
of parentheses: \code{log(sqrt(5))} takes the square root of 5 and then
takes the natural log.

\item {} 
The \textless{}- operator takes the output of the function on the right and
saves them in the named object on the left. For example, z.out \textless{}-
zelig(…) stores the output from zelig() as the object z.out in your
working memory. You may use z.out as an argument in other functions,
view the output by typing z.out at the R prompt, or save z.out to a
file using the procedures described in .

\item {} 
You may name your objects anything, within a few constraints:
\begin{itemize}
\item {} 
You may only use letters (in upper or lower case) and periods to
punctuate your variable names.

\item {} 
You may \emph{not} use any special characters (aside from the period)
or spaces to punctuate your variable names.

\item {} 
Names cannot begin with numbers. For example, R will not let you
save an object as \code{1997.election} but will let you save
\code{election.1997}.

\end{itemize}

\item {} 
Use the names() command to see the contents of R objects, and the \$
operator to extract elements from R objects. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Run least squares regression and save the output in working memory:}
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}y \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{,} data \PYG{o}{=} mydata\PYG{p}{)}
\PYG{c+c1}{\PYGZsh{} See what\PYGZsq{}s in the R object:}
\PYG{o}{\PYGZgt{}} names\PYG{p}{(}z.out\PYG{p}{)}
 \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{coefficients\PYGZdq{}}  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{residuals\PYGZdq{}}  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{effects\PYGZdq{}}  \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{rank\PYGZdq{}}
\PYG{c+c1}{\PYGZsh{} Extract and display the coefficients in z.out:}
\PYG{o}{\PYGZgt{}} z.out\PYG{o}{\PYGZdl{}}coefficients
\end{Verbatim}

\item {} 
All objects have a class designation which tells R how to treat it in
subsequent commands. An object’s class is generated by the function
or mathematical operation that created it.

\item {} 
To see a list of all objects in your current workspace, type:
\code{ls()}. You can remove an object permanently from memory by typing
\code{remove(goo)} (which deletes the object goo), or remove all the
objects with remove(list = ls()).

\item {} 
To run commands in a batch, use a text editor (such as the Windows R
script editor or emacs) to compose your R commands, and save the file
with a .R file extension in your working directory. To run the file,
type \code{source(Code.R)} at the R prompt.

\end{enumerate}

If you encounter a syntax error, check your spelling, case, parentheses,
and commas. These are the most common syntax errors, and are easy to
detect and correct with a little practice. If you encounter a syntax
error in batch mode, R will tell you the line on which the syntax error
occurred.
\end{quote}


\paragraph{Data Structures}
\label{docs/user_guide:data-structures}
Zelig uses only three of R’s many data structures:
\begin{enumerate}
\item {} 
A \textbf{variable} is a one-dimensional vector of length .

\item {} 
A \textbf{data frame} is a rectangular matrix with  rows and
 columns. Each column represents a variable and each row an
observation. Each variable may have a different class. (See for a
list of classes.) You may refer to specific variables from a data
frame using, for example, data\$variable.

\item {} 
A \textbf{list} is a combination of different data structures. For
example, z.out contains both coefficients (a vector) and data (a data
frame). Use names() to view the elements available within a list, and
the \$ operator to refer to an element in a list.

\end{enumerate}

For a more comprehensive introduction, including ways to manipulate
these data structures, please refer to Chapter {[}a:R{]}.


\paragraph{Loading Data}
\label{docs/user_guide:loading-data}
Datasets in Zelig are stored in “data frames.” In this section, we
explain the standard ways to load data from disk into memory, how to
handle special cases, and how to verify that the data you loaded is what
you think it is.


\subparagraph{Standard Ways to Load Data}
\label{docs/user_guide:standard-ways-to-load-data}
Make sure that the data file is saved in your working directory. You can
check to see what your working directory is by starting R, and typing
getwd(). If you wish to use a different directory as your starting
directory, use \code{setwd("dirpath")}, where \code{"dirpath"} is the full
directory path of the directory you would like to use as your working
directory.

After setting your working directory, load data using one of the
following methods:
\begin{enumerate}
\item {} 
If your dataset is in a \textbf{tab- or space-delimited .txt file}, use
\code{read.table(mydata.txt)}

\item {} 
If your dataset is \textbf{a comma separated table}, use
\code{read.csv(mydata.csv)}.

\item {} 
To import \textbf{SPSS, Stata, and other data files}, use the foreign
package, which automatically preserves field characteristics for each
variable. Thus, variables classed as dates in Stata are automatically
translated into values in the date class for R. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} library\PYG{p}{(}foreign\PYG{p}{)}                           \PYG{c+c1}{\PYGZsh{} Load the foreign package.}
\PYG{o}{\PYGZgt{}} stata.data \PYG{o}{\PYGZlt{}\PYGZhy{}} read.dta\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.dta\PYGZdq{}}\PYG{p}{)}       \PYG{c+c1}{\PYGZsh{} For Stata data.}
\PYG{o}{\PYGZgt{}} spss.data \PYG{o}{\PYGZlt{}\PYGZhy{}} read.spss\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.sav\PYGZdq{}}\PYG{p}{,} to.data.frame \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} For SPSS.}
\end{Verbatim}

\item {} 
To load data in R format, use load(“mydata.RData”).

\item {} 
For sample data sets included with R packages such as Zelig, you may
use the data() command, which is a shortcut for loading data from the
sample data directories. Because the locations of these directories
vary by installation, it is extremely difficult to locate sample data
sets and use one of the three preceding methods; data() searches all
of the currently used packages and loads sample data automatically.
For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} library\PYG{p}{(}Zelig\PYG{p}{)}                              \PYG{c+c1}{\PYGZsh{} Loads the Zelig library.}
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}turnout\PYG{p}{)}                               \PYG{c+c1}{\PYGZsh{} Loads the turnout data.}
\end{Verbatim}

\end{enumerate}


\subparagraph{Special Cases When Loading Data}
\label{docs/user_guide:special-cases-when-loading-data}
These procedures apply to any of the above read commands:
\begin{enumerate}
\item {} 
If your file uses the \textbf{first row to identify variable names}, you
should use the option \code{header = TRUE} to import those field names.
For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} read.csv\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.csv\PYGZdq{}}\PYG{p}{,} header \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
\end{Verbatim}

will read the words in the first row as the variable names and the
subsequent rows (each with the same number of values as the first) as
observations for each of those variables. If you have additional
characters on the last line of the file or fewer values in one of the
rows, you need to edit the file before attempting to read the data.

\item {} 
The R missing value code is \code{NA}. If this value is in your data, R
will recognize your missing values as such. If you have instead used
a place-holder value (such as -9) to represent missing data, you need
to tell R this on loading the data:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} read.table\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.tab\PYGZdq{}}\PYG{p}{,} header \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,} na.strings \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{\PYGZhy{}9\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

Note: You must enclose your place holder values in quotes.

\item {} 
Unlike Windows, the file extension in R does not determine the
default method for dealing with the file. For example, if your data
is tab-delimited, but saved as a .sav file,
\code{read.table(mydata.sav)} will load your data into R.

\end{enumerate}


\subparagraph{Verifying You Loaded The Data Correctly}
\label{docs/user_guide:verifying-you-loaded-the-data-correctly}
Whichever method you use, try the \code{names()}, \code{dim()}, and
\code{summary()} commands to verify that the data was properly loaded. For
example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data \PYG{o}{\PYGZlt{}\PYGZhy{}} read.csv\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.csv\PYGZdq{}}\PYG{p}{,} header \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}             \PYG{c+c1}{\PYGZsh{} Read the data.}
\PYG{o}{\PYGZgt{}} dim\PYG{p}{(}data\PYG{p}{)}                    \PYG{c+c1}{\PYGZsh{} Displays the dimensions of the data frame}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+m}{16000}  \PYG{l+m}{8}                   \PYG{c+c1}{\PYGZsh{}  in rows then columns.}
\PYG{o}{\PYGZgt{}} data\PYG{p}{[}\PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{10}\PYG{p}{,}\PYG{p}{]}                  \PYG{c+c1}{\PYGZsh{} Display rows 1\PYGZhy{}10 and all columns.}
\PYG{o}{\PYGZgt{}} names\PYG{p}{(}data\PYG{p}{)}                  \PYG{c+c1}{\PYGZsh{} Check the variable names.}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{V1\PYGZdq{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{V2\PYGZdq{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{V3\PYGZdq{}}             \PYG{c+c1}{\PYGZsh{} These values indicate that the variables}
                               \PYG{c+c1}{\PYGZsh{}  weren\PYGZsq{}t named, and took default values.}
\PYG{o}{\PYGZgt{}} names\PYG{p}{(}data\PYG{p}{)} \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{income\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{educate\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{year\PYGZdq{}}\PYG{p}{)}     \PYG{c+c1}{\PYGZsh{} Assign variable names.}
\PYG{o}{\PYGZgt{}} summary\PYG{p}{(}data\PYG{p}{)}                \PYG{c+c1}{\PYGZsh{} Returning a summary for each variable.}
\end{Verbatim}

In this case, the summary() command will return the maximum, minimum,
mean, median, first and third quartiles, as well as the number of
missing values for each variable.


\paragraph{Saving Data}
\label{docs/user_guide:saving-data}
Use \code{save()} to write data or any object to a file in your working
directory. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} save\PYG{p}{(}mydata\PYG{p}{,} file \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.RData\PYGZdq{}}\PYG{p}{)}     \PYG{c+c1}{\PYGZsh{} Saves {}`mydata\PYGZsq{} to {}`mydata.RData\PYGZsq{}}
                                          \PYG{c+c1}{\PYGZsh{}  in your working directory.}
\PYG{o}{\PYGZgt{}} save.image\PYG{p}{(}\PYG{p}{)}                            \PYG{c+c1}{\PYGZsh{} Saves your entire workspace to}
                                          \PYG{c+c1}{\PYGZsh{}  the default {}`.RData\PYGZsq{} file.}
\end{Verbatim}

R will also prompt you to save your workspace when you use the \code{q()}
command to quit. When you start R again, it will load the previously
saved workspace. Restarting R will not, however, load previously used
packages. You must remember to load Zelig at the beginning of every R
session.

Alternatively, you can recall individually saved objects from .RData
files using the load() command. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} load\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.RData\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

loads the objects saved in the mydata.RData file. You may save a data
frame, a data frame and associated functions, or other R objects to
file.


\subsubsection{Variables}
\label{docs/user_guide:variables}

\paragraph{Classes of Variables}
\label{docs/user_guide:classes-of-variables}
R variables come in several types. Certain Zelig models require
dependent variables of a certain class of variable. (These are
documented under the manual pages for each model.) Use class(variable)
to determine the class of a variable or class(data\$variable) for a
variable within a data frame.


\subparagraph{Types of Variables}
\label{docs/user_guide:types-of-variables}
For all types of variable (vectors), you may use the c() command to
“concatenate” elements into a vector, the : operator to generate a
sequence of integer values, the seq() command to generate a sequence of
non-integer values, or the rep() function to repeat a value to a
specified length. In addition, you may use the \textless{}- operator to save
variables (or any other objects) to the workspace. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} logic \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{k+kc}{TRUE}\PYG{p}{,} \PYG{k+kc}{FALSE}\PYG{p}{,} \PYG{k+kc}{TRUE}\PYG{p}{,} \PYG{k+kc}{TRUE}\PYG{p}{,} \PYG{k+kc}{TRUE}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Creates {}`logic\PYGZsq{} (5 T/F values).}
\PYG{o}{\PYGZgt{}} var1 \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{10}\PYG{o}{:}\PYG{l+m}{20}                             \PYG{c+c1}{\PYGZsh{} All integers between 10 and 20.}
\PYG{o}{\PYGZgt{}} var2 \PYG{o}{\PYGZlt{}\PYGZhy{}} seq\PYG{p}{(}from \PYG{o}{=} \PYG{l+m}{5}\PYG{p}{,} to \PYG{o}{=} \PYG{l+m}{10}\PYG{p}{,} by \PYG{o}{=} \PYG{l+m}{0.5}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Sequence from 5 to 10 by}
                                            \PYG{c+c1}{\PYGZsh{}  intervals of 0.5.}
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} rep\PYG{p}{(}\PYG{k+kc}{NA}\PYG{p}{,} length \PYG{o}{=} \PYG{l+m}{20}\PYG{p}{)}              \PYG{c+c1}{\PYGZsh{} 20 {}`NA\PYGZsq{} values.}
\PYG{o}{\PYGZgt{}} var4 \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}rep\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{15}\PYG{p}{)}\PYG{p}{,} rep\PYG{p}{(}\PYG{l+m}{0}\PYG{p}{,} \PYG{l+m}{15}\PYG{p}{)}\PYG{p}{)}         \PYG{c+c1}{\PYGZsh{} 15 {}`1\PYGZsq{}s followed by 15 {}`0\PYGZsq{}s.}
\end{Verbatim}

For the seq() command, you may alternatively specify length instead of
by to create a variable with a specific number (denoted by the length
argument) of evenly spaced elements.
\begin{enumerate}
\item {} 
\textbf{Numeric} variables are real numbers and the default variable class
for most dataset values. You can perform any type of math or logical
operation on numeric values. If var1 and var2 are numeric variables,
we can compute

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} log\PYG{p}{(}var2\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{l+m}{2}\PYG{o}{*}var1      \PYG{c+c1}{\PYGZsh{} Create {}`var3\PYGZsq{} using math operations.}
\end{Verbatim}

\code{Inf} (infinity), \code{-Inf} (negative infinity), \code{NA} (missing
value), and \code{NaN} (not a number) are special numeric values on
which most math operations will fail. (Logical operations will work,
however.) Use as.numeric() to transform variables into numeric
variables. Integers are a special class of numeric variable.

\item {} 
\textbf{Logical} variables contain values of either \code{TRUE} or \code{FALSE}.
R supports the following logical operators: ==, exactly equals; \textgreater{},
greater than; \textless{}, less than; \textgreater{}=, greater than or equals; \textless{}=, less than
or equals; and !=, not equals. The = symbol is \emph{not} a logical
operator. Refer to for more detail on logical operators. If var1 and
var2 both have  observations, commands such as

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} var1 \PYG{o}{\PYGZlt{}} var2
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} var1 \PYG{o}{==} var2
\end{Verbatim}

create  TRUE/FALSE observations such that the th
observation in var3 evaluates whether the logical statement is true
for the th value of var1 with respect to the th
value of var2. Logical variables should usually be converted to
integer values prior to analysis; use the as.integer() command.

\item {} 
\textbf{Character} variables are sets of text strings. Note that text
strings are always enclosed in quotes to denote that the string is a
value, not an object in the workspace or an argument for a function
(neither of which take quotes). Variables of class character are not
normally used in data analysis, but used as descriptive fields. If a
character variable is used in a statistical operation, it must first
be transformed into a factored variable.

\item {} 
\textbf{Factor} variables may contain values consisting of either integers
or character strings. Use factor() or as.factor() to convert
character or integer variables into factor variables. Factor
variables separate unique values into levels. These levels may either
be ordered or unordered. In practice, this means that including a
factor variable among the explanatory variables is equivalent to
creating dummy variables for each level. In addition, some models
(ordinal logit, ordinal probit, and multinomial logit), require that
the dependent variable be a factor variable.

\end{enumerate}


\paragraph{Recoding Variables}
\label{docs/user_guide:recoding-variables}
Researchers spend a significant amount of time cleaning and recoding
data prior to beginning their analyses. R has several procedures to
facilitate the process.


\subparagraph{Extracting, Replacing, and Generating New Variables}
\label{docs/user_guide:extracting-replacing-and-generating-new-variables}
While it is not difficult to recode variables, the process is prone to
human error. Thus, we recommend that before altering the data, you save
your existing data frame using the procedures described in , that you
only recode one variable at a time, and that you recode the variable
outside the data frame and then return it to the data frame.

To extract the variable you wish to recode, type:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} var \PYG{o}{\PYGZlt{}\PYGZhy{}} data\PYG{o}{\PYGZdl{}}var1               \PYG{c+c1}{\PYGZsh{} Copies {}`var1\PYGZsq{} from {}`data\PYGZsq{}, creating {}`var\PYGZsq{}.}
\end{Verbatim}

Do \emph{not} sort the extracted variable or delete observations from it. If
you do, the th observation in var will no longer match the
th observation in data.

To replace the variable or generate a new variable in the data frame,
type: {[}insert{]}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data\PYG{o}{\PYGZdl{}}var1 \PYG{o}{\PYGZlt{}\PYGZhy{}} var                \PYG{c+c1}{\PYGZsh{} Replace {}`var1\PYGZsq{} in {}`data\PYGZsq{} with {}`var\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} data\PYG{o}{\PYGZdl{}}new.var \PYG{o}{\PYGZlt{}\PYGZhy{}} var             \PYG{c+c1}{\PYGZsh{} Generate {}`new.var\PYGZsq{} in {}`data\PYGZsq{} using {}`var\PYGZsq{}.}
\end{Verbatim}

To remove a variable from a data frame (rather than replacing one
variable with another):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data\PYG{o}{\PYGZdl{}}var1 \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NULL}
\end{Verbatim}


\subparagraph{Logical Operators}
\label{docs/user_guide:logical-operators}
R has an intuitive method for recoding variables, which relies on
logical operators that return statements of TRUE and FALSE. A
mathematical operator (such as ==, !=, \textgreater{}, \textgreater{}= \textless{}, and \textless{}=) takes two
objects of equal dimensions (scalars, vectors of the same length,
matrices with the same number of rows and columns, or similarly
dimensioned arrays) and compares every element in the first object to
its counterpart in the second object.
\begin{itemize}
\item {} 
==: checks that one variable “exactly equals” another in a list-wise
manner. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{4}\PYG{p}{,} \PYG{l+m}{5}\PYG{p}{)}                \PYG{c+c1}{\PYGZsh{} Creates the object {}`x\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} y \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{5}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{)}                \PYG{c+c1}{\PYGZsh{} Creates the object {}`y\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} x \PYG{o}{==} y                               \PYG{c+c1}{\PYGZsh{} Only the 3rd {}`x\PYGZsq{} exactly equals}
  \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE}    \PYG{c+c1}{\PYGZsh{}  its counterpart in {}`y\PYGZsq{}.}
\end{Verbatim}

(The = symbol is \emph{not} a logical operator.)

\item {} 
!=: checks that one variable does not equal the other in a list-wise
manner. Continuing the example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{!=} y
  \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}  \PYG{k+kc}{TRUE}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE}  \PYG{k+kc}{TRUE}
\end{Verbatim}

\item {} 
\textgreater{} (\textgreater{}=): checks whether each element in the left-hand object is
greater than (or equal to) every element in the right-hand object.
Continuing the example from above:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZgt{}} y                                   \PYG{c+c1}{\PYGZsh{} Only the 5th {}`x\PYGZsq{} is greater}
  \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE}       \PYG{c+c1}{\PYGZsh{}  than its counterpart in {}`y\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZgt{}=} y                                  \PYG{c+c1}{\PYGZsh{} The 3rd {}`x\PYGZsq{} is equal to the}
  \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE}       \PYG{c+c1}{\PYGZsh{}  3rd {}`y\PYGZsq{} and becomes TRUE.}
\end{Verbatim}

\item {} 
\textless{} (\textless{}=): checks whether each element in the left-hand object is less
than (or equal to) every object in the right-hand object. Continuing
the example from above:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}} y                           \PYG{c+c1}{\PYGZsh{} The elements 1, 2, and 4 of {}`x\PYGZsq{} are}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}  \PYG{k+kc}{TRUE}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE} \PYG{c+c1}{\PYGZsh{}  less than their counterparts in {}`y\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}=} y                          \PYG{c+c1}{\PYGZsh{} The 3rd {}`x\PYGZsq{} is equal to the 3rd {}`y\PYGZsq{}}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}  \PYG{k+kc}{TRUE}  \PYG{k+kc}{TRUE}  \PYG{k+kc}{TRUE}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE} \PYG{c+c1}{\PYGZsh{}  and becomes TRUE.}
\end{Verbatim}

\end{itemize}

For two vectors of five elements, the mathematical operators compare the
first element in x to the first element in y, the second to the second
and so forth. Thus, a mathematical comparison of x and y returns a
vector of five TRUE/FALSE statements. Similarly, for two matrices with 3
rows and 20 columns each, the mathematical operators will return a
 matrix of logical values.

There are additional logical operators which allow you to combine and
compare logical statements:
\begin{itemize}
\item {} 
\&: is the logical equivalent of “and”, and evaluates one array of
logical statements against another in a list-wise manner, returning a
TRUE only if both are true in the same location. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} a \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}c\PYG{p}{(}\PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{12}\PYG{p}{)}\PYG{p}{,} nrow \PYG{o}{=} \PYG{l+m}{3}\PYG{p}{,} ncol \PYG{o}{=} \PYG{l+m}{4}\PYG{p}{)}      \PYG{c+c1}{\PYGZsh{} Creates a matrix {}`a\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} a
     \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{4}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{1}    \PYG{l+m}{4}    \PYG{l+m}{7}   \PYG{l+m}{10}
\PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{2}    \PYG{l+m}{5}    \PYG{l+m}{8}   \PYG{l+m}{11}
\PYG{p}{[}\PYG{l+m}{3}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{3}    \PYG{l+m}{6}    \PYG{l+m}{9}   \PYG{l+m}{12}
\PYG{o}{\PYGZgt{}} b \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}c\PYG{p}{(}\PYG{l+m}{12}\PYG{o}{:}\PYG{l+m}{1}\PYG{p}{)}\PYG{p}{,} nrow \PYG{o}{=} \PYG{l+m}{3}\PYG{p}{,} ncol \PYG{o}{=} \PYG{l+m}{4}\PYG{p}{)}      \PYG{c+c1}{\PYGZsh{} Creates a matrix {}`b\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} b
     \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{4}\PYG{p}{]}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]}   \PYG{l+m}{12}    \PYG{l+m}{9}    \PYG{l+m}{6}    \PYG{l+m}{3}
\PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]}   \PYG{l+m}{11}    \PYG{l+m}{8}    \PYG{l+m}{5}    \PYG{l+m}{2}
\PYG{p}{[}\PYG{l+m}{3}\PYG{p}{,}\PYG{p}{]}   \PYG{l+m}{10}    \PYG{l+m}{7}    \PYG{l+m}{4}    \PYG{l+m}{1}
\PYG{o}{\PYGZgt{}} v1 \PYG{o}{\PYGZlt{}\PYGZhy{}} a \PYG{o}{\PYGZgt{}} \PYG{l+m}{3}                    \PYG{c+c1}{\PYGZsh{} Creates the matrix {}`v1\PYGZsq{} (T/F values).}
\PYG{o}{\PYGZgt{}} v2 \PYG{o}{\PYGZlt{}\PYGZhy{}} b \PYG{o}{\PYGZgt{}} \PYG{l+m}{3}                    \PYG{c+c1}{\PYGZsh{} Creates the matrix {}`v2\PYGZsq{} (T/F values).}
\PYG{o}{\PYGZgt{}} v1 \PYG{o}{\PYGZam{}} v2                        \PYG{c+c1}{\PYGZsh{} Checks if the (i,j) value in {}`v1\PYGZsq{} and}
      \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]}  \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{4}\PYG{p}{]}       \PYG{c+c1}{\PYGZsh{}  {}`v2\PYGZsq{} are both TRUE.  Because columns}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]} \PYG{k+kc}{FALSE} \PYG{k+kc}{TRUE} \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE}       \PYG{c+c1}{\PYGZsh{}  2\PYGZhy{}4 of {}`v1\PYGZsq{} are TRUE, and columns 1\PYGZhy{}3}
\PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]} \PYG{k+kc}{FALSE} \PYG{k+kc}{TRUE} \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE}       \PYG{c+c1}{\PYGZsh{}  of {}`var2\PYGZsq{} are TRUE, columns 2\PYGZhy{}3 are}
\PYG{p}{[}\PYG{l+m}{3}\PYG{p}{,}\PYG{p}{]} \PYG{k+kc}{FALSE} \PYG{k+kc}{TRUE} \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE}       \PYG{c+c1}{\PYGZsh{}  TRUE here.}
\PYG{o}{\PYGZgt{}} \PYG{p}{(}a \PYG{o}{\PYGZgt{}} \PYG{l+m}{3}\PYG{p}{)} \PYG{o}{\PYGZam{}} \PYG{p}{(}b \PYG{o}{\PYGZgt{}} \PYG{l+m}{3}\PYG{p}{)}              \PYG{c+c1}{\PYGZsh{} The same, in one step.}
\end{Verbatim}

For more complex comparisons, parentheses may be necessary to delimit
logical statements.

\item {} 
\textbar{}: is the logical equivalent of “or”, and evaluates in a list-wise
manner whether either of the values are TRUE. Continuing the example
from above:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} \PYG{p}{(}a \PYG{o}{\PYGZlt{}} \PYG{l+m}{3}\PYG{p}{)} \PYG{o}{\textbar{}} \PYG{p}{(}b \PYG{o}{\PYGZlt{}} \PYG{l+m}{3}\PYG{p}{)}                \PYG{c+c1}{\PYGZsh{} (1,1) and (2,1) in {}`a\PYGZsq{} are less}
      \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]}  \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]}  \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]}  \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{4}\PYG{p}{]}       \PYG{c+c1}{\PYGZsh{}  than 3, and (2,4) and (3,4) in}
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE}       \PYG{c+c1}{\PYGZsh{}  {}`b\PYGZsq{} are less than 3; \textbar{} returns}
\PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]}  \PYG{k+kc}{TRUE} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE}       \PYG{c+c1}{\PYGZsh{}  a matrix with {}`TRUE\PYGZsq{} in (1,1),}
\PYG{p}{[}\PYG{l+m}{3}\PYG{p}{,}\PYG{p}{]} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE} \PYG{k+kc}{FALSE}  \PYG{k+kc}{TRUE}       \PYG{c+c1}{\PYGZsh{}  (2,1), (2,4), and (3,4).}
\end{Verbatim}

\end{itemize}

The \&\& (if and only if) and \textbar{}\textbar{} (either or) operators are used to
control the command flow within functions. The \&\& operator returns a
TRUE only if every element in the comparison statement is true; the \textbar{}\textbar{}
operator returns a TRUE if any of the elements are true. Unlike the \&
and \textbar{} operators, which return arrays of logical values, the \&\& and \textbar{}\textbar{}
operators return only one logical statement irrespective of the
dimensions of the objects under consideration. Hence, \&\& and \textbar{}\textbar{} are
logical operators which are \emph{not} appropriate for recoding variables.


\subparagraph{Coding and Recoding Variables}
\label{docs/user_guide:coding-and-recoding-variables}
R uses vectors of logical statements to indicate how a variable should
be coded or recoded. For example, to create a new variable var3 equal to
1 if var1  var2 and 0 otherwise:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} var1 \PYG{o}{\PYGZlt{}} var2               \PYG{c+c1}{\PYGZsh{} Creates a vector of n T/F observations.}
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} as.integer\PYG{p}{(}var3\PYG{p}{)}          \PYG{c+c1}{\PYGZsh{} Replaces the T/F values in {}`var3\PYGZsq{} with}
                                    \PYG{c+c1}{\PYGZsh{}  1\PYGZsq{}s for TRUE and 0\PYGZsq{}s for FALSE.}
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} as.integer\PYG{p}{(}var1 \PYG{o}{\PYGZlt{}} var2\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} Combine the two steps above into one.}
\end{Verbatim}

In addition to generating a vector of dummy variables, you can also
refer to specific values using logical operators defined in . For
example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} v1 \PYG{o}{\PYGZlt{}\PYGZhy{}} var1 \PYG{o}{==} \PYG{l+m}{5}                     \PYG{c+c1}{\PYGZsh{} Creates a vector of T/F statements.}
\PYG{o}{\PYGZgt{}} var1\PYG{p}{[}v1\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{4}                       \PYG{c+c1}{\PYGZsh{} For every TRUE in {}`v1\PYGZsq{}, replaces the}
                                      \PYG{c+c1}{\PYGZsh{}  value in {}`var1\PYGZsq{} with a 4.}
\PYG{o}{\PYGZgt{}} var1\PYG{p}{[}var1 \PYG{o}{==} \PYG{l+m}{5}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{4}                \PYG{c+c1}{\PYGZsh{} The same, in one step.}
\end{Verbatim}

The index (inside the square brackets) can be created with reference to
other variables. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} var1\PYG{p}{[}var2 \PYG{o}{==} var3\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{1}
\end{Verbatim}

replaces the th value in var1 with a 1 when the th
value in var2 equals the th value in var3. If you use = in
place of ==, however, you will replace all the values in var1 with 1’s
because = is another way to assign variables. Thus, the statement var2 =
var3 is of course true.

Finally, you may also replace any (character, numerical, or logical)
values with special values (most commonly, NA).

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} var1\PYG{p}{[}var1 \PYG{o}{==} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{don\PYGZsq{}t know\PYGZdq{}}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NA}   \PYG{c+c1}{\PYGZsh{} Replaces all \PYGZdq{}don\PYGZsq{}t know\PYGZdq{}\PYGZsq{}s with NA\PYGZsq{}s.}
\end{Verbatim}

After recoding the var1 replace the old data\$var1 with the recoded var1:
data\$var1 \textless{}- var1. You may combine the recoding and replacement
procedures into one step. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data\PYG{o}{\PYGZdl{}}var1\PYG{p}{[}data\PYG{o}{\PYGZdl{}}var1 \PYG{o}{=}\PYG{o}{\PYGZlt{}} \PYG{l+m}{0}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{\PYGZhy{}1}
\end{Verbatim}

Alternatively, rather than recoding just specific values in variables,
you may calculate new variables from existing variables. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} var1 \PYG{o}{+} \PYG{l+m}{2} \PYG{o}{*} var2
\PYG{o}{\PYGZgt{}} var3 \PYG{o}{\PYGZlt{}\PYGZhy{}} log\PYG{p}{(}var1\PYG{p}{)}
\end{Verbatim}

After generating the new variables, use the assignment mechanism \textless{}- to
insert the new variable into the data frame.

In addition to generating vectors of dummy variables, you may transform
a vector into a matrix of dummy indicator variables. For example, see to
transform a vector of  unique values (with 
observations in the complete vector) into a  matrix.


\subparagraph{Missing Data}
\label{docs/user_guide:missing-data}
To deal with missing values in some of your variables:
\begin{enumerate}
\item {} 
You may generate multiply imputed datasets using (or other programs).

\item {} 
You may omit missing values. Zelig models automatically apply
list-wise deletion, so no action is required to run a model. To
obtain the total number of observations or produce other summary
statistics using the analytic dataset, you may manually omit
incomplete observations. To do so, first create a data frame
containing only the variables in your analysis. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} new.data \PYG{o}{\PYGZlt{}\PYGZhy{}} cbind\PYG{p}{(}data\PYG{o}{\PYGZdl{}}dep.var\PYG{p}{,} data\PYG{o}{\PYGZdl{}}var1\PYG{p}{,} data\PYG{o}{\PYGZdl{}}var2\PYG{p}{,} data\PYG{o}{\PYGZdl{}}var3\PYG{p}{)}
\end{Verbatim}

The cbind() command “column binds” variables into a data frame. (A
similar command rbind() “row binds” observations with the same number
of variables into a data frame.) To omit missing values from this new
data frame:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} new.data \PYG{o}{\PYGZlt{}\PYGZhy{}} na.omit\PYG{p}{(}new.data\PYG{p}{)}
\end{Verbatim}

If you perform na.omit() on the full data frame, you risk deleting
observations that are fully observed in your experimental variables,
but missing values in other variables. Creating a new data frame
containing only your experimental variables usually increases the
number of observations retained after na.omit().

\end{enumerate}


\subsection{Statistical Commands}
\label{docs/user_guide:statistical-commands}\label{docs/user_guide:userguide-statistical-commands}

\subsubsection{Zelig Commands}
\label{docs/user_guide:zelig-commands}

\paragraph{Quick Overview}
\label{docs/user_guide:quick-overview}
For any statistical model, Zelig does its work with a combination of
three commands.
\begin{enumerate}
\item {} 
Use \code{zelig()} to run the chosen statistical model on a given data
set, with a specific set of variables. For standard likelihood
models, for example, this step estimates the coefficients, other
model parameters, and a variance-covariance matrix. In addition, you
may choose from a variety of options:
\begin{itemize}
\item {} 
Pre-process data: Prior to calling zelig(), you may choose from a
variety of data pre-processing commands (matching or multiple
imputation, for example) to make your statistical inferences more
accurate.

\item {} 
Summarize model: After calling zelig(), you may summarize the
fitted model output using summary().

\item {} 
Validate model: After calling zelig(), you may choose to validate
the fitted model. This can be done, for example, by using
cross-validation procedures and diagnostics tools.

\end{itemize}

\item {} 
Use \code{setx()} to set each of the explanatory variables to chosen
(actual or counterfactual) values in preparation for calculating
quantities of interest. After calling setx(), you may use to evaluate
these choices by determining whether they involve interpolation
(i.e., are inside the convex hull of the observed data) or
extrapolation, as well as how far these counterfactuals are from the
data. Counterfactuals chosen in \code{setx()} that involve extrapolation
far from the data can generate considerably more model dependence
(see , , ).

\item {} 
Use \code{sim()} to draw simulations of your quantity of interest (such
as a predicted value, predicted probability, risk ratio, or first
difference) from the model. (These simulations may be drawn using an
asymptotic normal approximation (the default), bootstrapping, or
other methods when available, such as directly from a Bayesian
posterior.) After calling sim(), use any of the following to
summarize the simulations:
\begin{itemize}
\item {} 
The summary() function gives a numerical display. For multiple
setx() values, summary() lets you summarize simulations by
choosing one or a subset of observations.

\item {} 
If the setx() values consist of only one observation, plot()
produces density plots for each quantity of interest.

\end{itemize}

\end{enumerate}

Whenever possible, we use z.out as the zelig() output object, \code{x.out}
as the \code{setx()} output object, and s.out as the sim() output object,
but you may choose other names.


\paragraph{Examples}
\label{docs/user_guide:examples}\begin{itemize}
\item {} 
Use the \code{turnout} data set included with Zelig to estimate a logit
model of an individual’s probability of voting as function of race
and age. Simulate the predicted probability of voting for a white
individual, with age held at its mean:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}vote \PYG{o}{\PYGZti{}} race \PYG{o}{+} age\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{logit\PYGZdq{}}\PYG{p}{,} data \PYG{o}{=} turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.out \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} race \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{white\PYGZdq{}}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} s.out \PYG{o}{\PYGZlt{}\PYGZhy{}} sim\PYG{p}{(}z.out\PYG{p}{,} x \PYG{o}{=} x.out\PYG{p}{)}
\PYG{o}{\PYGZgt{}} summary\PYG{p}{(}s.out\PYG{p}{)}
\end{Verbatim}

\item {} 
Compute a first difference and risk ratio, changing education from 12
to 16 years, with other variables held at their means in the data:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}vote \PYG{o}{\PYGZti{}} race \PYG{o}{+} educate\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{logit\PYGZdq{}}\PYG{p}{,} data \PYG{o}{=} turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.low \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} educate \PYG{o}{=} \PYG{l+m}{12}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.high \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} educate \PYG{o}{=} \PYG{l+m}{16}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} s.out \PYG{o}{\PYGZlt{}\PYGZhy{}} sim\PYG{p}{(}z.out\PYG{p}{,} x \PYG{o}{=} x.low\PYG{p}{,} x1 \PYG{o}{=} x.high\PYG{p}{)}
\PYG{o}{\PYGZgt{}} summary\PYG{p}{(}s.out\PYG{p}{)}                                     \PYG{c+c1}{\PYGZsh{} Numerical summary.}
\PYG{o}{\PYGZgt{}} plot\PYG{p}{(}s.out\PYG{p}{)}                                        \PYG{c+c1}{\PYGZsh{} Graphical summary.}
\end{Verbatim}

\item {} 
Calculate expected values for every observation in your data set:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}vote \PYG{o}{\PYGZti{}} race \PYG{o}{+} educate\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{logit\PYGZdq{}}\PYG{p}{,} data \PYG{o}{=} turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.out \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} fn \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} s.out \PYG{o}{\PYGZlt{}\PYGZhy{}} sim\PYG{p}{(}z.out\PYG{p}{,} x \PYG{o}{=} x.out\PYG{p}{)}
\PYG{o}{\PYGZgt{}} summary\PYG{p}{(}s.out\PYG{p}{)}
\end{Verbatim}

\item {} 
Use five multiply imputed data sets from in an ordered logit model:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}immi1\PYG{p}{,} immi2\PYG{p}{,} immi3\PYG{p}{,} immi4\PYG{p}{,} immi5\PYG{p}{)}
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}as.factor\PYG{p}{(}ipip\PYG{p}{)} \PYG{o}{\PYGZti{}} wage1992 \PYG{o}{+} prtyid \PYG{o}{+} ideol\PYG{p}{,}
                 model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ologit\PYGZdq{}}\PYG{p}{,}
                 data \PYG{o}{=} mi\PYG{p}{(}immi1\PYG{p}{,} immi2\PYG{p}{,} immi3\PYG{p}{,} immi4\PYG{p}{,} immi5\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

\item {} 
Use the nearest propensity score matching via \emph{MatchIt} package, and
then calculate the conditional average treatment effect of the job
training program based on the linear regression model:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} library\PYG{p}{(}MatchIt\PYG{p}{)}
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}lalonde\PYG{p}{)}
\PYG{o}{\PYGZgt{}} m.out \PYG{o}{\PYGZlt{}\PYGZhy{}} matchit\PYG{p}{(}treat \PYG{o}{\PYGZti{}} re74 \PYG{o}{+} re75 \PYG{o}{+} educ \PYG{o}{+} black \PYG{o}{+} hispan \PYG{o}{+} age\PYG{p}{,}
                   data \PYG{o}{=} lalonde\PYG{p}{,} method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{nearest\PYGZdq{}}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} m.data \PYG{o}{\PYGZlt{}\PYGZhy{}} match.data\PYG{p}{(}m.out\PYG{p}{)}
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}re78 \PYG{o}{\PYGZti{}} treat \PYG{o}{+} distance \PYG{o}{+} re74 \PYG{o}{+} re75 \PYG{o}{+} educ \PYG{o}{+} black \PYG{o}{+}
                 hispan \PYG{o}{+} age\PYG{p}{,} data \PYG{o}{=} m.data\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.out0 \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} fn \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{,} treat \PYG{o}{=} \PYG{l+m}{0}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.out1 \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} fn \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{,} treat \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} s.out \PYG{o}{\PYGZlt{}\PYGZhy{}} sim\PYG{p}{(}z.out\PYG{p}{,} x\PYG{o}{=}x.out0\PYG{p}{,} x1\PYG{o}{=}x.out1\PYG{p}{)}
\PYG{o}{\PYGZgt{}} summary\PYG{p}{(}s.out\PYG{p}{)}
\end{Verbatim}

\item {} 
Validate the fitted model using the leave-one-out cross validation
procedure and calculating the average squared prediction error via
\emph{boot} package. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} library\PYG{p}{(}boot\PYG{p}{)}
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}vote \PYG{o}{\PYGZti{}} race \PYG{o}{+} educate\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{logit\PYGZdq{}}\PYG{p}{,} data \PYG{o}{=} turnout\PYG{p}{,} cite\PYG{o}{=}\PYG{k+kVariable}{F}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} cv.out \PYG{o}{\PYGZlt{}\PYGZhy{}} cv.glm\PYG{p}{(}z.out\PYG{p}{,} data \PYG{o}{=} turnout\PYG{p}{,} k\PYG{o}{=}\PYG{l+m}{11}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} print\PYG{p}{(}cv.out\PYG{o}{\PYGZdl{}}delta\PYG{p}{)}
\end{Verbatim}

\end{itemize}


\paragraph{Details}
\label{docs/user_guide:details}\begin{enumerate}
\item {} 
z.out \textless{}- zelig(formula, model, data, by = NULL, …)

The zelig() command estimates a selected statistical model given the
specified data. You may name the output object (\code{z.out} above)
anything you desire. You must include three required arguments, in
the following order:
\begin{enumerate}
\item {} 
\code{formula} takes the form y \textasciitilde{} x1 + x2, where y is the dependent
variable and x1 and x2 are the explanatory variables, and y, x1,
and x2 are contained in the same dataset. The + symbol means
“inclusion” not “addition.” You may include interaction terms in
the form of x1*x2 without having to compute them in prior steps
or include the main effects separately. For example, R treats the
formula y \textasciitilde{} x1*x2 as y \textasciitilde{} x1 + x2 + x1*x2. To prevent R from
automatically including the separate main effect terms, use the
I() function, thus: y \textasciitilde{} I(x1 * x2).

\item {} 
\code{model} lets you choose which statistical model to run. You must
put the name of the model in quotation marks, in the form model =
“ls”, for example. See for a list of currently supported models.

\item {} 
\code{data} specifies the data frame containing the variables called
in the formula, in the form data = mydata. Alternatively, you may
input multiply imputed datasets in the form data = mi(data1,
data2, …). {\color{red}\bfseries{}{[}1{]}\_} If you are working with matched data created using
, you may create a data frame within the zelig() statement by
using data = match.data(…). In all cases, the data frame or
MatchIt object must have been previously loaded into the working
memory.

\item {} 
by (an optional argument which is by default NULL) allows you to
choose a factor variable (see ) in the data frame as a subsetting
variable. For each of the unique strata defined in the by
variable, zelig() does a separate run of the specified model. The
variable chosen should \emph{not} be in the formula, because there will
be no variance in the by variable in the subsets. If you have one
data set for all 191 countries in the UN, for example, you may use
the by option to run the same model 191 times, once on each
country, all with a single zelig() statement. You may also use the
by option to run models on subclasses.

\item {} 
The output object, z.out, contains all of the options chosen,
including the name of the data set. Because data sets may be
large, Zelig does not store the full data set, but only the name
of the dataset. Every time you use a Zelig function, it looks for
the dataset with the appropriate name in working memory. (Thus, it
is critical that you do \emph{not} change the name of your data set, or
perform any additional operations on your selected variables
between calling zelig() and setx(), or between setx() and sim().)

\item {} 
If you would like to view the regression output at this
intermediate step, type summary(z.out) to return the coefficients,
standard errors, -statistics and -values. We
recommend instead that you calculate quantities of interest;
creating z.out is only the first of three steps in this task.

\end{enumerate}

\item {} 
x.out \textless{}- setx(z.out, fn = list(numeric = mean, ordered = median,
others = mode), data = NULL, cond = FALSE, …)

The setx() command lets you choose values for the explanatory
variables, with which sim() will simulate quantities of interest.
There are two types of setx() procedures:
\begin{itemize}
\item {} 
You may perform the usual \emph{unconditional} prediction (by default,
cond = FALSE), by explicitly choosing the values of each
explanatory variable yourself or letting setx() compute them,
either from the data used to create z.out or from a new data set
specified in the optional data argument. You may also compute
predictions for all observed values of your explanatory variables
using fn = NULL.

\item {} 
Alternatively, for advanced uses, you may perform \emph{conditional}
prediction (cond = TRUE), which predicts certain quantities of
interest by conditioning on the observed value of the dependent
variable. In a simple linear regression model, this procedure is
not particularly interesting, since the conditional prediction is
merely the observed value of the dependent variable for that
observation. However, conditional prediction is extremely useful
for other models and methods, including the following:
\begin{itemize}
\item {} 
In a matched sampling design, the sample average treatment
effect for the treated can be estimated by computing the
difference between the observed dependent variable for the
treated group and their expected or predicted values of the
dependent variable under no treatment .

\item {} 
With censored data, conditional prediction will ensure that all
predicted values are greater than the censored observed values
.

\item {} 
In ecological inference models, conditional prediction
guarantees that the predicted values are on the tomography line
and thus restricted to the known bounds .

\item {} 
The conditional prediction in many linear random effects (or
Bayesian hierarchical) models is a weighted average of the
unconditional prediction and the value of the dependent
variable for that observation, with the weight being an
estimable function of the accuracy of the unconditional
prediction . When the unconditional prediction is highly
certain, the weight on the value of the dependent variable for
this observation is very small, hence reducing inefficiency;
when the unconditional prediction is highly uncertain, the
relative weight on the unconditional prediction is very small,
hence reducing bias. Although the simple weighted average
expression no longer holds in nonlinear models, the general
logic still holds and the mean square error of the measurement
is typically reduced .

\end{itemize}

In these and other models, conditioning on the observed value of
the dependent variable can vastly increase the accuracy of
prediction and measurement.

\end{itemize}

The setx() arguments for \textbf{unconditional} prediction are as follows:
\begin{enumerate}
\item {} 
z.out, the zelig() output object, must be included first.

\item {} 
You can set particular explanatory variables to specified values.
For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}vote \PYG{o}{\PYGZti{}} age \PYG{o}{+} race\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{logit\PYGZdq{}}\PYG{p}{,} data \PYG{o}{=} turnout\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.out \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} age \PYG{o}{=} \PYG{l+m}{30}\PYG{p}{)}
\end{Verbatim}

\code{setx()} sets the variables \emph{not} explicitly listed to their
mean if numeric, and their median if ordered factors, and their
mode if unordered factors, logical values, or character strings.
Alternatively, you may specify one explanatory variable as a range
of values, creating one observation for every unique value in the
range of values: {\color{red}\bfseries{}{[}2{]}\_}

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x.out \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} age \PYG{o}{=} \PYG{l+m}{18}\PYG{o}{:}\PYG{l+m}{95}\PYG{p}{)}
\end{Verbatim}

This creates 78 observations with with age set to 18 in the first
observation, 19 in the second observation, up to 95 in the 78th
observation. The other variables are set to their default values,
but this may be changed by setting fn, as described next.

\item {} 
Optionally, \code{fn} is a list which lets you to choose a different
function to apply to explanatory variables of class
\begin{itemize}
\item {} 
numeric, which is mean by default,

\item {} 
ordered factor, which is median by default, and

\item {} 
other variables, which consist of logical variables, character
string, and unordered factors, and are set to their mode by
default.

\end{itemize}

While any function may be applied to numeric variables, mean will
default to median for ordered factors, and mode is the only
available option for other types of variables. In the special
case, fn = NULL, setx() returns all of the observations.

\item {} 
You cannot perform other math operations within the fn argument,
but can use the output from one call of setx to create new values
for the explanatory variables. For example, to set the explanatory
variables to one standard deviation below their mean:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} X.sd \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} fn \PYG{o}{=} list\PYG{p}{(}numeric \PYG{o}{=} sd\PYG{p}{)}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} X.mean \PYG{o}{\PYGZlt{}\PYGZhy{}} setx\PYG{p}{(}z.out\PYG{p}{,} fn \PYG{o}{=} list\PYG{p}{(}numeric \PYG{o}{=} mean\PYG{p}{)}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} x.out \PYG{o}{\PYGZlt{}\PYGZhy{}} X.mean \PYG{o}{\PYGZhy{}} X.sd
\end{Verbatim}

\item {} 
Optionally, \code{data} identifies a new data frame (rather than the
one used to create z.out) from which the setx() values are
calculated. You can use this argument to set values of the
explanatory variables for hold-out or out-of-sample fit tests.

\item {} 
The cond is always FALSE for unconditional prediction.

\end{enumerate}

If you wish to calculate risk ratios or first differences, call
setx() a second time to create an additional set of the values for
the explanatory variables. For example, continuing from the example
above, you may create an alternative set of explanatory variables
values one standard deviation above their mean:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x.alt \PYG{o}{\PYGZlt{}\PYGZhy{}} X.mean \PYG{o}{+} X.sd
\end{Verbatim}

The required arguments for \textbf{conditional} prediction are as follows:
\begin{enumerate}
\item {} 
z.out, the zelig() output object, must be included first.

\item {} 
fn, which equals NULL to indicate that all of the observations are
selected. You may only perform conditional inference on actual
observations, not the mean of observations or any other function
applied to the observations. Thus, if fn is missing, but cond =
TRUE, setx() coerces fn = NULL.

\item {} 
data, the data for conditional prediction.

\item {} 
cond, which equals TRUE for conditional prediction.

\end{enumerate}

Additional arguments, such as any of the variable names, are ignored
in conditional prediction since the actual values of that observation
are used.

\item {} 
s.out \textless{}- sim(z.out, x = x.out, x1 = NULL, num = c(1000, 100),
bootstrap = FALSE, bootfn = NULL, …)

The sim() command simulates quantities of interest given the output
objects from \code{zelig()} and \code{setx()}. This procedure uses only the
assumptions of the statistical model. The sim() command performs
either unconditional or conditional prediction depending on the
options chosen in setx().

The arguments are as follows for \textbf{unconditional} prediction:
\begin{enumerate}
\item {} 
z.out, the model output from zelig().

\item {} 
x, the output from the setx() procedure performed on the model
output.

\item {} 
Optionally, you may calculate first differences by specifying x1,
an additional setx() object. For example, using the x.out and
x.alt, you may generate first differences using:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} s.out \PYG{o}{\PYGZlt{}\PYGZhy{}} sim\PYG{p}{(}z.out\PYG{p}{,} x \PYG{o}{=} x.out\PYG{p}{,} x1 \PYG{o}{=} x.alt\PYG{p}{)}
\end{Verbatim}

\item {} 
By default, the number of simulations, num, equals 1000 (or 100
simulations if bootstrap is selected), but this may be decreased
to increase computational speed, or increased for additional
precision.

\item {} 
Zelig simulates parameters from classical \emph{maximum likelihood}
models using asymptotic normal approximation to the
log-likelihood. This is the same assumption as used for
frequentist hypothesis testing (which is of course equivalent to
the asymptotic approximation of a Bayesian posterior with improper
uniform priors). See . For \emph{Bayesian models}, Zelig simulates
quantities of interest from the posterior density, whenever
possible. For \emph{robust Bayesian models}, simulations are drawn from
the identified class of Bayesian posteriors.

\item {} 
Alternatively, you may set bootstrap = TRUE to simulate parameters
using bootstrapped data sets. If your dataset is large, bootstrap
procedures will usually be more memory intensive and
time-consuming than simulation using asymptotic normal
approximation. The type of bootstrapping (including the sampling
method) is determined by the optional argument bootfn, described
below.

\item {} 
If bootstrap = TRUE is selected, sim() will bootstrap parameters
using the default bootfn, which re-samples from the data frame
with replacement to create a sampled data frame of the same number
of observations, and then re-runs zelig() (inside sim()) to create
one set of bootstrapped parameters. Alternatively, you may create
a function outside the sim() procedure to handle different
bootstrap procedures. Please consult help(boot) for more
details. \footnote{
If you choose to create your own bootfn, it must include the the
following three arguments: data, the original data frame; one of the
sampling methods described in help(boot); and object, the original
zelig() output object. The alternative bootstrapping function must
sample the data, fit the model, and extract the model-specific
parameters.
}

\end{enumerate}

For \textbf{conditional} prediction, sim() takes only two required
arguments:
\begin{enumerate}
\item {} 
z.out, the model output from zelig().

\item {} 
x, the conditional output from setx().

\item {} 
Optionally, for duration models, cond.data, which is the data
argument from setx(). For models for duration dependent variables
(see ), sim() must impute the uncensored dependent variables
before calculating the average treatment effect. Inputting the
cond.data allows sim() to generate appropriate values.

\end{enumerate}

Additional arguments are ignored or generate error messages.

\end{enumerate}


\subparagraph{Presenting Results}
\label{docs/user_guide:presenting-results}\begin{enumerate}
\item {} 
Use summary(s.out) to print a summary of your simulated quantities.
You may specify the number of significant digits as:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} print\PYG{p}{(}summary\PYG{p}{(}s.out\PYG{p}{)}\PYG{p}{,} digits \PYG{o}{=} \PYG{l+m}{2}\PYG{p}{)}
\end{Verbatim}

\item {} 
Alternatively, you can plot your results using \code{plot(s.out)}.

\item {} 
You can also use \code{names(s.out)} to see the names and a description
of the elements in this object and the \$ operator to extract
particular results. For most models, these are: s.out\$qi\$pr (for
predicted values), s.out\$qi\$ev (for expected values), and s.out\$qi\$fd
(for first differences in expected values). For the logit, probit,
multinomial logit, ordinal logit, and ordinal probit models,
quantities of interest also include s.out\$qi\$rr (the risk ratio).

\end{enumerate}


\subsubsection{Describe a model’s systematic and stochastic parameters}
\label{docs/user_guide:describe-a-models-systematic-and-stochastic-parameters}
In order to use parse.formula(), parse.par(), and the
model.*.multiple() commands, you must write a describe.mymodel()
function where mymodel is the name of your modeling function. (Hence, if
your function is called normal.regression(), you need to write a
describe.normal.regression() function.) Note that describe() is \emph{not} a
generic function, but is called by parse.formula(…, model = “mymodel”)
using a combination of paste() and exists(). You will never need to call
describe.mymodel() directly, since it will be called from
parse.formula() as that function checks the user-input formula or list
of formulas.

\begin{Verbatim}[commandchars=\\\{\}]
describe.mymodel\PYG{p}{(}\PYG{p}{)}
\end{Verbatim}

The describe.mymodel() function takes no arguments.

The describe.mymodel() function returns a list with the following
information:
\begin{itemize}
\item {} 
category: a character string, consisting of one of the following:
\begin{itemize}
\item {} 
“continuous”: the dependent variable is continuous, numeric, and
unbounded (e.g., normal regression), but may be censored with an
associated censoring indicator (e.g., tobit regression).

\item {} 
“dichotomous”: the dependent variable takes two discrete integer
values, usually 0 and 1 (e.g., logistic regression).

\item {} 
“ordinal”: the dependent variable is an ordered factor response,
taking 3 or more discrete values which are arranged in an
ascending or descending manner (e.g., ordered logistic
regression).

\item {} 
“multinomial”: the dependent variable is an unordered factor
response, taking 3 or more discrete values which are arranged in
no particular order (e.g., multinomial logistic regression).

\item {} 
“count”: the dependent variable takes integer values greater than
or equal to 0 (e.g., Poisson regression).

\item {} 
“bounded”: the dependent variable is a continuous numeric
variable, that is restricted (bounded within) some range (e.g.,
). The variable may also be censored either on
the left and/or right side, with an associated censoring indicator
(e.g., Weibull regression).

\item {} 
“mixed”: the dependent variables are a mix of the above categories
(usually applies to multiple equation models).

\end{itemize}

Selecting the category is particularly important since it sets
certain interface parameters for the entire GUI.

\item {} 
package: (optional) a list with the following elements
\begin{itemize}
\item {} 
name: a characters string with the name of the package containing
the mymodel() function.

\item {} 
version: the minimum version number that works with Zelig.

\item {} 
CRAN: if the package is not hosted on CRAN mirrors, provide the
URL here as a character string. You should be able to install your
package from this URL using name, version, and CRAN:

\begin{Verbatim}[commandchars=\\\{\}]
install.packages\PYG{p}{(}name\PYG{p}{,} repos \PYG{o}{=} CRAN\PYG{p}{,} installWithVers \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
\end{Verbatim}

By default, CRAN = “\href{http://cran.us.r-project.org/}{http://cran.us.r-project.org/}”.

\end{itemize}

\item {} 
parameters: For each systematic and stochastic parameter (or set of
parameters) in your model, you should create a list (named after the
parameters as given in your model’s notation, e.g., mu, sigma, theta,
etc.; not literally myparameter) with the following information:
\begin{itemize}
\item {} 
equations: an integer number of equations for the parameter. For
parameters that can take an undefined number of equations (for
example in seemingly unrelated regression), use c(2, Inf) or c(2,
999) to indicate that the parameter can take a minimum of two
equations up to a theoretically infinite number of equations.

\item {} 
tagsAllowed: a logical value (TRUE/FALSE) specifying whether a
given parameter allows constraints. If there is only one equation
for a parameter (for example, mu for the normal regression model
has equations = 1), then tagsAllowed = FALSE by default. If there
are two or more equations for the parameter (for example, mu for
the bivariate probit model has equations = 2), then tagsAllowed =
TRUE by default.

\item {} 
depVar: a logical value (TRUE/FALSE) specifying whether a
parameter requires a corresponding dependent variable.

\item {} 
expVar: a logical value (TRUE/FALSE) specifying whether a
parameter allows explanatory variables. If depVar = TRUE and
expVar = TRUE, we call the parameter a “systematic component” and
parse.formula() will fail if formula(s) are not specified for this
parameter. If depVar = FALSE and expVar = TRUE, the parameter is
estimated as a scalar ancillary parameter, with default formula
\code{\textasciitilde{} 1}, if the user does not specify a formula explicitly. If
depVar = FALSE and expVar = FALSE, the parameter can only be
estimated as a scalar ancillary parameter.

\item {} 
specialFunction: (optional) a character string giving the name of
a function that appears on the left-hand side of the formula.
Options include “Surv”, “cbind”, and “as.factor”.

\item {} 
varInSpecial: (optional) a scalar or vector giving the number of
variables taken by the specialFunction. For example, Surv() takes
a minimum of 2 arguments, and a maximum of 4 arguments, which is
represented as c(2, 4).

\end{itemize}

If you have more than one parameter (or set of parameters) in your
model, you will need to produce a myparameter list for each one. See
examples below for details.

\end{itemize}

For a Normal regression model with mean mu and scalar variance parameter
sigma2, the minimal describe.*() function is as follows:

\begin{Verbatim}[commandchars=\\\{\}]
describe.normal.regression \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  category \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{continuous\PYGZdq{}}
  mu \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{,}              \PYG{c+c1}{\PYGZsh{} Systematic component}
             tagsAllowed \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}
             depVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             expVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
  sigma2 \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{,}          \PYG{c+c1}{\PYGZsh{} Scalar ancillary parameter}
                 tagsAllowed \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}
                 depVar \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}
                 expVar \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{)}
  pars \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}mu \PYG{o}{=} mu\PYG{p}{,} sigma2 \PYG{o}{=} sigma2\PYG{p}{)}
  model \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}category \PYG{o}{=} category\PYG{p}{,} parameters \PYG{o}{=} pars\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

See for full code to execute this model from scratch in R with Zelig.

Now consider a bivariate probit model with parameter vector mu and
correlation parameter rho (which may or may not take explanatory
variables). Since the bivariate probit function uses the pmvnorm()
function from the mvtnorm library, we list this under package.

\begin{Verbatim}[commandchars=\\\{\}]
describe.bivariate.probit \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  category \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{dichotomous\PYGZdq{}}
  package \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}name \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mvtnorm\PYGZdq{}}\PYG{p}{,}
                  version \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0.7\PYGZdq{}}\PYG{p}{)}
  mu \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{2}\PYG{p}{,}               \PYG{c+c1}{\PYGZsh{} Systematic component}
             tagsAllowed \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             depVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             expVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
  rho \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{,}              \PYG{c+c1}{\PYGZsh{} Optional systematic component}
             tagsAllowed \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}         \PYG{c+c1}{\PYGZsh{}   Estimated as an ancillary}
             depVar \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}              \PYG{c+c1}{\PYGZsh{}   parameter by default}
             expVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
  pars \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}mu \PYG{o}{=} mu\PYG{p}{,} rho \PYG{o}{=} rho\PYG{p}{)}
  list\PYG{p}{(}category \PYG{o}{=} category\PYG{p}{,} package \PYG{o}{=} package\PYG{p}{,} parameters \PYG{o}{=} pars\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

See for the full code to write this model from scratch in R with Zelig.

For a multinomial logit model, which takes an undefined number of
equations (corresponding to each level in the response variable):

\begin{Verbatim}[commandchars=\\\{\}]
describe.multinomial.logit \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  category \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{multinomial\PYGZdq{}}
  mu \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{k+kc}{Inf}\PYG{p}{)}\PYG{p}{,}
             tagsAllowed \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             depVAR \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             expVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             specialFunction \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{as.factor\PYGZdq{}}\PYG{p}{,}
             varInSpecial \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{)}\PYG{p}{)}
  list\PYG{p}{(}category \PYG{o}{=} category\PYG{p}{,} parameters \PYG{o}{=} list\PYG{p}{(}mu \PYG{o}{=} mu\PYG{p}{)}\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

(This example does not have corresponding executable sample code.)
\begin{itemize}
\item {} 
for an overview of how the describe.*() function works with
parse.formula().

\end{itemize}

Kosuke Imai, Gary King, Olivia Lau, and Ferdinand Alimadhi.


\subsubsection{Supported Models}
\label{docs/user_guide:supported-models}
We list here all models implemented in Zelig, organized by the nature of
the dependent variable(s) to be predicted, explained, or described.
\begin{enumerate}
\item {} 
\textbf{Continuous Unbounded} dependent variables can take any real value
in the range . While most of these models
take a continuous dependent variable, Bayesian factor analysis takes
multiple continuous dependent variables.
\begin{enumerate}
\item {} 
“ls”: The \emph{linear least-squares} (see ) calculates the
coefficients that minimize the sum of squared residuals. This is
the usual method of computing linear regression coefficients, and
returns unbiased estimates of  and 
(conditional on the specified model).

\item {} 
“normal”: The \emph{Normal} (see ) model computes the
maximum-likelihood estimator for a Normal stochastic component and
linear systematic component. The coefficients are identical to
\code{ls}, but the maximum likelihood estimator for 
is consistent but biased.

\item {} 
“normal.bayes”: The \emph{Bayesian Normal} regression model () is
similar to maximum likelihood Gaussian regression, but makes valid
small sample inferences via draws from the exact posterior and
also allows for priors.

\item {} 
“netls”: The \emph{network least squares} regression () is similar to
least squares regression for continuous-valued proximity matrix
dependent variables. Proximity matrices are also known as
sociomatrices, adjacency matrices, and matrix representations of
directed graphs.

\item {} 
“tobit”: The \emph{tobit} regression model (see ) is a Normal
distribution with left-censored observations.

\item {} 
“tobit.bayes”: The \emph{Bayesian tobit} distribution (see ) is a
Normal distribution that has either left and/or right censored
observations.

\item {} 
“arima”: Use \emph{auto-regressive, integrated, moving-average} (ARIMA)
models for time series data (see .

\item {} 
“factor.bayes”: The \emph{Bayesian factor analysis} model (see )
estimates multiple observed continuous dependent variables as a
function of latent explanatory variables.

\end{enumerate}

\item {} 
\textbf{Dichotomous} dependent variables consist of two discrete values,
usually .
\begin{enumerate}
\item {} 
“logit”: \emph{Logistic regression} (see ) specifies 
to be a(n inverse) logistic transformation of a linear function of
a set of explanatory variables.

\item {} 
“relogit”: The \emph{rare events logistic} regression option (see )
estimates the same model as the logit, but corrects for bias due
to rare events (when one of the outcomes is much more prevalent
than the other). It also optionally uses prior correction to
correct for choice-based (case-control) sampling designs.

\item {} 
“logit.bayes”: \emph{Bayesian logistic regression} (see ) is similar to
maximum likelihood logistic regression, but makes valid small
sample inferences via draws from the exact posterior and also
allows for priors.

\item {} 
“probit”: \emph{Probit regression} (see ) Specifies  to
be a(n inverse) CDF normal transformation as a linear function of
a set of explanatory variables.

\item {} 
“probit.bayes”: \emph{Bayesian probit} regression (see ) is similar to
maximum likelihood probit regression, but makes valid small sample
inferences via draws from the exact posterior and also allows for
priors.

\item {} 
“netlogit”: The \emph{network logistic} regression () is similar to
logistic regression for binary-valued proximity matrix dependent
variables. Proximity matrices are also known as sociomatrices,
adjacency matrices, and matrix representations of directed graphs.

\item {} 
“blogit”: The \emph{bivariate logistic} model (see ) models
 for
 according to a
bivariate logistic density.

\item {} 
“bprobit”: The \emph{bivariate probit} model (see ) models
 for
 according to a
bivariate normal density.

\item {} 
“irt1d”: The \emph{one-dimensional item response} model (see ) takes
multiple dichotomous dependent variables and models them as a
function of \emph{one} latent (unobserved) explanatory variable.

\item {} 
“irtkd”: The \emph{k-dimensional item response} model (see ) takes
multiple dichotomous dependent variables and models them as a
function of  latent (unobserved) explanatory variables.

\end{enumerate}

\item {} 
\textbf{Ordinal} are used to model ordered, discrete dependent variables.
The values of the outcome variables (such as kill, punch, tap, bump)
are ordered, but the distance between any two successive categories
is not known exactly. Each dependent variable may be thought of as
linear, with one continuous, unobserved dependent variable observed
through a mechanism that only returns the ordinal choice.
\begin{enumerate}
\item {} 
“ologit”: The \emph{ordinal logistic} model (see ) specifies the
stochastic component of the unobserved variable to be a standard
logistic distribution.

\item {} 
“oprobit”: The \emph{ordinal probit} distribution (see ) specifies the
stochastic component of the unobserved variable to be standardized
normal.

\item {} 
“oprobit.bayes”: \emph{Bayesian ordinal probit} model (see ) is similar
to ordinal probit regression, but makes valid small sample
inferences via draws from the exact posterior and also allows for
priors.

\item {} 
“factor.ord”: \emph{Bayesian ordered factor analysis} (see ) models
observed, ordinal dependent variables as a function of latent
explanatory variables.

\end{enumerate}

\item {} 
\textbf{Multinomial} dependent variables are unordered, discrete
categorical responses. For example, you could model an individual’s
choice among brands of orange juice or among candidates in an
election.
\begin{enumerate}
\item {} 
“mlogit”: The \emph{multinomial logistic} model (see ) specifies
categorical responses distributed according to the multinomial
stochastic component and logistic systematic component.

\item {} 
“mlogit.bayes”: \emph{Bayesian multinomial logistic} regression (see )
is similar to maximum likelihood multinomial logistic regression,
but makes valid small sample inferences via draws from the exact
posterior and also allows for priors.

\end{enumerate}

\item {} 
\textbf{Count} dependent variables are non-negative integer values, such
as the number of presidential vetoes or the number of photons that
hit a detector.
\begin{enumerate}
\item {} 
“poisson”: The \emph{Poisson} model (see ) specifies the expected
number of events that occur in a given observation period to be an
exponential function of the explanatory variables. The Poisson
stochastic component has the property that,
:math:{\color{red}\bfseries{}{}`}lambda = textrm\{E\}(Y\_i\textbar{}X\_i)
\begin{quote}

= textrm\{V\}(Y\_i\textbar{}X\_i){}`.
\end{quote}

\item {} 
“poisson.bayes”: \emph{Bayesian Poisson} regression (see ) is similar
to maximum likelihood Poisson regression, but makes valid small
sample inferences via draws from the exact posterior and also
allows for priors.

\item {} 
“negbin”: The \emph{negative binomial} model (see ) has the same
systematic component as the Poisson, but allows event counts to be
over-dispersed, such that
.

\end{enumerate}

\item {} 
{\color{red}\bfseries{}**}Continuous Bounded**{[}duration{]} dependent variables that are
continuous only over a certain range, usually . In
addition, some models (exponential, lognormal, and Weibull) are also
censored for values greater than some censoring point, such that the
dependent variable has some units fully observed and others that are
only partially observed (censored).
\begin{enumerate}
\item {} 
“gamma”: The \emph{Gamma} model (see ) for positively-valued,
continuous dependent variables that are fully observed (no
censoring).

\item {} 
“exp”: The \emph{exponential} model (see ) for right-censored dependent
variables assumes that the hazard function is constant over time.
For some variables, this may be an unrealistic assumption as
subjects are more or less likely to fail the longer they have been
exposed to the explanatory variables.

\item {} 
“weibull”: The \emph{Weibull} model (see ) for right-censored dependent
variables relaxes the assumption of constant hazard by including
an additional scale parameter : If
, the risk of failure increases the longer the
subject has survived; if , the risk of failure
decreases the longer the subject has survived. While zelig()
estimates  by default, you may optionally fix
 at any value greater than 0. Fixing
 results in an exponential model.

\item {} 
“lognorm”: The \emph{log-normal} model (see ) for right-censored
duration dependent variables specifies the hazard function
non-monotonically, with increasing hazard over part of the
observation period and decreasing hazard over another.

\end{enumerate}

\item {} 
\textbf{Mixed} dependent variables include models that take more than one
dependent variable, where the dependent variables come from two or
more of categories above. (They do not need to be of a homogeneous
type.)
\begin{enumerate}
\item {} 
The \emph{Bayesian mixed factor analysis} model, in contrast to the
Bayesian factor analysis model and ordinal factor analysis model,
can model both types of dependent variables as a function of
latent explanatory variables.

\end{enumerate}

\item {} 
\textbf{Ecological inference} models estimate unobserved internal cell
values given contingency tables with observed row and column
marginals.
\begin{enumerate}
\item {} 
ei.hier: The \emph{hierarchical ei} model (see ) produces estimates for
a cross-section of  tables.

\item {} 
ei.dynamic: \emph{Quinn’s dynamic Bayesian ei} model (see ) estimates a
dynamic Bayesian model for  tables with temporal
dependence across tables.

\item {} 
ei.RxC: The  ei model (see ) estimates a
hierarchical Multinomial-Dirichlet ei model for contingency tables
with more than 2 rows or columns.

\end{enumerate}

\end{enumerate}


\subsubsection{Replication Procedures}
\label{docs/user_guide:replication-procedures}
A large part of any statistical analysis is documenting your work such
that given the same data, anyone may replicate your results. In
addition, many journals require the creation and dissemination of
“replication data sets” in order that others may replicate your results
(see ). Whether you wish to create replication materials for your own
records, or contribute data to others as a companion to your published
work, Zelig makes this process easy.


\paragraph{Saving Replication Materials}
\label{docs/user_guide:saving-replication-materials}
Let mydata be your final data set, z.out be your zelig() output, and
s.out your sim() output. To save all of this in one file, type:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} save\PYG{p}{(}mydata\PYG{p}{,} z.out\PYG{p}{,} s.out\PYG{p}{,} file \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{replication.RData\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

This creates the file replication.RData in your working directory. You
may compress this file using zip or gzip tools.

If you have run several specifications, all of these estimates may be
saved in one .RData file. Even if you only created quantities of
interest from one of these models, you may still save all the
specifications in one file. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} save\PYG{p}{(}mydata\PYG{p}{,} z.out1\PYG{p}{,} z.out2\PYG{p}{,} s.out\PYG{p}{,} file \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{replication.RData\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

Although the .RData format can contain data sets as well as output
objects, it is not the most space-efficient way of saving large data
sets. In an uncompressed format, ASCII text files take up less space
than data in .RData format. (When compressed, text-formatted data is
still smaller than .RData-formatted data.) Thus, if you have more than
100,000 observations, you may wish to save the data set separately from
the Zelig output objects. To do this, use the write.table() command. For
example, if mydata is a data frame in your workspace, use
write.table(mydata, file = “mydata.tab”) to save this as a tab-delimited
ASCII text file. You may specify other delimiters as well; see
help.zelig(“write.table”) for options.


\paragraph{Replicating Analyses}
\label{docs/user_guide:replicating-analyses}
If the data set and analyses are all saved in one .RData file, located
in your working directory, you may simply type:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} load\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{replication.RData\PYGZdq{}}\PYG{p}{)}                   \PYG{c+c1}{\PYGZsh{} Loads the replication file.}
\PYG{o}{\PYGZgt{}} z.rep \PYG{o}{\PYGZlt{}\PYGZhy{}} repl\PYG{p}{(}z.out\PYG{p}{)}                        \PYG{c+c1}{\PYGZsh{} To replicate the model only.}
\PYG{o}{\PYGZgt{}} s.rep \PYG{o}{\PYGZlt{}\PYGZhy{}} repl\PYG{p}{(}s.out\PYG{p}{)}                        \PYG{c+c1}{\PYGZsh{} To replicate the model and}
                                              \PYG{c+c1}{\PYGZsh{}  quantities of interest.}
\end{Verbatim}

By default, repl() uses the same options used to create the original
output object. Thus, if the original s.out object used bootstrapping
with 245 simulations, the s.rep object will similarly have 245
bootstrapped simulations. In addition, you may use the prev option when
replicating quantities of interest to reuse rather than recreate
simulated parameters. Type help.zelig(“repl”) to view the complete list
of options for repl().

If the data were saved in a text file, use read.table() to load the
data, and then replicate the analysis:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} dat \PYG{o}{\PYGZlt{}\PYGZhy{}} read.table\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.tab\PYGZdq{}}\PYG{p}{,} header \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Where {}`dat\PYGZsq{} is the same}
\PYG{o}{\PYGZgt{}} load\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{replication.RData\PYGZdq{}}\PYG{p}{)}                       \PYG{c+c1}{\PYGZsh{}   as the name used in}
\PYG{o}{\PYGZgt{}} z.rep \PYG{o}{\PYGZlt{}\PYGZhy{}} repl\PYG{p}{(}z.out\PYG{p}{)}                            \PYG{c+c1}{\PYGZsh{}   {}`z.out\PYGZsq{}.}
\PYG{o}{\PYGZgt{}} s.rep \PYG{o}{\PYGZlt{}\PYGZhy{}} repl\PYG{p}{(}s.out\PYG{p}{)}
\end{Verbatim}

If you have problems loading the data, please refer to .

Finally, you may use the identical() command to ensure that the
replicated regression output is in every way identical to the original
zelig() output. \footnote{
The identical() command checks that numeric values are identical to
the maximum number of decimal places (usually 16), and also checks
that the the two objects have the same class (numeric, character,
integer, logical, or factor). Refer to help(identical) for more
information.
} For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} identical\PYG{p}{(}z.out\PYG{o}{\PYGZdl{}}coef\PYG{p}{,} z.rep\PYG{o}{\PYGZdl{}}coef\PYG{p}{)}              \PYG{c+c1}{\PYGZsh{} Checks the coefficients.}
\end{Verbatim}

Simulated quantities of interest will vary from the original quantities
if parameters are re-simulated or re-sampled. If you wish to use
identical() to verify that the quantities of interest are identical, you
may use

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Re\PYGZhy{}use the parameters simulated (and stored) in the original sim() output.}
\PYG{o}{\PYGZgt{}} s.rep \PYG{o}{\PYGZlt{}\PYGZhy{}} repl\PYG{p}{(}s.out\PYG{p}{,} prev \PYG{o}{=} s.out\PYG{o}{\PYGZdl{}}par\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Check that the expected values are identical.  You may do this for each qi.}
\PYG{o}{\PYGZgt{}} identical\PYG{p}{(}s.out\PYG{o}{\PYGZdl{}}qi\PYG{o}{\PYGZdl{}}ev\PYG{p}{,} s.rep\PYG{o}{\PYGZdl{}}qi\PYG{o}{\PYGZdl{}}ev\PYG{p}{)}
\end{Verbatim}


\subsection{Graphing Commands}
\label{docs/user_guide:graphing-commands}\label{docs/user_guide:userguide-graphing-commands}
R, and thus Zelig, can produce exceptionally beautiful plots. Many
built-in plotting functions exist, including scatter plots, line charts,
histograms, bar charts, pie charts, ternary diagrams, contour plots, and
a variety of three-dimensional graphs. If you desire, you can exercise a
high degree of control to generate just the right graphic. Zelig
includes several default plots for one-observation simulations for each
model. To view these plots on-screen, simply type plot(s.out), where
s.out is the output from sim(). Depending on the model chosen, plot()
will return different plots.

If you wish to create your own plots, this section reviews the most
basic procedures for creating and saving two-dimensional plots. R plots
material in two steps:
\begin{enumerate}
\item {} 
You must call an output device (discussed in ), select a type of
plot, draw a plotting region, draw axes, and plot the given data. At
this stage, you may also define axes labels, the plot title, and
colors for the plotted data. Step one is described in below.

\item {} 
Optionally, you may add points, lines, text, or a legend to the
existing plot. These commands are described in .

\end{enumerate}


\subsubsection{Drawing Plots}
\label{docs/user_guide:drawing-plots}
The most generic plotting command is \code{plot()}, which automatically
recognizes the type of R object(s) you are trying to plot and selects
the best type of plot. The most common graphs returned by \code{plot()} are
as follows:
\begin{enumerate}
\item {} 
If \code{X} is a variable of length , \code{plot(X)} returns a
scatter plot of  for . If X is
unsorted, this procedure produces a messy graph. Use
\code{plot(sort(X))} to arrange the plotted values of 
from smallest to largest.

\item {} 
With two numeric vectors \code{X} and \code{Y}, both of length ,
\code{plot(X, Y)} plots a scatter plot of each point 
for . Alternatively, if Z is an object with two
vectors, \code{plot(Z)} also creates a scatter plot.

\end{enumerate}

Optional arguments specific to \code{plot} include:
\begin{itemize}
\item {} 
\code{main} creates a title for the graph, and \code{xlab} and \code{ylab}
label the x and y axes, respectively. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{n}{plot}\PYG{p}{(}\PYG{n}{x}\PYG{p}{,} \PYG{n}{y}\PYG{p}{,} \PYG{n}{main} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{My Lovely Plot}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,} \PYG{n}{xlab} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Explanatory Variable}\PYG{l+s}{\PYGZdq{}}\PYG{p}{,}
     \PYG{n}{ylab} \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Dependent Variable}\PYG{l+s}{\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\item {} 
\code{type} controls the type of plot you request. The default is
\code{plot(x, y, type = p)}, but you may choose among the following
types:

{[}!h{]}
\begin{quote}

\begin{tabulary}{\linewidth}{|L|L|}
\hline

“p”
 & 
points
\\

“l”
 & 
lines
\\

“b”
 & 
both points and lines
\\

“c”
 & 
lines drawn up to but not including the points
\\

“h”
 & 
histogram
\\

“s”
 & 
a step function
\\

“n”
 & 
a blank plotting region ( with the axes specified)
\\
\hline\end{tabulary}

\end{quote}

\item {} 
If you choose type = “p”, R plots open circles by default. You can
change the type of point by specifying the pch argument. For example,
\code{plot(x, y, type = p, pch = 19)} creates a scatter-plot of filled
circles. Other options for pch include:

{[}!h{]}
\begin{quote}

\begin{tabulary}{\linewidth}{|L|L|}
\hline

19
 & 
solid circle (a disk)
\\

20
 & 
smaller solid circle
\\

21
 & 
circle
\\

22
 & 
square
\\

23
 & 
diamond
\\

24
 & 
triangle pointed up
\\

25
 & 
triangle pointed down
\\
\hline\end{tabulary}

\end{quote}

In addition, you can specify your own symbols by using, for example,
pch = “*” or pch = “.”.

\item {} 
If you choose type = “l”, R plots solid lines by default. Use the
optional lty argument to set the line type. For example, plot(x, y,
type = “l”, lty = “dashed”) plots a dashed line. Other options are
dotted, dotdash, longdash, and twodash.

\item {} 
\code{col} sets the color of the points, lines, or bars. For example,
\code{plot(x, y, type = b, pch = 20, lty = dotted, col = violet)} plots
small circles connected by a dotted line, both of which are violet.
(The axes and labels remain black.) Use \code{colors()} to see the full
list of available colors.

\item {} 
\code{xlim} and ylim set the limits to the -axis and
-axis. For example,
\code{plot(x, y, xlim = c(0, 25), ylim = c(-15, 5))} sets range of the
-axis to {[}0, 25{]} and the range of the -axis to
.

\end{itemize}

For additional plotting options, refer to help(par).


\subsubsection{Adding Points, Lines, and Legends to Existing Plots}
\label{docs/user_guide:adding-points-lines-and-legends-to-existing-plots}
Once you have created a plot, you can \emph{add} points, lines, text, or a
legend. To place each of these elements, R uses coordinates defined in
terms of the x-axes and y-axes of the plot area, not coordinates defined
in terms of the the plotting window or device. For example, if your plot
has an x-axis with values between , and a y-axis with values between , you may add a
point at .
\begin{itemize}
\item {} 
\textbf{points()} plots one or more sets of points. Use \code{pch} with
\code{points} to add points to an existing plot. For example,
\code{points(P, Q, pch = ., col = forest green)} plots each
 as tiny green dots.

\item {} 
\textbf{lines()} joins the specified points with line segments. The
arguments \code{col} and \code{lty} may also be used. For example,
\code{lines(X, Y, col = blue, lty = dotted)} draws a blue dotted line
from each set of points  to the next.
Alternatively, \code{lines} also takes command output which specifies
 coordinates. For example, \code{density(Z)} creates a
vector of  and a vector of , and plot(density(Z))
draws the kernel density function.

\item {} 
\textbf{text()} adds a character string at the specified set of
 coordinates. For example, text(5, 5, labels = “Key
Point”) adds the label “Key Point” at the plot location
. You may also choose the font using the font option,
the size of the font relative to the axis labels using the cex
option, and choose a color using the col option. The full list of
options may be accessed using help(text).

\item {} 
\textbf{legend()} places a legend at a specified set of 
coordinates. Type demo(vertci) to see an example for legend().

\end{itemize}


\subsubsection{Saving Graphs to Files}
\label{docs/user_guide:saving-graphs-to-files}
By default, R displays graphs in a window on your screen. To save R
plots to file (to include them in a paper, for example), preface your
plotting commands with:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} ps.options\PYG{p}{(}family \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Times\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} pointsize \PYG{o}{=} \PYG{l+m}{12}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} postscript\PYG{p}{(}file \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mygraph.eps\PYGZdq{}}\PYG{p}{,} horizontal \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,} paper \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{special\PYGZdq{}}\PYG{p}{,}
             width \PYG{o}{=} \PYG{l+m}{6.25}\PYG{p}{,} height \PYG{o}{=} \PYG{l+m}{4}\PYG{p}{)}
\end{Verbatim}

where the \code{ps.options()} command sets the font type and size in the
output file, and the \code{postscript} command allows you to specify the
name of the file as well as several additional options. Using paper =
special allows you to specify the width and height of the encapsulated
postscript region in inches (6.25 inches long and 4 inches high, in this
case), and the statement \code{horizontal = FALSE} suppresses R’s default
landscape orientation. Alternatively, you may use pdf() instead of
postscript(). If you wish to select postscript options for .pdf output,
you may do so using options in pdf(). For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} pdf\PYG{p}{(}file \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mygraph.pdf\PYGZdq{}}\PYG{p}{,} width \PYG{o}{=} \PYG{l+m}{6.25}\PYG{p}{,} height \PYG{o}{=} \PYG{l+m}{4}\PYG{p}{,} family \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Times\PYGZdq{}}\PYG{p}{,}
\PYG{o}{+}     pointsize \PYG{o}{=} \PYG{l+m}{12}\PYG{p}{)}
\end{Verbatim}

At the end of every plot, you should close your output device. The
command \code{dev.off()} stops writing and saves the \code{.eps} or .pdf file
to your working directory. If you forget to close the file, you will
write all subsequent plots to the same file, overwriting previous plots.
You may also use \code{dev.off()} to close on-screen plot windows.

To write multiple plots to the same file, you can use the following
options:
\begin{itemize}
\item {} 
For plots on separate pages in the same .pdf document, use

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} pdf\PYG{p}{(}file \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mygraph.pdf\PYGZdq{}}\PYG{p}{,} width \PYG{o}{=} \PYG{l+m}{6.25}\PYG{p}{,} height \PYG{o}{=} \PYG{l+m}{4}\PYG{p}{,} family \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Times\PYGZdq{}}\PYG{p}{,}
\PYG{o}{+}     pointsize \PYG{o}{=} \PYG{l+m}{12}\PYG{p}{,} onefile \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
\end{Verbatim}

\item {} 
For multiple plots on one page, initialize either a .pdf or .eps
file, then (before any plotting commands) type:

\begin{Verbatim}[commandchars=\\\{\}]
par\PYG{p}{(}mfrow \PYG{o}{=} c\PYG{p}{(}\PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{4}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

This creates a grid that has two rows and four columns. Your plot
statements will populate the grid going across the first row, then
the second row, from left to right.

\end{itemize}


\subsubsection{Examples}
\label{docs/user_guide:id17}

\paragraph{Descriptive Plots: Box-plots}
\label{docs/user_guide:descriptive-plots-box-plots}
\includegraphics{docs/figs/vertci}

Using the sample \code{turnout} data set included with Zelig, the following
commands will produce the graph above.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} library\PYG{p}{(}Zelig\PYG{p}{)}                             \PYG{c+c1}{\PYGZsh{} Loads the Zelig package.}
\PYG{o}{\PYGZgt{}} data \PYG{p}{(}turnout\PYG{p}{)}                             \PYG{c+c1}{\PYGZsh{} Loads the sample data.}
\PYG{o}{\PYGZgt{}} boxplot\PYG{p}{(}income \PYG{o}{\PYGZti{}} educate\PYG{p}{,}                  \PYG{c+c1}{\PYGZsh{} Creates a boxplot with income}
\PYG{o}{+}  data \PYG{o}{=} turnout\PYG{p}{,} col \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{grey\PYGZdq{}}\PYG{p}{,} pch \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{.\PYGZdq{}}\PYG{p}{,}  \PYG{c+c1}{\PYGZsh{}  as a function of education.}
\PYG{o}{+}  main \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Income as a Function of Years of Education\PYGZdq{}}\PYG{p}{,}
\PYG{o}{+}  xlab \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Education in Years\PYGZdq{}}\PYG{p}{,} ylab \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Income in \PYGZbs{}\PYGZdl{}10,000s\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}


\paragraph{Density Plots: A Histogram}
\label{docs/user_guide:density-plots-a-histogram}
Histograms are easy ways to evaluate the density of a quantity of
interest.

\includegraphics{docs/figs/vertci}

Here’s the code to create this graph:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} library\PYG{p}{(}Zelig\PYG{p}{)}                              \PYG{c+c1}{\PYGZsh{} Loads the Zelig package.}
\PYG{o}{\PYGZgt{}} data\PYG{p}{(}turnout\PYG{p}{)}                               \PYG{c+c1}{\PYGZsh{} Loads the sample data set.}
\PYG{o}{\PYGZgt{}} truehist\PYG{p}{(}turnout\PYG{o}{\PYGZdl{}}income\PYG{p}{,}  col \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{wheat1\PYGZdq{}}\PYG{p}{,}   \PYG{c+c1}{\PYGZsh{} Calls the main plot, with}
\PYG{o}{+}      xlab \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Annual Income in \PYGZdl{}10,000s\PYGZdq{}}\PYG{p}{,}    \PYG{c+c1}{\PYGZsh{}  options.}
\PYG{o}{+}      main \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Histogram of Income\PYGZdq{}}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} lines\PYG{p}{(}density\PYG{p}{(}turnout\PYG{o}{\PYGZdl{}}income\PYG{p}{)}\PYG{p}{)}              \PYG{c+c1}{\PYGZsh{} Adds the kernel density line.}
\end{Verbatim}


\paragraph{Advanced Examples}
\label{docs/user_guide:advanced-examples}
The examples above are simple examples which only skim the surface of
R’s plotting potential. We include more advanced, model-specific plots
in the Zelig demo scripts, and have created functions that automate some
of these plots, including:
\begin{enumerate}
\item {} 
\textbf{Ternary Diagrams} describe the predicted probability of a
categorical dependent variable that has three observed outcomes. You
may choose to use this plot with the multinomial logit, the ordinal
logit, or the ordinal probit models (Katz and King, 1999). See for
the sample code, type demo(mlogit) at the R prompt to run the
example, and refer to Section {[}ternary{]} to add points to a ternary
diagram.

\includegraphics{docs/figs/vertci}

\item {} 
\textbf{ROC Plots} summarize how well models for binary dependent
variables (logit, probit, and relogit) fit the data. The ROC plot
evaluates the fraction of 0’s and 1’s correctly predicted for every
possible threshold value at which the continuous
Prob may be realized as a dichotomous prediction.
The closer the ROC curve is to the upper right corner of the plot,
the better the fit of the model specification (King and Zeng,
2002\emph{b}). See Section {[}ROC{]} for the sample code, and type demo(roc)
at the R prompt to run the example.

\includegraphics{docs/figs/vertci}

\item {} 
\textbf{Vertical Confidence Intervals} may be used for almost any model,
and describe simulated confidence intervals for any quantity of
interest while allowing one of the explanatory variables to vary over
a given range of values (King, Tomz and Wittenberg, 2000). Type
demo(vertci) at the R prompt to run the example, and
help.zelig(plot.ci) for the manual page.

\includegraphics{docs/figs/vertci} {[}plot.vertci{]}

\end{enumerate}


\subsection{R Objects}
\label{docs/user_guide:userguide-r-objects}\label{docs/user_guide:r-objects}
In R, objects can have one or more classes, consisting of the class of
the scalar value and the class of the data structure holding the scalar
value. Use the is() command to determine what an object \emph{is}. If you are
already familiar with R objects, you may skip to for loading data, or
for a description of Zelig commands.


\subsubsection{Scalar Values}
\label{docs/user_guide:scalar-values}
R uses several classes of scalar values, from which it constructs larger
data structures. R is highly class-dependent: certain operations will
only work on certain types of values or certain types of data
structures. We list the three basic types of scalar values here for your
reference:
\begin{enumerate}
\item {} 
\textbf{Numeric} is the default value type for most numbers. An
\code{integer} is a subset of the \code{numeric} class, and may be used as
a \code{numeric} value. You can perform any type of math or logical
operation on numeric values, including:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZgt{} log(3 * 4 * (2 + pi))         \PYGZsh{} Note that pi is a built\PYGZhy{}in constant,
   [1] 4.122270                 \PYGZsh{}   and log() the natural log function.
\PYGZgt{} 2 \PYGZgt{} 3                         \PYGZsh{} Basic logical operations, including \PYGZgt{},
   [1] FALSE                    \PYGZsh{}   \PYGZlt{}, \PYGZgt{}= (greater than or equals),
                                \PYGZsh{}   \PYGZlt{}= (less than or equals), == (exactly
                                \PYGZsh{}   equals), and != (not equals).
\PYGZgt{} 3 \PYGZgt{}= 2 \PYGZam{}\PYGZam{} 100 == 1000/10      \PYGZsh{} Advanced logical operations, including
   [1] TRUE                     \PYGZsh{}   \PYGZam{} (and), \PYGZam{}\PYGZam{} (if and only if), \textbar{} (or),
                                \PYGZsh{}   and \textbar{}\textbar{} (either or).
\end{Verbatim}

Note that \code{Inf} (infinity), \code{-Inf} (negative infinity), \code{NA}
(missing value), and \code{NaN} (not a number) are special numeric
values on which most math operations will fail. (Logical operations
will work, however.)

\item {} 
\textbf{Logical} operations create logical values of either \code{TRUE} or
\code{FALSE}. To convert logical values to numerical values, use the
\code{as.integer()} command:

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZgt{} as.integer(TRUE)
   [1] 1
\PYGZgt{} as.integer(FALSE)
   [1] 0
\end{Verbatim}

\item {} 
\textbf{Character} values are text strings. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} text \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{supercalafragilisticxpaladocious\PYGZdq{}}
\PYG{o}{\PYGZgt{}} text
\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{supercalafragilisticxpaladocious\PYGZdq{}}
\end{Verbatim}

assigns the text string on the right-hand side of the \code{\textless{}-} to the
named object in your workspace. Text strings are primarily used with
data frames, described in the next section. R always returns
character strings in quotes.

\end{enumerate}


\subsubsection{Data Structures}
\label{docs/user_guide:id18}

\paragraph{Arrays}
\label{docs/user_guide:arrays}
Arrays are data structures that consist of only one type of scalar value
(e.g., a vector of character strings, or a matrix of numeric values).
The most common versions, one-dimensional and two-dimensional arrays,
are known as \emph{vectors} and \emph{matrices}, respectively.


\subparagraph{Ways to create arrays}
\label{docs/user_guide:ways-to-create-arrays}\begin{enumerate}
\item {} 
Common ways to create \textbf{vectors} (or one-dimensional arrays)
include:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} a \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{7}\PYG{p}{,} \PYG{l+m}{9}\PYG{p}{,} \PYG{l+m}{11}\PYG{p}{)}    \PYG{c+c1}{\PYGZsh{} Concatenates numeric values into a vector}
\PYG{o}{\PYGZgt{}} a \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{a\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{b\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{c\PYGZdq{}}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Concatenates character strings into a vector}
\PYG{o}{\PYGZgt{}} a \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{5}               \PYG{c+c1}{\PYGZsh{} Creates a vector of integers from 1 to 5 inclusive}
\PYG{o}{\PYGZgt{}} a \PYG{o}{\PYGZlt{}\PYGZhy{}} rep\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} times \PYG{o}{=} \PYG{l+m}{5}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Creates a vector of 5 repeated {}`1\PYGZsq{}s}
\end{Verbatim}

To manipulate a vector:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} a\PYG{p}{[}\PYG{l+m}{10}\PYG{p}{]}                \PYG{c+c1}{\PYGZsh{} Extracts the 10th value from the vector {}`a\PYGZsq{}}
\PYG{o}{\PYGZgt{}} a\PYG{p}{[}\PYG{l+m}{5}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{3.14}         \PYG{c+c1}{\PYGZsh{} Inserts 3.14 as the 5th value in the vector {}`a\PYGZsq{}}
\PYG{o}{\PYGZgt{}} a\PYG{p}{[}\PYG{l+m}{5}\PYG{o}{:}\PYG{l+m}{7}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{4}\PYG{p}{,} \PYG{l+m}{7}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Replaces the 5th through 7th values with 2, 4, and 7}
\end{Verbatim}

\emph{Unlike} larger arrays, vectors can be extended without first
creating another vector of the correct length. Hence,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} a \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{4}\PYG{p}{,} \PYG{l+m}{6}\PYG{p}{,} \PYG{l+m}{8}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} a\PYG{p}{[}\PYG{l+m}{5}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{9}       \PYG{c+c1}{\PYGZsh{} Inserts a 9 in the 5th position of the vector,}
                  \PYG{c+c1}{\PYGZsh{}  automatically inserting an {}`NA\PYGZsq{} values position 4}
\end{Verbatim}

\item {} 
{[}factors{]} A \textbf{factor vector} is a special type of vector that allows
users to create  indicator variables in one vector, rather
than using  dummy variables (as in Stata or SPSS). R creates
this special class of vector from a pre-existing vector x using the
factor() command, which separates x into levels based on the discrete
values observed in x. These values may be either integer value or
character strings. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{9}\PYG{p}{,} \PYG{l+m}{9}\PYG{p}{,} \PYG{l+m}{9}\PYG{p}{,} \PYG{l+m}{9}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} factor\PYG{p}{(}x\PYG{p}{)}
   \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} \PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{2} \PYG{l+m}{2} \PYG{l+m}{2} \PYG{l+m}{9} \PYG{l+m}{9} \PYG{l+m}{9} \PYG{l+m}{9}
   Levels\PYG{o}{:} \PYG{l+m}{1} \PYG{l+m}{2} \PYG{l+m}{9}
\end{Verbatim}

By default, factor() creates unordered factors, which are treated as
discrete, rather than ordered, levels. Add the optional argument
ordered = TRUE to order the factors in the vector:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{like\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{dislike\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{hate\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{like\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{don\PYGZsq{}t know\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{like\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{dislike\PYGZdq{}}\PYG{p}{)}
\PYG{o}{\PYGZgt{}} factor\PYG{p}{(}x\PYG{p}{,} levels \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{hate\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{dislike\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{like\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{don\PYGZsq{}t know\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
\PYG{o}{+}        ordered \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
  \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} like    dislike    hate    like   don\PYG{l+s}{\PYGZsq{}}\PYG{l+s}{t know   like   dislike}
\PYG{l+s}{Levels: hate \PYGZlt{} dislike \PYGZlt{} like \PYGZlt{} don\PYGZsq{}}t know
\end{Verbatim}

The factor() command orders the levels according to the order in the
optional argument levels. If you omit the levels command, R will
order the values as they occur in the vector. Thus, omitting the
levels argument sorts the levels as like \textless{} dislike \textless{} hate \textless{} don’t
know in the example above. If you omit one or more of the levels in
the list of levels, R returns levels values of NA for the missing
level(s):

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} factor\PYG{p}{(}x\PYG{p}{,} levels \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{hate\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{dislike\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{like\PYGZdq{}}\PYG{p}{)}\PYG{p}{,} ordered \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
  \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} like    dislike hate    like    \PYG{o}{\PYGZlt{}}\PYG{k+kc}{NA}\PYG{o}{\PYGZgt{}}    like    dislike
Levels\PYG{o}{:} hate \PYG{o}{\PYGZlt{}} dislike \PYG{o}{\PYGZlt{}} like
\end{Verbatim}

Use factored vectors within data frames for plotting (see ), to set
the values of the explanatory variables using setx (see ) and in the
ordinal logit and multinomial logit models (see ).

\item {} 
Build \textbf{matrices} (or two-dimensional arrays) from vectors
(one-dimensional arrays). You can create a matrix in two ways:
\begin{enumerate}
\item {} 
From a vector: Use the command \code{matrix(vector, nrow =}
\code{, ncol =} \code{)} to create a
 matrix from the vector by filling in the
columns from left to right. For example,

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} matrix\PYG{p}{(}c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{,}\PYG{l+m}{4}\PYG{p}{,}\PYG{l+m}{5}\PYG{p}{,}\PYG{l+m}{6}\PYG{p}{)}\PYG{p}{,} nrow \PYG{o}{=} \PYG{l+m}{2}\PYG{p}{,} ncol \PYG{o}{=} \PYG{l+m}{3}\PYG{p}{)}
        \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]}       \PYG{c+c1}{\PYGZsh{} Note that when assigning a vector to a}
   \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{1}    \PYG{l+m}{3}    \PYG{l+m}{5}       \PYG{c+c1}{\PYGZsh{}  matrix, none of the rows or columns}
   \PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{2}    \PYG{l+m}{4}    \PYG{l+m}{6}       \PYG{c+c1}{\PYGZsh{}  have names.}
\end{Verbatim}

\item {} 
From two or more vectors of length : Use \code{cbind()} to
combine  vectors vertically to form a 
matrix, or \code{rbind()} to combine  vectors horizontally
to form a  matrix. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{11}\PYG{p}{,} \PYG{l+m}{12}\PYG{p}{,} \PYG{l+m}{13}\PYG{p}{)}         \PYG{c+c1}{\PYGZsh{} Creates a vector {}`x\PYGZsq{} of 3 values.}
\PYG{o}{\PYGZgt{}} y \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{55}\PYG{p}{,} \PYG{l+m}{33}\PYG{p}{,} \PYG{l+m}{12}\PYG{p}{)}         \PYG{c+c1}{\PYGZsh{} Creates another vector {}`y\PYGZsq{} of 3 values.}
\PYG{o}{\PYGZgt{}} rbind\PYG{p}{(}x\PYG{p}{,} y\PYG{p}{)}                \PYG{c+c1}{\PYGZsh{} Creates a 2 x 3 matrix.  Note that row}
     \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]}          \PYG{c+c1}{\PYGZsh{}  1 is named x and row 2 is named y,}
   x   \PYG{l+m}{11}   \PYG{l+m}{12}   \PYG{l+m}{13}          \PYG{c+c1}{\PYGZsh{}  according to the order in which the}
   y   \PYG{l+m}{55}   \PYG{l+m}{33}   \PYG{l+m}{12}          \PYG{c+c1}{\PYGZsh{}  arguments were passed to rbind().}
\PYG{o}{\PYGZgt{}} cbind\PYG{p}{(}x\PYG{p}{,} y\PYG{p}{)}                \PYG{c+c1}{\PYGZsh{} Creates a 3 x 2 matrix.  Note that the}
         x  y                \PYG{c+c1}{\PYGZsh{}  columns are named according to the}
   \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]} \PYG{l+m}{11} \PYG{l+m}{55}                \PYG{c+c1}{\PYGZsh{}  order in which they were passed to}
   \PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]} \PYG{l+m}{12} \PYG{l+m}{33}                \PYG{c+c1}{\PYGZsh{}  cbind().}
   \PYG{p}{[}\PYG{l+m}{3}\PYG{p}{,}\PYG{p}{]} \PYG{l+m}{13} \PYG{l+m}{12}
\end{Verbatim}

\end{enumerate}

R supports a variety of matrix functions, including: \code{det()}, which
returns the matrix’s determinant; \code{t()}, which transposes the
matrix; \code{solve()}, which inverts the the matrix; and \code{\%\%}, which
multiplies two matricies. In addition, the \code{dim()} command returns
the dimensions of your matrix. As with vectors, square brackets
extract specific values from a matrix and the assignment mechanism
\code{\textless{}-} replaces values. For example:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} loo\PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]}             \PYG{c+c1}{\PYGZsh{} Extracts the third column of loo.}
\PYG{o}{\PYGZgt{}} loo\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]}             \PYG{c+c1}{\PYGZsh{} Extracts the first row of loo.}
\PYG{o}{\PYGZgt{}} loo\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{13}          \PYG{c+c1}{\PYGZsh{} Inserts 13 as the value for row 1, column 3.}
\PYG{o}{\PYGZgt{}} loo\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{2}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{)}     \PYG{c+c1}{\PYGZsh{} Replaces the first row of loo.}
\end{Verbatim}

If you encounter problems replacing rows or columns, make sure that
the \code{dims()} of the vector matches the \code{dims()} of the matrix you
are trying to replace.

\item {} 
An \textbf{n-dimensional array} is a set of stacked matrices of identical
dimensions. For example, you may create a three dimensional array
with dimensions  by stacking  matrices each
with  rows and  columns.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} a \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}\PYG{l+m}{8}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{)}       \PYG{c+c1}{\PYGZsh{} Creates a 2 x 3 matrix populated with 8\PYGZsq{}s.}
\PYG{o}{\PYGZgt{}} b \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}\PYG{l+m}{9}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{)}       \PYG{c+c1}{\PYGZsh{} Creates a 2 x 3 matrix populated with 9\PYGZsq{}s.}
\PYG{o}{\PYGZgt{}} array\PYG{p}{(}c\PYG{p}{(}a\PYG{p}{,} b\PYG{p}{)}\PYG{p}{,} c\PYG{p}{(}\PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{)}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Creates a 2 x 3 x 2 array with the first}
   \PYG{p}{,} \PYG{p}{,} \PYG{l+m}{1}                     \PYG{c+c1}{\PYGZsh{}  level [,,1] populated with matrix a (8\PYGZsq{}s),}
                             \PYG{c+c1}{\PYGZsh{}  and the second level [,,2] populated}
        \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]}       \PYG{c+c1}{\PYGZsh{}  with matrix b (9\PYGZsq{}s).}
   \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{8}    \PYG{l+m}{8}    \PYG{l+m}{8}
   \PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{8}    \PYG{l+m}{8}    \PYG{l+m}{8}       \PYG{c+c1}{\PYGZsh{} Use square brackets to extract values.  For}
                             \PYG{c+c1}{\PYGZsh{}  example, [1, 2, 2] extracts the second}
   \PYG{p}{,} \PYG{p}{,} \PYG{l+m}{2}                     \PYG{c+c1}{\PYGZsh{}  value in the first row of the second level.}
                             \PYG{c+c1}{\PYGZsh{} You may also use the \PYGZlt{}\PYGZhy{} operator to}
        \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]} \PYG{p}{[}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{]}       \PYG{c+c1}{\PYGZsh{}  replace values.}
   \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{9}    \PYG{l+m}{9}    \PYG{l+m}{9}
   \PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{p}{]}    \PYG{l+m}{9}    \PYG{l+m}{9}    \PYG{l+m}{9}
\end{Verbatim}

If an array is a one-dimensional vector or two-dimensional matrix, R
will treat the array using the more specific method.

\end{enumerate}

Three functions especially helpful for arrays:
\begin{itemize}
\item {} 
is() returns both the type of scalar value that populates the array,
as well as the specific type of array (vector, matrix, or array more
generally).

\item {} 
dims() returns the size of an array, where

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} dims\PYG{p}{(}b\PYG{p}{)}
 \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}  \PYG{l+m}{33}  \PYG{l+m}{5}
\end{Verbatim}

indicates that the array is two-dimensional (a matrix), and has 33
rows and 5 columns.

\item {} 
The single bracket \code{{[} {]}} indicates specific values in the array.
Use commas to indicate the index of the specific values you would
like to pull out or replace:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} dims\PYG{p}{(}a\PYG{p}{)}
 \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}  \PYG{l+m}{14}
\PYG{o}{\PYGZgt{}} a\PYG{p}{[}\PYG{l+m}{10}\PYG{p}{]}       \PYG{c+c1}{\PYGZsh{} Pull out the 10th value in the vector {}`a\PYGZsq{}}
\PYG{o}{\PYGZgt{}} dims\PYG{p}{(}b\PYG{p}{)}
 \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}  \PYG{l+m}{33}  \PYG{l+m}{5}
\PYG{o}{\PYGZgt{}} b\PYG{p}{[}\PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{12}\PYG{p}{,} \PYG{p}{]}   \PYG{c+c1}{\PYGZsh{} Pull out the first 12 rows of {}`b\PYGZsq{}}
\PYG{o}{\PYGZgt{}} c\PYG{p}{[}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{]}     \PYG{c+c1}{\PYGZsh{} Pull out the value in the first row, second column of {}`c\PYGZsq{}}
\PYG{o}{\PYGZgt{}} dims\PYG{p}{(}d\PYG{p}{)}
 \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]}  \PYG{l+m}{1000}  \PYG{l+m}{4}  \PYG{l+m}{5}
\PYG{o}{\PYGZgt{}} d\PYG{p}{[} \PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{]}  \PYG{c+c1}{\PYGZsh{} Pulls out a vector of 1,000 values}
\end{Verbatim}

\end{itemize}


\paragraph{Lists}
\label{docs/user_guide:lists}
Unlike arrays, which contain only one type of scalar value, lists are
flexible data structures that can contain heterogeneous value types and
heterogeneous data structures. Lists are so flexible that one list can
contain another list. For example, the list output can contain coef, a
vector of regression coefficients; variance, the variance-covariance
matrix; and another list terms that describes the data using character
strings. Use the names() function to view the named elements in a list,
and to extract a named element, use

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} names\PYG{p}{(}output\PYG{p}{)}
 \PYG{p}{[}\PYG{l+m}{1}\PYG{p}{]} coefficients   variance   terms
\PYG{o}{\PYGZgt{}} output\PYG{o}{\PYGZdl{}}coefficients
\end{Verbatim}

For lists where the elements are not named, use double square brackets
\code{{[}{[} {]}{]}} to extract elements:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} L\PYG{p}{[[}\PYG{l+m}{4}\PYG{p}{]]}      \PYG{c+c1}{\PYGZsh{} Extracts the 4th element from the list {}`L\PYGZsq{}}
\PYG{o}{\PYGZgt{}} L\PYG{p}{[[}\PYG{l+m}{4}\PYG{p}{]]} \PYG{o}{\PYGZlt{}\PYGZhy{}} b \PYG{c+c1}{\PYGZsh{} Replaces the 4th element of the list {}`L\PYGZsq{} with a matrix {}`b\PYGZsq{}}
\end{Verbatim}

Like vectors, lists are flexible data structures that can be extended
without first creating another list of with the correct number of
elements:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} L \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}\PYG{p}{)}                      \PYG{c+c1}{\PYGZsh{} Creates an empty list}
\PYG{o}{\PYGZgt{}} L\PYG{o}{\PYGZdl{}}coefficients \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{4}\PYG{p}{,} \PYG{l+m}{6}\PYG{p}{,} \PYG{l+m}{8}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} Inserts a vector into the list, and}
                                   \PYG{c+c1}{\PYGZsh{}  names that vector {}`coefficients\PYGZsq{}}
                   \PYG{c+c1}{\PYGZsh{}  within the list}
\PYG{o}{\PYGZgt{}} L\PYG{p}{[[}\PYG{l+m}{4}\PYG{p}{]]} \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} \PYG{l+m}{4}\PYG{p}{,} \PYG{l+m}{6}\PYG{p}{,} \PYG{l+m}{8}\PYG{p}{)}          \PYG{c+c1}{\PYGZsh{} Inserts the vector into the 4th position}
                                   \PYG{c+c1}{\PYGZsh{}  in the list.  If this list doesn\PYGZsq{}t}
                                   \PYG{c+c1}{\PYGZsh{}  already have 4 elements, the empty}
                                   \PYG{c+c1}{\PYGZsh{}  elements will be {}`NULL\PYGZsq{} values}
\end{Verbatim}

Alternatively, you can easily create a list using objects that already
exist in your workspace:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} L \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}coefficients \PYG{o}{=} k\PYG{p}{,} variance \PYG{o}{=} v\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Where {}`k\PYGZsq{} is a vector and}
                                            \PYG{c+c1}{\PYGZsh{}   {}`v\PYGZsq{} is a matrix}
\end{Verbatim}


\paragraph{Data Frames}
\label{docs/user_guide:data-frames}
A data frame (or data set) is a special type of list in which each
variable is constrained to have the same number of observations. A data
frame may contain variables of different types (numeric, integer,
logical, character, and factor), so long as each variable has the same
number of observations.

Thus, a data frame can use both matrix commands and list commands to
manipulate variables and observations.
.
. sourcecode:: r
\begin{quote}

\textgreater{} dat{[}1:10,{]}         \# Extracts observations 1-10 and all associated variables
\textgreater{} dat{[}dat\$grp == 1,{]} \# Extracts all observations that belong to group 1
\textgreater{} group \textless{}- dat\$grp   \# Saves the variable {\color{red}\bfseries{}{}`}grp' as a vector {\color{red}\bfseries{}{}`}group' in
\begin{quote}

\#   the workspace, not in the data frame
\end{quote}

\textgreater{} var4 \textless{}- dat{[}{[}4{]}{]}   \# Saves the 4th variable as a {\color{red}\bfseries{}{}`}var4' in the workspace
\end{quote}

For a comprehensive introduction to data frames and recoding data, see .


\paragraph{Identifying Objects and Data Structures}
\label{docs/user_guide:identifying-objects-and-data-structures}
Each data structure has several \emph{attributes} which describe it. Although
these attributes are normally invisible to users (e.g., not printed to
the screen when one types the name of the object), there are several
helpful functions that display particular attributes:
\begin{itemize}
\item {} 
For arrays, dims() returns the size of each dimension.

\item {} 
For arrays, is() returns the scalar value type and specific type of
array (vector, matrix, array). For more complex data structures, is()
returns the default methods (classes) for that object.

\item {} 
For lists and data frames, names() returns the variable names, and
str() returns the variable names and a short description of each
element.

\end{itemize}

For almost all data types, you may use summary() to get summary
statistics.


\subsection{Programming Statements}
\label{docs/user_guide:programming-statements}\label{docs/user_guide:userguide-programming-statements}
This chapter introduces the main programming commands. These include
functions, if-else statements, for-loops, and special procedures for
managing the inputs to statistical models.


\subsubsection{Functions}
\label{docs/user_guide:functions}
Functions are either built-in or user-defined sets of encapsulated
commands which may take any number of arguments. Preface a function with
the function statement and use the \textless{}- operator to assign functions to
objects in your workspace.

You may use functions to run the same procedure on different objects in
your workspace. For example,

\begin{Verbatim}[commandchars=\\\{\}]
check \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}p\PYG{p}{,} q\PYG{p}{)} \PYG{p}{\PYGZob{}}
 result \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{p}{(}p \PYG{o}{\PYGZhy{}} q\PYG{p}{)}\PYG{o}{/}q
 result
 \PYG{p}{\PYGZcb{}}
\end{Verbatim}

is a simple function with arguments p and q which calculates the
difference between the th elements of the vector p and the
th element of the vector q as a proportion of the
th element of q, and returns the resulting vector. For
example, check(p = 10, q = 2) returns 4. You may omit the descriptors as
long as you keep the arguments in the correct order: check(10, 2) also
returns 4. You may also use other objects as inputs to the function. If
again = 10 and really = 2, then check(p = again, q = really) and
check(again, really) also returns 4.

Because functions run commands as a set, you should make sure that each
command in your function works by testing each line of the function at
the R prompt.


\subsubsection{If-Statements}
\label{docs/user_guide:if-statements}
Use if (and optionally, else) to control the flow of R functions. For
example, let x and y be scalar numerical values:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kr}{if} \PYG{p}{(}x \PYG{o}{==} y\PYG{p}{)} \PYG{p}{\PYGZob{}}                \PYG{c+c1}{\PYGZsh{} If the logical statement in the ()\PYGZsq{}s is true,}
  x \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NA}                    \PYG{c+c1}{\PYGZsh{}  then {}`x\PYGZsq{} is changed to {}`NA\PYGZsq{} (missing value).}
\PYG{p}{\PYGZcb{}}
\PYG{k+kr}{else} \PYG{p}{\PYGZob{}}                       \PYG{c+c1}{\PYGZsh{} The {}`else\PYGZsq{} statement tells R what to do if}
  x \PYG{o}{\PYGZlt{}\PYGZhy{}} x\PYG{o}{\PYGZca{}}\PYG{l+m}{2}                   \PYG{c+c1}{\PYGZsh{}  the if\PYGZhy{}statement is false.}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

As with a function, use \{ and \} to define the set of commands associated
with each if and else statement. (If you include if statements inside
functions, you may have multiple sets of nested curly braces.)


\subsubsection{For-Loops}
\label{docs/user_guide:for-loops}
Use for to repeat (loop) operations. Avoiding loops by using matrix or
vector commands is usually faster and more elegant, but loops are
sometimes necessary to assign values. If you are using a loop to assign
values to a data structure, you must first initialize an empty data
structure to hold the values you are assigning.

Select a data structure compatible with the type of output your loop
will generate. If your loop generates a scalar, store it in a vector
(with the th value in the vector corresponding to the the
th run of the loop). If your loop generates vector output,
store them as rows (or columns) in a matrix, where the th row
(or column) corresponds to the th iteration of the loop. If
your output consists of matrices, stack them into an array. For list
output (such as regression output) or output that changes dimensions in
each iteration, use a list. To initialize these data structures, use:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} vector\PYG{p}{(}\PYG{p}{)}                          \PYG{c+c1}{\PYGZsh{} An empty vector of any length.}
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}\PYG{p}{)}                            \PYG{c+c1}{\PYGZsh{} An empty list of any length.}
\end{Verbatim}

The vector() and list() commands create a vector or list of any length,
such that assigning x{[}5{]} \textless{}- 15 automatically creates a vector with 5
elements, the first four of which are empty values (NA). In contrast,
the matrix() and array() commands create data structures that are
restricted to their original dimensions.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}nrow \PYG{o}{=} \PYG{l+m}{5}\PYG{p}{,} ncol \PYG{o}{=} \PYG{l+m}{2}\PYG{p}{)}  \PYG{c+c1}{\PYGZsh{} A matrix with 5 rows and 2 columns.}
\PYG{o}{\PYGZgt{}} x \PYG{o}{\PYGZlt{}\PYGZhy{}} array\PYG{p}{(}dim \PYG{o}{=} c\PYG{p}{(}\PYG{l+m}{5}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{,}\PYG{l+m}{3}\PYG{p}{)}\PYG{p}{)}       \PYG{c+c1}{\PYGZsh{} A 3D array of 3 stacked 5 by 2 matrices.}
\end{Verbatim}

If you attempt to assign a value at  to either of
these data structures, R will return an error message (“subscript is out
of bounds”). R does not automatically extend the dimensions of either a
matrix or an array to accommodate additional values.

\begin{Verbatim}[commandchars=\\\{\}]
x \PYG{o}{\PYGZlt{}\PYGZhy{}} array\PYG{p}{(}\PYG{p}{)}             \PYG{c+c1}{\PYGZsh{} Initializes an empty data structure.}
\PYG{k+kr}{for} \PYG{p}{(}i \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{10}\PYG{p}{)} \PYG{p}{\PYGZob{}}        \PYG{c+c1}{\PYGZsh{} Loops through every value from 1 to 10, replacing}
  \PYG{k+kr}{if} \PYG{p}{(}is.integer\PYG{p}{(}i\PYG{o}{/}\PYG{l+m}{2}\PYG{p}{)}\PYG{p}{)} \PYG{p}{\PYGZob{}} \PYG{c+c1}{\PYGZsh{}  the even values in {}`x\PYGZsq{} with i+5.}
    x\PYG{p}{[}i\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} i \PYG{o}{+} \PYG{l+m}{5}
  \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}                        \PYG{c+c1}{\PYGZsh{} Enclose multiple commands in \PYGZob{}\PYGZcb{}.}
\end{Verbatim}

You may use for() inside or outside of functions.

Example 2: Creating dummy variables by hand
!!!

You may also use a loop to create a matrix of dummy variables to append
to a data frame. For example, to generate fixed effects for each state,
let’s say that you have mydata which contains y, x1, x2, x3, and state,
with state a character variable with 50 unique values. There are three
ways to create dummy variables: 1) with a built-in R command; 2) with
one loop; or 3) with 2 for loops.
\begin{enumerate}
\item {} 
R will create dummy variables on the fly from a single variable with
distinct values.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}y \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2 \PYG{o}{+} x3 \PYG{o}{+} as.factor\PYG{p}{(}state\PYG{p}{)}\PYG{p}{,}
                 data \PYG{o}{=} mydata\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

This method returns  indicators for  states.

\item {} 
Alternatively, you can use a loop to create dummy variables by hand.
There are two ways to do this, but both start with the same initial
commands. Using vector commands, first create an index of for the
states, and initialize a matrix to hold the dummy variables:

\begin{Verbatim}[commandchars=\\\{\}]
idx \PYG{o}{\PYGZlt{}\PYGZhy{}} sort\PYG{p}{(}unique\PYG{p}{(}mydata\PYG{o}{\PYGZdl{}}state\PYG{p}{)}\PYG{p}{)}
dummy \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}\PYG{k+kc}{NA}\PYG{p}{,} nrow \PYG{o}{=} nrow\PYG{p}{(}mydata\PYG{p}{)}\PYG{p}{,} ncol \PYG{o}{=} length\PYG{p}{(}idx\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

Now choose between the two methods.
\begin{enumerate}
\item {} 
The first method is computationally inefficient, but more
intuitive for users not accustomed to vector operations. The first
loop uses i as in index to loop through all the rows, and the
second loop uses j to loop through all 50 values in the vector
idx, which correspond to columns 1 through 50 in the matrix dummy.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kr}{for} \PYG{p}{(}i \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}nrow\PYG{p}{(}mydata\PYG{p}{)}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{k+kr}{for} \PYG{p}{(}j \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}length\PYG{p}{(}idx\PYG{p}{)}\PYG{p}{)} \PYG{p}{\PYGZob{}}
    \PYG{k+kr}{if} \PYG{p}{(}mydata\PYG{o}{\PYGZdl{}}state\PYG{p}{[}i\PYG{p}{,}j\PYG{p}{]} \PYG{o}{==} idx\PYG{p}{[}j\PYG{p}{]}\PYG{p}{)} \PYG{p}{\PYGZob{}}
      dummy\PYG{p}{[}i\PYG{p}{,}j\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{1}
    \PYG{p}{\PYGZcb{}}
    \PYG{k+kr}{else} \PYG{p}{\PYGZob{}}
      dummy\PYG{p}{[}i\PYG{p}{,}j\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{0}
    \PYG{p}{\PYGZcb{}}
  \PYG{p}{\PYGZcb{}}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

Then add the new matrix of dummy variables to your data frame:

\begin{Verbatim}[commandchars=\\\{\}]
names\PYG{p}{(}dummy\PYG{p}{)} \PYG{o}{\PYGZlt{}\PYGZhy{}} idx
mydata \PYG{o}{\PYGZlt{}\PYGZhy{}} cbind\PYG{p}{(}mydata\PYG{p}{,} dummy\PYG{p}{)}
\end{Verbatim}

\item {} 
As you become more comfortable with vector operations, you can
replace the double loop procedure above with one loop:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{k+kr}{for} \PYG{p}{(}j \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}length\PYG{p}{(}idx\PYG{p}{)}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  dummy\PYG{p}{[}\PYG{p}{,}j\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} as.integer\PYG{p}{(}mydata\PYG{o}{\PYGZdl{}}state \PYG{o}{==} idx\PYG{p}{[}j\PYG{p}{]}\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

The single loop procedure evaluates each element in idx against
the vector mydata\$state. This creates a vector of 
TRUE/FALSE observations, which you may transform to 1’s and 0’s
using as.integer(). Assign the resulting vector to the appropriate
column in dummy. Combine the dummy matrix with the data frame as
above to complete the procedure.

\end{enumerate}

\end{enumerate}

Selecting the by option in zelig() partitions the data frame and then
automatically loops the specified model through each partition. Suppose
that mydata is a data frame with variables y, x1, x2, x3, and state,
with state a factor variable with 50 unique values. Let’s say that you
would like to run a weighted regression where each observation is
weighted by the inverse of the standard error on x1, estimated for that
observation’s state. In other words, we need to first estimate the model
for each of the 50 states, calculate 1 / se(x1) for each
state , and then assign these weights to each
observation in mydata.
\begin{itemize}
\item {} 
Estimate the model separate for each state using the by option in
zelig():

\begin{Verbatim}[commandchars=\\\{\}]
z.out \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}y \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2 \PYG{o}{+} x3\PYG{p}{,} by \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{state\PYGZdq{}}\PYG{p}{,} data \PYG{o}{=} mydata\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

Now z.out is a list of 50 regression outputs.

\item {} 
Extract the standard error on x1 for each of the state level
regressions.

\begin{Verbatim}[commandchars=\\\{\}]
se \PYG{o}{\PYGZlt{}\PYGZhy{}} array\PYG{p}{(}\PYG{p}{)}                          \PYG{c+c1}{\PYGZsh{} Initalize the empty data structure.}
\PYG{k+kr}{for} \PYG{p}{(}i \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{50}\PYG{p}{)} \PYG{p}{\PYGZob{}}                      \PYG{c+c1}{\PYGZsh{} vcov() creates the variance matrix}
  se\PYG{p}{[}i\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} sqrt\PYG{p}{(}vcov\PYG{p}{(}z.out\PYG{p}{[[}i\PYG{p}{]]}\PYG{p}{)}\PYG{p}{[}\PYG{l+m}{2}\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Since we have an intercept, the 2nd}
\PYG{p}{\PYGZcb{}}                                      \PYG{c+c1}{\PYGZsh{} diagonal value corresponds to x1.}
\end{Verbatim}

\item {} 
Create the vector of weights.

\begin{Verbatim}[commandchars=\\\{\}]
wts \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{1} \PYG{o}{/} se
\end{Verbatim}

This vector wts has 50 values that correspond to the 50 sets of
state-level regression output in z.out.

\item {} 
To assign the vector of weights to each observation, we need to match
each observation’s state designation to the appropriate state. For
simplicity, assume that the states are numbered 1 through 50.

\begin{Verbatim}[commandchars=\\\{\}]
mydata\PYG{o}{\PYGZdl{}}w \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NA}            \PYG{c+c1}{\PYGZsh{} Initalizing the empty variable}
\PYG{k+kr}{for} \PYG{p}{(}i \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}\PYG{l+m}{50}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  mydata\PYG{o}{\PYGZdl{}}w\PYG{p}{[}mydata\PYG{o}{\PYGZdl{}}state \PYG{o}{==} i\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} wts\PYG{p}{[}i\PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

We use mydata\$state as the index (inside the square brackets) to
assign values to mydata\$w. Thus, whenever state equals 5 for an
observation, the loop assigns the fifth value in the vector wts to
the variable w in mydata. If we had 500 observations in mydata, we
could use this method to match each of the 500 observations to the
appropriate wts.

If the states are character strings instead of integers, we can use a
slightly more complex version

\begin{Verbatim}[commandchars=\\\{\}]
mydata\PYG{o}{\PYGZdl{}}w \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NA}
idx \PYG{o}{\PYGZlt{}\PYGZhy{}} sort\PYG{p}{(}unique\PYG{p}{(}mydata\PYG{o}{\PYGZdl{}}state\PYG{p}{)}\PYG{p}{)}
\PYG{k+kr}{for} \PYG{p}{(}i \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}length\PYG{p}{(}idx\PYG{p}{)} \PYG{p}{\PYGZob{}}
  mydata\PYG{o}{\PYGZdl{}}w\PYG{p}{[}mydata\PYG{o}{\PYGZdl{}}state \PYG{o}{==} idx\PYG{p}{[}i\PYG{p}{]]} \PYG{o}{\PYGZlt{}\PYGZhy{}} wts\PYG{p}{[}i\PYG{p}{]}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

\item {} 
Now we can run our weighted regression:

\begin{Verbatim}[commandchars=\\\{\}]
z.wtd \PYG{o}{\PYGZlt{}\PYGZhy{}} zelig\PYG{p}{(}y \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2 \PYG{o}{+} x3\PYG{p}{,} weights \PYG{o}{=} w\PYG{p}{,} data \PYG{o}{=} mydata\PYG{p}{,}
               model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{ls\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\end{itemize}


\section{Developer Guide}
\label{docs/dev_guide::doc}\label{docs/dev_guide:developer-guide}\label{docs/dev_guide:devguide}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\begin{itemize}
\item {} 
{\hyperref[docs/dev_guide:writing-new-models]{Writing New Models}}
\begin{itemize}
\item {} 
{\hyperref[docs/dev_guide:managing-statistical-model-inputs]{Managing Statistical Model Inputs}}

\item {} 
{\hyperref[docs/dev_guide:easy-ways-to-manage-matrices]{Easy Ways to Manage Matrices}}

\end{itemize}

\item {} 
{\hyperref[docs/dev_guide:adding-models-and-methods-to-zelig]{Adding Models and Methods to Zelig}}
\begin{itemize}
\item {} 
{\hyperref[docs/dev_guide:making-the-model-compatible-with-zelig]{Making the Model Compatible with Zelig}}

\item {} 
{\hyperref[docs/dev_guide:getting-ready-for-the-gui]{Getting Ready for the GUI}}

\item {} 
{\hyperref[docs/dev_guide:formatting-reference-manual-pages]{Formatting Reference Manual Pages}}

\end{itemize}

\end{itemize}
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\subsection{Writing New Models}
\label{docs/dev_guide:writing-new-models}\label{docs/dev_guide:devguide-writing-new-models}
With Zelig, writing a new model in R is straightforward. (If you already
have a model, see Chapter {[}c:addingmodels{]} for how to include it in
Zelig.) With tools to streamline user inputs, writing a new model does
not require a lot of programming knowledge, but lets developers focus on
the model’s math. Generally, writing a new statistical procedure or
model comes in orderly steps:
\begin{enumerate}
\item {} 
Write down the mathematical model. Define the parameters that you
need, grouping parameters into convenient vectors or matrices
whenever possible (this will make your code clearer).

\item {} 
Write the code.

\item {} 
Test the code (usually using Monte Carlo data, where you know the
true values being estimated ) and make sure that it works as
expected.

\item {} 
Write some documentation explaining your model and the functions that
run your model.

\end{enumerate}

Somewhere between steps {[}1{]} and {[}2{]}, you will need to translate input
data into the mathematical notation that you used to write down the
model. Rather than repeating whole blocks of code, use functions to
streamline the number of commands that users will need to run your
model.

With more steps being performed by fewer commands, the inputs to these
commands become more sophisticated. The structure of those inputs
actually matters quite a lot. If your function has a convoluted syntax,
it will be difficult to use, difficult to explain, and difficult to
document. If your function is easy to use and has an intuitive syntax,
however, it will be easy to explain and document, which will make your
procedure more accessible to all users.


\subsubsection{Managing Statistical Model Inputs}
\label{docs/dev_guide:managing-statistical-model-inputs}
Most statistical models require a matrix of explanatory variables and a
matrix of dependent variables. Rather than have users create matrices
themselves, R has a convenient user interface to create matrices of
response and explanatory variables on the fly. Users simply specify a
formula in the form of \code{dependent \textasciitilde{} explanatory variables}, and
developers use the following functions to transform the formula into the
appropriate matrices. Let mydata be a data frame.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} formula \PYG{o}{\PYGZlt{}\PYGZhy{}} y \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2                   \PYG{c+c1}{\PYGZsh{} User input}

\PYG{c+c1}{\PYGZsh{} Given the formula above, programmers can use the following standard commands}
\PYG{o}{\PYGZgt{}} D \PYG{o}{\PYGZlt{}\PYGZhy{}} model.frame\PYG{p}{(}formula\PYG{p}{,} data \PYG{o}{=} mydata\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} Subset \PYGZam{} listwise deletion}
\PYG{o}{\PYGZgt{}} X \PYG{o}{\PYGZlt{}\PYGZhy{}} model.matrix\PYG{p}{(}formula\PYG{p}{,} data \PYG{o}{=} D\PYG{p}{)}     \PYG{c+c1}{\PYGZsh{} Creates X matrix}
\PYG{o}{\PYGZgt{}} Y \PYG{o}{\PYGZlt{}\PYGZhy{}} model.response\PYG{p}{(}D\PYG{p}{)}                   \PYG{c+c1}{\PYGZsh{} Creates Y matrix}
\end{Verbatim}

where
\begin{itemize}
\item {} 
D is a subset of mydata that contains only the variables specified in
the formula (y, x1, and x2) with listwise deletion performed on the
subset data frame;

\item {} 
X is a matrix that contains a column of 1’s, and the explanatory
variables x1 and x2 from D; and

\item {} 
Y is a matrix containing the dependent variable(s) from D.

\end{itemize}

Depending on the model, Y may be a column vector, matrix, or other data
structure.


\paragraph{Describe the Statistical Model}
\label{docs/dev_guide:describe-the-statistical-model}
After setting up the  matrix, the next step for most models
will be to identify the corresponding vector of parameters. For a single
response variable model with no ancillary parameters, the standard R
interface is quite convenient: given , the model’s parameters
are simply .

There are very few models, however, that fall into this category. Even
Normal regression, for example, has two sets of parameters 
and . In order to make the R formula format more
flexible, Zelig has an additional set of tools that lets you describe
the inputs to your model (for multiple sets of parameters).

After you have written down the statistical model, identify the
parameters in your model. With these parameters in mind, the first step
is to write a describe.*() function for your model. If your model is
called mymodel, then the describe.mymodel() function takes no arguments
and returns a list with the following information:
\begin{itemize}
\item {} 
category: a character string that describes the dependent variable.
See for the current list of available categories.

\item {} 
parameters: a list containing parameter sets used in your model. For
each parameter (e.g., theta), you need to provide the following
information:
\begin{itemize}
\item {} 
equations: an integer number of equations for the parameter. For
parameters that can take, for example, two to four equations, use
c(2, 4).

\item {} 
tagsAllowed: a logical value (TRUE/FALSE) specifying whether a
given parameter allows constraints.

\item {} 
depVar: a logical value (TRUE/FALSE) specifying whether a
parameter requires a corresponding dependent variable.

\item {} 
expVar: a logical value (TRUE/FALSE) specifying whether a
parameter allows explanatory variables.

\end{itemize}

\end{itemize}

(See for examples and additional arguments output by
describe.mymodel().)


\paragraph{Single Response Variable Models: Normal Regression Model}
\label{docs/dev_guide:single-response-variable-models-normal-regression-model}
Let’s say that you are trying to write a Normal regression model with
stochastic component

with scalar variance parameter , and systematic
component . This implies two sets of
parameters in your model, and the following describe.normal.regression()
function:

\begin{Verbatim}[commandchars=\\\{\}]
describe.normal.regression \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  category \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{continuous\PYGZdq{}}
  mu \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{,}              \PYG{c+c1}{\PYGZsh{} Systematic component}
             tagsAllowed \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}
             depVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             expVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
  sigma2 \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{,}          \PYG{c+c1}{\PYGZsh{} Scalar ancillary parameter}
                 tagsAllowed \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}
                 depVar \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}
                 expVar \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{)}
  pars \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}mu \PYG{o}{=} mu\PYG{p}{,} sigma2 \PYG{o}{=} sigma2\PYG{p}{)}
  list\PYG{p}{(}category \PYG{o}{=} category\PYG{p}{,} parameters \PYG{o}{=} pars\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

To find the log-likelihood:

In R code, this translates to:

\begin{Verbatim}[commandchars=\\\{\}]
ll.normal \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}par\PYG{p}{,} X\PYG{p}{,} Y\PYG{p}{,} n\PYG{p}{,} terms\PYG{p}{)} \PYG{p}{\PYGZob{}}
  beta \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu\PYGZdq{}}\PYG{p}{)}             \PYG{c+c1}{\PYGZsh{} [1]}
  gamma \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{sigma2\PYGZdq{}}\PYG{p}{)}        \PYG{c+c1}{\PYGZsh{} [2]}
  sigma2 \PYG{o}{\PYGZlt{}\PYGZhy{}} exp\PYG{p}{(}gamma\PYG{p}{)}
  \PYG{l+m}{\PYGZhy{}0.5} \PYG{o}{*} \PYG{p}{(}n \PYG{o}{*} log\PYG{p}{(}sigma2\PYG{p}{)} \PYG{o}{+} sum\PYG{p}{(}\PYG{p}{(}Y \PYG{o}{\PYGZhy{}} X \PYG{o}{\PYGZpc{}*\PYGZpc{}} beta\PYG{p}{)}\PYG{o}{\PYGZca{}}\PYG{l+m}{2} \PYG{o}{/} sigma2\PYG{p}{)}\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

At Comment {[}1{]} above, we use the function parse.par() to pull out the
vector of parameters beta (which relate the systematic component
 to the explanatory variables ). No matter how
many covariates there are, the parse.par() function can use terms to
pull out the appropriate parameters from par. We also use parse.par() at
Comment {[}2{]} to pull out the scalar ancillary parameter that (after
transformation) corresponds to the  parameter.

To optimize this function, simply type:

\begin{Verbatim}[commandchars=\\\{\}]
out \PYG{o}{\PYGZlt{}\PYGZhy{}} optim\PYG{p}{(}start.val\PYG{p}{,} ll.normal\PYG{p}{,} control \PYG{o}{=} list\PYG{p}{(}fnscale \PYG{o}{=} \PYG{l+m}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{,}
             method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BFGS\PYGZdq{}}\PYG{p}{,} hessian \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,} X \PYG{o}{=} X\PYG{p}{,} Y \PYG{o}{=} Y\PYG{p}{,} terms \PYG{o}{=} terms\PYG{p}{)}
\end{Verbatim}

where
\begin{itemize}
\item {} 
start.val is a vector of starting values for par. Use set.start() to
create starting values for all parameters, systematic and ancillary,
in one step.

\item {} 
ll.normal is the log-likelihood function derived above.

\item {} 
“BFGS” specifies unconstrained optimization using a quasi-Newton
method.

\item {} 
control = list(fnscale = -1) specifies that R should maximize the
function (omitting this causes R to minimize the function by
default).

\item {} 
hessian = TRUE instructs R to return the Hessian matrix (from which
you may calculate the variance-covariance matrix).

\item {} 
X and Y are the matrix of explanatory variables and vector of
dependent variables, used in the ll.normal() function.

\item {} 
terms are meta-data constructed from the model.frame() command.

\end{itemize}

Please refer to the R-help for optim() for more options.

To make this procedure generalizable, we can write a function that takes
a user-specified data frame and formula, and optional starting values
for the optimization procedure:

\begin{Verbatim}[commandchars=\\\{\}]
normal.regression \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}formula\PYG{p}{,} data\PYG{p}{,} start.val \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{,} \PYG{k+kc}{...}\PYG{p}{)} \PYG{p}{\PYGZob{}}

  fml \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.formula\PYG{p}{(}formula\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{normal.regression\PYGZdq{}}\PYG{p}{)} \PYG{c+c1}{\PYGZsh{} [1]}
  D \PYG{o}{\PYGZlt{}\PYGZhy{}} model.frame\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} data\PYG{p}{)}
  X \PYG{o}{\PYGZlt{}\PYGZhy{}} model.matrix\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} D\PYG{p}{)}
  Y \PYG{o}{\PYGZlt{}\PYGZhy{}} model.response\PYG{p}{(}D\PYG{p}{)}
  terms \PYG{o}{\PYGZlt{}\PYGZhy{}} attr\PYG{p}{(}D\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{terms\PYGZdq{}}\PYG{p}{)}
  n \PYG{o}{\PYGZlt{}\PYGZhy{}} nrow\PYG{p}{(}X\PYG{p}{)}

  start.val \PYG{o}{\PYGZlt{}\PYGZhy{}} set.start\PYG{p}{(}start.val\PYG{p}{,} terms\PYG{p}{)}

  res \PYG{o}{\PYGZlt{}\PYGZhy{}} optim\PYG{p}{(}start.val\PYG{p}{,} ll.normal\PYG{p}{,} method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BFGS\PYGZdq{}}\PYG{p}{,}
               hessian \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,} control \PYG{o}{=} list\PYG{p}{(}fnscale \PYG{o}{=} \PYG{l+m}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{,}
               X \PYG{o}{=} X\PYG{p}{,} Y \PYG{o}{=} Y\PYG{p}{,} n \PYG{o}{=} n\PYG{p}{,} terms \PYG{o}{=} terms\PYG{p}{,} \PYG{k+kc}{...}\PYG{p}{)}      \PYG{c+c1}{\PYGZsh{} [2]}

  fit \PYG{o}{\PYGZlt{}\PYGZhy{}} model.end\PYG{p}{(}res\PYG{p}{,} D\PYG{p}{)}                                   \PYG{c+c1}{\PYGZsh{} [3]}
  fit\PYG{o}{\PYGZdl{}}n \PYG{o}{\PYGZlt{}\PYGZhy{}} n
  class\PYG{p}{(}fit\PYG{p}{)} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{normal\PYGZdq{}}                                     \PYG{c+c1}{\PYGZsh{} [4]}
  fit
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

The following comments correspond to the bracketed numbers above:
\begin{enumerate}
\item {} 
The parse.formula() command looks for the
describe.normal.regression() function, which changes the
user-specified formula into the following format:

\begin{Verbatim}[commandchars=\\\{\}]
list\PYG{p}{(}mu \PYG{o}{=} formula\PYG{p}{,}         \PYG{c+c1}{\PYGZsh{} where {}`formula\PYGZsq{} was specified by the user}
     sigma \PYG{o}{=} \PYG{o}{\PYGZti{}} \PYG{l+m}{1}\PYG{p}{)}
\end{Verbatim}

\item {} 
The … here indicate that if the user enters any additional arguments
when calling normal.regression(), that those arguments should go to
the optim() function.

\item {} 
The model.end() function takes the optimized output and the listwise
deleted data frame D and creates an object that will work with
setx().

\item {} 
Choose a class for your model output so that you will be able to
write an appropriate summary(), param(), and qi() function for your
model.

\end{enumerate}


\paragraph{Multivariate models: Bivariate Normal example}
\label{docs/dev_guide:multivariate-models-bivariate-normal-example}
Most common models have one systematic component. For 
observations, the systematic component varies over observations
. In the case of the Normal regression model, the systematic
component is  ( is not estimated as a
function of covariates).

In some cases, however, your model may have more than one systematic
component. In the case of bivariate probit, we have a dependent variable
 observed as (0,0), (1,0), (0,1), or (1,1)
for . Similar to a single-response probit model,
the stochastic component is described by two latent (unobserved)
continuous variables (, ) which follow
the bivariate Normal distribution:

where for ,  is the mean for
 and  is a correlation parameter. The
following observation mechanism links the observed dependent variables,
, with these latent variables

The systemic components for each observation are

In the default specification,  is a scalar (such that
 only contains an intercept term).

If so, we have two sets of parameters:  and . This implies the following
describe.bivariate.probit() function:

\begin{Verbatim}[commandchars=\\\{\}]
describe.bivariate.probit \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  category \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{dichotomous\PYGZdq{}}
  package \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}name \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mvtnorm\PYGZdq{}}\PYG{p}{,}       \PYG{c+c1}{\PYGZsh{} Required package and}
                  version \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{0.7\PYGZdq{}}\PYG{p}{)}        \PYG{c+c1}{\PYGZsh{}  minimum version number}
  mu \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{2}\PYG{p}{,}               \PYG{c+c1}{\PYGZsh{} Systematic component has 2}
             tagsAllowed \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}          \PYG{c+c1}{\PYGZsh{}  required equations}
             depVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,}
             expVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}\PYG{p}{,}
  rho \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}equations \PYG{o}{=} \PYG{l+m}{1}\PYG{p}{,}              \PYG{c+c1}{\PYGZsh{} Optional systematic component}
             tagsAllowed \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}         \PYG{c+c1}{\PYGZsh{}   (estimated as an ancillary}
             depVar \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}              \PYG{c+c1}{\PYGZsh{}    parameter by default)}
             expVar \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}\PYG{p}{,}
  pars \PYG{o}{\PYGZlt{}\PYGZhy{}} parameters\PYG{p}{(}mu \PYG{o}{=} mu\PYG{p}{,} rho \PYG{o}{=} rho\PYG{p}{)}
  list\PYG{p}{(}category \PYG{o}{=} category\PYG{p}{,} package \PYG{o}{=} package\PYG{p}{,} parameters \PYG{o}{=} pars\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

Since users may choose different explanatory variables to parameterize
 and  (and sometimes ), the
model requires a minimum of \emph{two} formulas. For example,

\begin{Verbatim}[commandchars=\\\{\}]
formulae \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}mu1 \PYG{o}{=} y1 \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2\PYG{p}{,}                         \PYG{c+c1}{\PYGZsh{} User input}
                 mu2 \PYG{o}{=} y2 \PYG{o}{\PYGZti{}} x2 \PYG{o}{+} x3\PYG{p}{)}
fml \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.formula\PYG{p}{(}formulae\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{bivariate.probit\PYGZdq{}}\PYG{p}{)}   \PYG{c+c1}{\PYGZsh{} [1]}
D \PYG{o}{\PYGZlt{}\PYGZhy{}} model.frame\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} mydata\PYG{p}{)}
X \PYG{o}{\PYGZlt{}\PYGZhy{}} model.matrix\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} D\PYG{p}{)}
Y \PYG{o}{\PYGZlt{}\PYGZhy{}} model.response\PYG{p}{(}D\PYG{p}{)}
\end{Verbatim}

At comment {[}1{]}, parse.formula() finds the describe.bivariate.probit()
function and parses the formulas accordingly.

If  takes covariates (and becomes a systematic component
rather than an ancillary parameter), there can be three sets of
explanatory variables:

\begin{Verbatim}[commandchars=\\\{\}]
formulae \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}mu1 \PYG{o}{=} y1 \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2\PYG{p}{,}
                 mu2 \PYG{o}{=} y2 \PYG{o}{\PYGZti{}} x2 \PYG{o}{+} x3\PYG{p}{,}
                 rho \PYG{o}{=} \PYG{o}{\PYGZti{}} x4 \PYG{o}{+} x5\PYG{p}{)}
\end{Verbatim}

From the perspective of the programmer, a nearly identical framework
works for both single and multiple equation models. The
(parse.formula()) line changes the class of fml from “list” to
“multiple” and hence ensures that model.frame() and model.matrix() go to
the appropriate methods. D, X , and Y are analogous to their single
equation counterparts above:
\begin{itemize}
\item {} 
D is the subset of mydata containing the variables y1, y2, x1, x2,
and x3 with listwise deletion performed on the subset;

\item {} 
X is a matrix corresponding to the explanatory variables, in one of
three forms discussed below (see ).

\item {} 
Y is an  matrix (where  here) with
columns (y1, y2) corresponding to the outcome variables on the
left-hand sides of the formulas.

\end{itemize}

Given for the bivariate probit probability density described above, the
likelihood is:

where I is an indicator function and
\begin{itemize}
\item {} 


\item {} 


\item {} 


\item {} 


\end{itemize}

This implies the following log-likelihood:

(For the corresponding R code, see below.)


\subsubsection{Easy Ways to Manage Matrices}
\label{docs/dev_guide:easy-ways-to-manage-matrices}
Most statistical methods relate explanatory variables  to a
dependent variable of interest  for each observation
. Let  be a set of parameters that correspond to
each column in , which is an  matrix with
rows . For a single equation model, the linear predictor is

Thus,  is the set of  for
 and is usually represented as an
 matrix.

For a two equation model such as bivariate probit, the linear predictor
becomes a matrix with columns corresponding to each dependent variable
:

With  as an  matrix, we now have a few
choices as to how to create the linear predictor:
\begin{enumerate}
\item {} 
An \textbf{intuitive} layout, which stacks matrices of explanatory
variables, provides an easy visual representation of the relationship
between explanatory variables and coefficients;

\item {} 
A \textbf{computationally-efficient} layout, which takes advantage of
computational vectorization; and

\item {} 
A \textbf{memory-saving} layout, which reduces the overall size of the
 and  matrices.

\end{enumerate}

Using the simple tools described in this section, you can pick the best
matrix management method for your model.

In addition, the way in which  is created also affects the
way parameters are estimated. Let’s say that you want two parameters to
have the same effect in different equations. By setting up  and
 in a certain way, you can let users set constraints across
parameters. Continuing the bivariate probit example above, let the model
specification be:

\begin{Verbatim}[commandchars=\\\{\}]
formulae \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}mu1 \PYG{o}{=} y1 \PYG{o}{\PYGZti{}} x1 \PYG{o}{+} x2 \PYG{o}{+} tag\PYG{p}{(}x3\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{land\PYGZdq{}}\PYG{p}{)}\PYG{p}{,}
                 mu2 \PYG{o}{=} y2 \PYG{o}{\PYGZti{}} x3 \PYG{o}{+} tag\PYG{p}{(}x4\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{land\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

where tag() is a special function that constrains variables to have the
same effect across equations. Thus, the coefficient for x3 in equation
mu1 is constrained to be equal to the coefficient for x4 in equation
mu2, and this effect is identified as the “land” effect in both
equations. In order to consider constraints across equations, the
structure of both  and  matter.


\paragraph{The Intuitive Layout}
\label{docs/dev_guide:the-intuitive-layout}
A stacked matrix of  and vector  is probably the
most visually intuitive configuration. Let  be the number
of equations in the bivariate probit model, and let  be the
total number of unique covariates in both equations. Choosing
model.matrix(…, shape = “stacked”) yields a  matrix of explanatory variables. Again, let 
be an  vector representing variable x1, 
x2, and so forth. Then

Correspondingly,  is a vector with elements

where  are the intercept terms for equation
. Since  is  and  is
, the resulting linear predictor  is
also stacked into a  matrix. Although difficult to manipulate (since observations are
indexed by  and  for each 
rather than just ), it is easy to see that we have turned the
two equations into one big  matrix and one long vector
, which is directly analogous to the familiar
single-equation .


\paragraph{The Computationally-Efficient Layout}
\label{docs/dev_guide:the-computationally-efficient-layout}
Choosing array  and vector  is probably the the
most computationally-efficient configuration: model.matrix(…, shape =
“array”) produces an  array where  is the total number of equations and
 is the total number of parameters across all the equations.
Since some parameter values may be constrained across equations,
. If a variable is not in a certain equation, it is
observed as a vector of 0s. With this option, each
  matrix becomes:

By stacking each of these  matrices along the first
dimension, we get  as an array with dimensions
.

Correspondingly,  is a vector with elements

To multiply the  array with dimensions
 and the  
vector, we \emph{vectorize} over equations as follows:

\begin{Verbatim}[commandchars=\\\{\}]
eta \PYG{o}{\PYGZlt{}\PYGZhy{}} apply\PYG{p}{(}X\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZpc{}*\PYGZpc{}\PYGZsq{}}\PYG{p}{,} beta\PYG{p}{)}
\end{Verbatim}

The linear predictor eta is therefore a  matrix.


\paragraph{The Memory-Efficient Layout}
\label{docs/dev_guide:the-memory-efficient-layout}
Choosing a “compact”  matrix and matrix  is
probably the most memory-efficient configuration: model.matrix(…, shape
= “compact”) (the default) produces an  matrix, where
 is the number of unique variables (5 in this case) \footnote{
Why 5? In addition to the intercept term (a variable which is the
same in either equation, and so counts only as one variable), the
\emph{unique} variables are , , , and
.
} in all
of the equations. Let  be an  vector
representing variable x1,  x2, and so forth.

The  parameter is used twice to implement
the constraint, and the number of empty cells is minimized by
implementing the constraints in  rather than .
Furthermore, since  is  and 
is ,  is .


\paragraph{Interchanging the Three Methods}
\label{docs/dev_guide:interchanging-the-three-methods}
Continuing the bivariate probit example above, we only need to modify a
few lines of code to put these different schemes into effect. Using the
default (memory-efficient) options, the log-likelihood is:

\begin{Verbatim}[commandchars=\\\{\}]
bivariate.probit \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}formula\PYG{p}{,} data\PYG{p}{,} start.val \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{,} \PYG{k+kc}{...}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  fml \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.formula\PYG{p}{(}formula\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{bivariate.probit\PYGZdq{}}\PYG{p}{)}
  D \PYG{o}{\PYGZlt{}\PYGZhy{}} model.frame\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} data\PYG{p}{)}
  X \PYG{o}{\PYGZlt{}\PYGZhy{}} model.matrix\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} D\PYG{p}{,} eqn \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}       \PYG{c+c1}{\PYGZsh{} [1]}
  Xrho \PYG{o}{\PYGZlt{}\PYGZhy{}} model.matrix\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} D\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{rho\PYGZdq{}}\PYG{p}{)}
  Y \PYG{o}{\PYGZlt{}\PYGZhy{}} model.response\PYG{p}{(}D\PYG{p}{)}
  terms \PYG{o}{\PYGZlt{}\PYGZhy{}} attr\PYG{p}{(}D\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{terms\PYGZdq{}}\PYG{p}{)}
  start.val \PYG{o}{\PYGZlt{}\PYGZhy{}} set.start\PYG{p}{(}start.val\PYG{p}{,} terms\PYG{p}{)}
  start.val \PYG{o}{\PYGZlt{}\PYGZhy{}} put.start\PYG{p}{(}start.val\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} terms\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{rho\PYGZdq{}}\PYG{p}{)}

  log.lik \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}par\PYG{p}{,} X\PYG{p}{,} Y\PYG{p}{,} terms\PYG{p}{)} \PYG{p}{\PYGZob{}}
    Beta \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms\PYG{p}{,} eqn \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}         \PYG{c+c1}{\PYGZsh{} [2]}
    gamma \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{rho\PYGZdq{}}\PYG{p}{)}
    rho \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{p}{(}exp\PYG{p}{(}Xrho \PYG{o}{\PYGZpc{}*\PYGZpc{}} gamma\PYG{p}{)} \PYG{o}{\PYGZhy{}} \PYG{l+m}{1}\PYG{p}{)} \PYG{o}{/} \PYG{p}{(}\PYG{l+m}{1} \PYG{o}{+} exp\PYG{p}{(}Xrho \PYG{o}{\PYGZpc{}*\PYGZpc{}} gamma\PYG{p}{)}\PYG{p}{)}
    mu \PYG{o}{\PYGZlt{}\PYGZhy{}} X \PYG{o}{\PYGZpc{}*\PYGZpc{}} Beta                                             \PYG{c+c1}{\PYGZsh{} [3]}
    llik \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+m}{0}
    \PYG{k+kr}{for} \PYG{p}{(}i \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}nrow\PYG{p}{(}mu\PYG{p}{)}\PYG{p}{)}\PYG{p}{\PYGZob{}}
      Sigma \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}c\PYG{p}{(}\PYG{l+m}{1}\PYG{p}{,} rho\PYG{p}{[}i\PYG{p}{,}\PYG{p}{]}\PYG{p}{,} rho\PYG{p}{[}i\PYG{p}{,}\PYG{p}{]}\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{)}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{)}
      \PYG{k+kr}{if} \PYG{p}{(}Y\PYG{p}{[}i\PYG{p}{,}\PYG{l+m}{1}\PYG{p}{]}\PYG{o}{==}\PYG{l+m}{1}\PYG{p}{)}
        \PYG{k+kr}{if} \PYG{p}{(}Y\PYG{p}{[}i\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]}\PYG{o}{==}\PYG{l+m}{1}\PYG{p}{)}
          llik \PYG{o}{\PYGZlt{}\PYGZhy{}} llik \PYG{o}{+} log\PYG{p}{(}pmvnorm\PYG{p}{(}lower \PYG{o}{=} c\PYG{p}{(}\PYG{l+m}{0}\PYG{p}{,} \PYG{l+m}{0}\PYG{p}{)}\PYG{p}{,} upper \PYG{o}{=} c\PYG{p}{(}\PYG{k+kc}{Inf}\PYG{p}{,} \PYG{k+kc}{Inf}\PYG{p}{)}\PYG{p}{,}
                                     mean \PYG{o}{=} mu\PYG{p}{[}i\PYG{p}{,}\PYG{p}{]}\PYG{p}{,} corr \PYG{o}{=} Sigma\PYG{p}{)}\PYG{p}{)}
        \PYG{k+kr}{else}
          llik \PYG{o}{\PYGZlt{}\PYGZhy{}} llik \PYG{o}{+} log\PYG{p}{(}pmvnorm\PYG{p}{(}lower \PYG{o}{=} c\PYG{p}{(}\PYG{l+m}{0}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{k+kc}{Inf}\PYG{p}{)}\PYG{p}{,} upper \PYG{o}{=} c\PYG{p}{(}\PYG{k+kc}{Inf}\PYG{p}{,} \PYG{l+m}{0}\PYG{p}{)}\PYG{p}{,}
                                     mean \PYG{o}{=} mu\PYG{p}{[}i\PYG{p}{,}\PYG{p}{]}\PYG{p}{,} corr \PYG{o}{=} Sigma\PYG{p}{)}\PYG{p}{)}
      \PYG{k+kr}{else}
        \PYG{k+kr}{if} \PYG{p}{(}Y\PYG{p}{[}i\PYG{p}{,}\PYG{l+m}{2}\PYG{p}{]}\PYG{o}{==}\PYG{l+m}{1}\PYG{p}{)}
          llik \PYG{o}{\PYGZlt{}\PYGZhy{}} llik \PYG{o}{+} log\PYG{p}{(}pmvnorm\PYG{p}{(}lower \PYG{o}{=} c\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{k+kc}{Inf}\PYG{p}{,} \PYG{l+m}{0}\PYG{p}{)}\PYG{p}{,} upper \PYG{o}{=} c\PYG{p}{(}\PYG{l+m}{0}\PYG{p}{,} \PYG{k+kc}{Inf}\PYG{p}{)}\PYG{p}{,}
                                     mean \PYG{o}{=} mu\PYG{p}{[}i\PYG{p}{,}\PYG{p}{]}\PYG{p}{,} corr \PYG{o}{=} Sigma\PYG{p}{)}\PYG{p}{)}
        \PYG{k+kr}{else}
          llik \PYG{o}{\PYGZlt{}\PYGZhy{}} llik \PYG{o}{+} log\PYG{p}{(}pmvnorm\PYG{p}{(}lower \PYG{o}{=} c\PYG{p}{(}\PYG{o}{\PYGZhy{}}\PYG{k+kc}{Inf}\PYG{p}{,} \PYG{o}{\PYGZhy{}}\PYG{k+kc}{Inf}\PYG{p}{)}\PYG{p}{,} upper \PYG{o}{=} c\PYG{p}{(}\PYG{l+m}{0}\PYG{p}{,} \PYG{l+m}{0}\PYG{p}{)}\PYG{p}{,}
                                     mean \PYG{o}{=} mu\PYG{p}{[}i\PYG{p}{,}\PYG{p}{]}\PYG{p}{,} corr \PYG{o}{=} Sigma\PYG{p}{)}\PYG{p}{)}
        \PYG{p}{\PYGZcb{}}
    \PYG{k+kr}{return}\PYG{p}{(}llik\PYG{p}{)}
  \PYG{p}{\PYGZcb{}}
  res \PYG{o}{\PYGZlt{}\PYGZhy{}} optim\PYG{p}{(}start.val\PYG{p}{,} log.lik\PYG{p}{,} method \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{BFGS\PYGZdq{}}\PYG{p}{,}
               hessian \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{,} control \PYG{o}{=} list\PYG{p}{(}fnscale \PYG{o}{=} \PYG{l+m}{\PYGZhy{}1}\PYG{p}{)}\PYG{p}{,}
               X \PYG{o}{=} X\PYG{p}{,} Y \PYG{o}{=} Y\PYG{p}{,} terms \PYG{o}{=} terms\PYG{p}{,} \PYG{k+kc}{...}\PYG{p}{)}
  fit \PYG{o}{\PYGZlt{}\PYGZhy{}} model.end\PYG{p}{(}res\PYG{p}{,} D\PYG{p}{)}
  class\PYG{p}{(}fit\PYG{p}{)} \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{bivariate.probit\PYGZdq{}}
  fit
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

If you find that the default (memory-efficient) method isn’t the best
way to run your model, you can use either the intuitive option or the
computationally-efficient option by changing just a few lines of code as
follows:
\begin{itemize}
\item {} 
\textbf{Intuitive option} At Comment {[}1{]}:

\begin{Verbatim}[commandchars=\\\{\}]
X \PYG{o}{\PYGZlt{}\PYGZhy{}} model.matrix\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} D\PYG{p}{,} shape \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{stacked\PYGZdq{}}\PYG{p}{,} eqn \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

and at Comment {[}2{]},

\begin{Verbatim}[commandchars=\\\{\}]
Beta \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms\PYG{p}{,} shape \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{vector\PYGZdq{}}\PYG{p}{,} eqn \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

The line at Comment {[}3{]} remains the same as in the original version.

\item {} 
\textbf{Computationally-efficient option} Replace the line at Comment {[}1{]}
with

\begin{Verbatim}[commandchars=\\\{\}]
X \PYG{o}{\PYGZlt{}\PYGZhy{}} model.matrix\PYG{p}{(}fml\PYG{p}{,} data \PYG{o}{=} D\PYG{p}{,} shape \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{array\PYGZdq{}}\PYG{p}{,} eqn \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

At Comment {[}2{]}:

\begin{Verbatim}[commandchars=\\\{\}]
Beta \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms\PYG{p}{,} shape \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{vector\PYGZdq{}}\PYG{p}{,} eqn \PYG{o}{=} c\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu1\PYGZdq{}}\PYG{p}{,} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
\end{Verbatim}

At Comment {[}3{]}:

\begin{Verbatim}[commandchars=\\\{\}]
mu \PYG{o}{\PYGZlt{}\PYGZhy{}} apply\PYG{p}{(}X\PYG{p}{,} \PYG{l+m}{3}\PYG{p}{,} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{\PYGZpc{}*\PYGZpc{}\PYGZsq{}}\PYG{p}{,} Beta\PYG{p}{)}
\end{Verbatim}

\end{itemize}

Even if your optimizer calls a C or FORTRAN routine, you can use
combinations of model.matrix() and parse.par() to set up the data
structures that you need to obtain the linear predictor (or your model’s
equivalent) before passing these data structures to your optimization
routine.


\subsection{Adding Models and Methods to Zelig}
\label{docs/dev_guide:adding-models-and-methods-to-zelig}\label{docs/dev_guide:devguide-adding-models-and-methods}
Zelig is highly modular. You can add methods to Zelig \emph{and}, if you
wish, release your programs as a stand-alone package. By making your
package compatible with Zelig, you will advertise your package and help
it achieve a widespread distribution.

This chapter assumes that your model is written as a function that takes
a user-defined formula and data set (see Chapter {[}s:new{]}), and returns a
list of output that includes (at the very least) the estimated
parameters and terms that describe the data used to fit the model. You
should choose a class (either S3 or S4 class) for this list of output,
and provide appropriate methods for generic functions such as summary(),
print(), coef() and vcov().

To add new models to Zelig, you need to provide six R functions,
illustrated in Figure {[}add{]}. Let mymodel be a new model with class
“myclass”.

{[}h!{]} {[}add{]}

(160,170)(0,0)

(0,166)Estimate

(70,162)(0,-1)42 (50,162)(40,12)zelig() (70,144)(0,-24)2(1,0)9
(80,138)(83,12)(1) zelig2mymodel() (80,114)(57,12)(2) mymodel()

(0,96)Interpret

(70,92)(0,-1)42 (50,92)(40,12)sim() (70,74)(0,-24)2(1,0)9
(80,68)(83,12)(3) param.myclass() (80,44)(69,12)(4) qi.myclass()

(0,26)Plot

(50,0)(105,12)(6) plot.zelig.mymodel()

These functions are as follows:
\begin{enumerate}
\item {} 
zelig2mymodel() translates zelig() arguments into the arguments for
mymodel().

\item {} 
mymodel() estimates your statistical procedure.

\item {} 
param.myclass() simulates parameters for your model. Alternatively,
if your model’s parameters consist of one vector with a
correspondingly observed variance-covariance matrix, you may write
\emph{two} simple functions to substitute for param.myclass():
\begin{enumerate}
\item {} 
coef.myclass() to extract the coefficients from your model output,
and

\item {} 
vcov.myclass() to extract the variance-covariance matrix from your
model.

\end{enumerate}

\item {} 
qi.myclass() calculates expected values, simulates predicted values,
and generates other quantities of interest for your model (applicable
only to models that take explanatory variables).

\item {} 
plot.zelig.mymodel() to plot the simulated quantities of interest
from your model.

\item {} 
A \textbf{reference manual page} to document the model. (See )

\item {} 
A function (describe.mymodel()) describing the inputs to your model,
for use with a graphical user interface. (See ).

\item {} 
An optional \textbf{demo script} mymodel.R which contains commented code
for the models contained in the example section of your reference
manual page.

\end{enumerate}


\subsubsection{Making the Model Compatible with Zelig}
\label{docs/dev_guide:making-the-model-compatible-with-zelig}
You can develop a model, write the model-fitting function, and test it
within the Zelig framework without explicit intervention from the Zelig
team. (We are, of course, happy to respond to any questions or
suggestions for improvement.)

Zelig’s modularity relies on two R programming conventions:
\begin{enumerate}
\item {} 
\textbf{*wrappers*}, which pass arguments from R functions to other R
functions or to foreign function calls (such as C, C++, or Fortran
functions); and

\item {} 
\textbf{*classes*}, which tell generic functions how to handle objects of
a given class.

\end{enumerate}

Specific methods for R generic functions take the general form:
method.class(), where method is the name of the generic procedure to be
performed and class is the class of the object. You may define, for
example, summary.contrib() to summarize the output of your model. Note
that for S4 classes, the name of generic functions does not have to be
method.class() so long as users can call them via method().

Zelig has implemented a unique method for incorporating new models which
lets contributors test their models \emph{within} the Zelig framework
\emph{without} any modification of the zelig() function itself.

Using a wrapper function zelig2contrib() (where contrib is the name of
your new model), zelig2contrib() redefines the inputs to zelig() to work
with the inputs you need for your function contrib(). For example, if
you type

\begin{Verbatim}[commandchars=\\\{\}]
zelig\PYG{p}{(}\PYG{k+kc}{...}\PYG{p}{,} model \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{normal.regression\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

zelig() looks for a zelig2normal.regression() wrapper in any environment
(either attached libraries or your workspace). If the wrapper exists,
then zelig() runs the model.

If you have a pre-existing model, writing a zelig2contrib() function is
quite easy. Let’s say that your model is contrib(), and takes the
following arguments: formula, data, weights, and start. The zelig()
function, in contrast, only takes the formula, data, model, and by
arguments. You may use the … to pass additional arguments from zelig()
to zelig2contrib(), and \textless{}- NULL to omit the elements you do not need.
Continuing the Normal regression example from , let formula, model, and
data be the inputs to zelig(), M is the number of subsets, and … are the
additional arguments not defined in the zelig() call, but passed to
normal.regression().

\begin{Verbatim}[commandchars=\\\{\}]
zelig2normal.regression \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}formula\PYG{p}{,} model\PYG{p}{,} data\PYG{p}{,} M\PYG{p}{,} \PYG{k+kc}{...}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  mf \PYG{o}{\PYGZlt{}\PYGZhy{}} match.call\PYG{p}{(}expand.dots \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}                     \PYG{c+c1}{\PYGZsh{} [1]}
  mf\PYG{o}{\PYGZdl{}}model \PYG{o}{\PYGZlt{}\PYGZhy{}} mf\PYG{o}{\PYGZdl{}}M \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kc}{NULL}                                 \PYG{c+c1}{\PYGZsh{} [2]}
  mf\PYG{p}{[[}\PYG{l+m}{1}\PYG{p}{]]} \PYG{o}{\PYGZlt{}\PYGZhy{}} as.name\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{normal.regression\PYGZdq{}}\PYG{p}{)}                  \PYG{c+c1}{\PYGZsh{} [3]}
  as.call\PYG{p}{(}mf\PYG{p}{)}                                              \PYG{c+c1}{\PYGZsh{} [4]}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

The bracketed numbers above correspond to the comments below:
\begin{enumerate}
\item {} 
Create a call (an expression to be evaluated) by creating a list of
the arguments in zelig2normal.regression(), including the extra
arguments taken by normal.regression(), but not by zelig(). All
wrappers must take the same standardized arguments (formula, model,
data, and M), which may be used in the wrapper function to manipulate
the zelig() call into the normal.regression() call. Additional
arguments to normal.regression(), such as start.val are passed
implicitly from zelig() using the ... operator.

\item {} 
Erase extraneous information from the call object mf. In this
wrapper, model and M are not used. In other models, these are used to
further manipulate the call, and so are included in the standard
inputs to all wrappers.

\item {} 
Reassign the first element of the call (currently
zelig2normal.regression) with the name of the function to be
evaluated, normal.regression().

\item {} 
Return the call to zelig(), which will evaluate the call for each
multiply-imputed data set, each subset defined in by, or simply data.

\end{enumerate}

If you use an S4 class to represent your model, say mymodel, within
zelig.default(), Zelig’s internal function, create.ZeligS4(),
automatically creates a new S4 class called ZeligS4mymodel in the global
environment with two additional slots. These include zelig, which stores
the name of the model, and zelig.data, which stores the data frame if
save.data=TRUE and is empty otherwise. These names are taken from the
original call. This new output inherits the original class mymodel so
all the generic functions associated with mymodel should still work. If
you would like to see an example, see the models implemented using the
VGAM package, such as multinomial probit.

In the case of setx(), most models will use setx.default(), which in
turn relies on the generic R function model.matrix(). For this procedure
to work, your list of output must include:
\begin{itemize}
\item {} 
terms, created by model.frame(), or manually;

\item {} 
formula, the formula object input by the user;

\item {} 
xlevels, which define the strata in the explanatory variables; and

\item {} 
contrasts, an optional element which defines the type of factor
variables used in the explanatory variables. See help(contrasts) for
more information.

\end{itemize}

If your model output does not work with setx.default(), you must write
your own setx.contrib() function. For example, models fit to
multiply-imputed data sets have output from zelig() of class “MI”. The
special setx.MI() wrapper pre-processes the zelig() output object and
passes the appropriate arguments to setx.default().

Simulating quantities of interest is an integral part of interpreting
model results. To use the functionality built into the Zelig sim()
procedure, you need to provide a way to simulate parameters (called a
param() function), and a method for calculating or drawing quantities of
interest from the simulated parameters (called a qi() function).

Whether you choose to use the default method, or write a model-specific
method for simulating parameters, these functions require the same three
inputs:
\begin{itemize}
\item {} 
object: the estimated model or zelig() output.

\item {} 
num: the number of simulations.

\item {} 
bootstrap: either TRUE or FALSE.

\end{itemize}

The output from param() should be either
\begin{itemize}
\item {} 
If bootstrap = FALSE (default), an matrix with rows corresponding to
simulations and columns corresponding to model parameters. Any
ancillary parameters should be included in the output matrix.

\item {} 
If bootstrap = TRUE, a vector containing all model parameters,
including ancillary parameters.

\end{itemize}

There are two ways to simulate parameters:
\begin{enumerate}
\item {} 
Use the param.default() function to extract parameters from the model
and, if bootstrapping is not selected, simulate coefficients using
asymptotic normal approximation. The param.default() function relies
on two R functions:
\begin{enumerate}
\item {} 
coef(): extracts the coefficients. Continuing the Normal
regression example from above, the appropriate coef.normal()
function is simply:

\begin{Verbatim}[commandchars=\\\{\}]
coef.normal \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}object\PYG{p}{)}
  object\PYG{o}{\PYGZdl{}}coefficients
\end{Verbatim}

\item {} 
vcov(): extracts the variance-covariance matrix. Again continuing
the Poisson example from above:

\begin{Verbatim}[commandchars=\\\{\}]
vcov.normal \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}object\PYG{p}{)}
  object\PYG{o}{\PYGZdl{}}variance
\end{Verbatim}

\end{enumerate}

\item {} 
Alternatively, you can write your own param.contrib() function. This
is appropriate when:
\begin{enumerate}
\item {} 
Your model has auxiliary parameters, such as  in the
case of the Normal distribution.

\item {} 
Your model performs some sort of correction to the coefficients or
the variance-covariance matrix, which cannot be performed in
either the coef.contrib() or the vcov.contrib() functions.

\item {} 
Your model does not rely on asymptotic approximation to the
log-likelihood. For Bayesian Markov-chain monte carlo models, for
example, the param.contrib() function (param.MCMCzelig() in this
case) simply extracts the model parameters simulated in the
model-fitting function.

\end{enumerate}

Continuing the Normal example,

\begin{Verbatim}[commandchars=\\\{\}]
param.normal \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}object\PYG{p}{,} num \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{,} bootstrap \PYG{o}{=} \PYG{k+kc}{FALSE}\PYG{p}{,}
                   terms \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  \PYG{k+kr}{if} \PYG{p}{(}\PYG{o}{!}bootstrap\PYG{p}{)} \PYG{p}{\PYGZob{}}
    par \PYG{o}{\PYGZlt{}\PYGZhy{}} mvrnorm\PYG{p}{(}num\PYG{p}{,} mu \PYG{o}{=} coef\PYG{p}{(}object\PYG{p}{)}\PYG{p}{,} Sigma \PYG{o}{=} vcov\PYG{p}{(}object\PYG{p}{)}\PYG{p}{)}
    Beta \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms \PYG{o}{=} terms\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu\PYGZdq{}}\PYG{p}{)}
    sigma2 \PYG{o}{\PYGZlt{}\PYGZhy{}} exp\PYG{p}{(}parse.par\PYG{p}{(}par\PYG{p}{,} terms \PYG{o}{=} terms\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{sigma2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
    res \PYG{o}{\PYGZlt{}\PYGZhy{}} cbind\PYG{p}{(}Beta\PYG{p}{,} sigma2\PYG{p}{)}
  \PYG{p}{\PYGZcb{}}
  \PYG{k+kr}{else} \PYG{p}{\PYGZob{}}
    par \PYG{o}{\PYGZlt{}\PYGZhy{}} coef\PYG{p}{(}object\PYG{p}{)}
    Beta \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} terms \PYG{o}{=} terms\PYG{p}{,}  eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu\PYGZdq{}}\PYG{p}{)}
    sigma2 \PYG{o}{\PYGZlt{}\PYGZhy{}} exp\PYG{p}{(}parse.par\PYG{p}{(}par\PYG{p}{,} terms \PYG{o}{=} terms\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{sigma2\PYGZdq{}}\PYG{p}{)}\PYG{p}{)}
    res \PYG{o}{\PYGZlt{}\PYGZhy{}} c\PYG{p}{(}coef\PYG{p}{,} sigma2\PYG{p}{)}
  \PYG{p}{\PYGZcb{}}
  res
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

\end{enumerate}

All models require a model-specific method for calculating quantities of
interest from the simulated parameters. For a model of class contrib,
the appropriate qi() function is qi.contrib(). This function should
calculate, at the bare minimum, the following quantities of interest:
\begin{itemize}
\item {} 
ev: the expected values, calculated from the analytic solution for
the expected value as a function of the systematic component and
ancillary parameters.

\item {} 
pr: the predicted values, drawn from a distribution defined by the
predicted values. If R does not have a built-in random generator for
your function, you may take a random draw from the uniform
distribution and use the inverse CDF method to calculate predicted
values.

\item {} 
fd: first differences in the expected value, calculated by
subtracting the expected values given the specified x from the
expected values given x1.

\item {} 
ate.ev: the average treatment effect calculated using the expected
values ev. This is simply y - ev, averaged across simulations for
each observation.

\item {} 
ate.pr: the average treatment effect calculated using the predicted
values pr. This is simply y - pr, averaged across simulations for
each observation.

\end{itemize}

The required arguments for the qi() function are:
\begin{itemize}
\item {} 
object: the zelig output object.

\item {} 
par: the simulated parameters.

\item {} 
x: the matrix of explanatory variables (created using setx()).

\item {} 
x1: the optional matrix of alternative values for first differences
(also created using setx()). If first differences are inappropriate
for your model, you should put in a warning() or stop() if x1 is not
NULL.

\item {} 
y: the optional vector or matrix of dependent variables (for
calculating average treatment effects). If average treatment effects
are inappropriate for your model, you should put in a warning() or
stop() if conditional prediction has been selected in the setx()
step.

\end{itemize}

Continuing the Normal regression example from above, the appropriate
qi.normal() function is as follows:

\begin{Verbatim}[commandchars=\\\{\}]
qi.normal \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{k+kr}{function}\PYG{p}{(}object\PYG{p}{,} par\PYG{p}{,} x\PYG{p}{,} x1 \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{,} y \PYG{o}{=} \PYG{k+kc}{NULL}\PYG{p}{)} \PYG{p}{\PYGZob{}}
  Beta \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mu\PYGZdq{}}\PYG{p}{)}                        \PYG{c+c1}{\PYGZsh{} [1]}
  sigma2 \PYG{o}{\PYGZlt{}\PYGZhy{}} parse.par\PYG{p}{(}par\PYG{p}{,} eqn \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{sigma2\PYGZdq{}}\PYG{p}{)}                  \PYG{c+c1}{\PYGZsh{} [2]}
  ev \PYG{o}{\PYGZlt{}\PYGZhy{}} Beta \PYG{o}{\PYGZpc{}*\PYGZpc{}} t\PYG{p}{(}x\PYG{p}{)}                                       \PYG{c+c1}{\PYGZsh{} [3a]}
  pr \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}\PYG{k+kc}{NA}\PYG{p}{,} ncol \PYG{o}{=} ncol\PYG{p}{(}ev\PYG{p}{)}\PYG{p}{,} nrow \PYG{o}{=} nrow\PYG{p}{(}ev\PYG{p}{)}\PYG{p}{)}
  \PYG{k+kr}{for} \PYG{p}{(}i \PYG{k+kr}{in} \PYG{l+m}{1}\PYG{o}{:}ncol\PYG{p}{(}ev\PYG{p}{)}\PYG{p}{)}
    pr\PYG{p}{[}\PYG{p}{,}i\PYG{p}{]} \PYG{o}{\PYGZlt{}\PYGZhy{}} rnorm\PYG{p}{(}length\PYG{p}{(}ev\PYG{p}{[}\PYG{p}{,}i\PYG{p}{]}\PYG{p}{)}\PYG{p}{,} mean \PYG{o}{=} ev\PYG{p}{[}\PYG{p}{,}i\PYG{p}{]}\PYG{p}{,}          \PYG{c+c1}{\PYGZsh{} [4]}
                    sigma \PYG{o}{=} sd\PYG{p}{(}sigma2\PYG{p}{[}i\PYG{p}{]}\PYG{p}{)}\PYG{p}{)}
  qi \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}ev \PYG{o}{=} ev\PYG{p}{,} pr \PYG{o}{=} pr\PYG{p}{)}
  qi.name \PYG{o}{\PYGZlt{}\PYGZhy{}} list\PYG{p}{(}ev \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Expected Values: E(Y\textbar{}X)\PYGZdq{}}\PYG{p}{,}
                  pr \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Predicted Values: Y\textbar{}X\PYGZdq{}}\PYG{p}{)}
  \PYG{k+kr}{if} \PYG{p}{(}\PYG{o}{!}is.null\PYG{p}{(}x1\PYG{p}{)}\PYG{p}{)}\PYG{p}{\PYGZob{}}
    ev1 \PYG{o}{\PYGZlt{}\PYGZhy{}} par \PYG{o}{\PYGZpc{}*\PYGZpc{}} t\PYG{p}{(}x1\PYG{p}{)}                                    \PYG{c+c1}{\PYGZsh{} [3b]}
    qi\PYG{o}{\PYGZdl{}}fd \PYG{o}{\PYGZlt{}\PYGZhy{}} ev1 \PYG{o}{\PYGZhy{}} ev
    qi.name\PYG{o}{\PYGZdl{}}fd \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{First Differences in Expected Values: E(Y\textbar{}X1)\PYGZhy{}E(Y\textbar{}X)\PYGZdq{}}
  \PYG{p}{\PYGZcb{}}
  \PYG{k+kr}{if} \PYG{p}{(}\PYG{o}{!}is.null\PYG{p}{(}y\PYG{p}{)}\PYG{p}{)} \PYG{p}{\PYGZob{}}
    yvar \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}rep\PYG{p}{(}y\PYG{p}{,} nrow\PYG{p}{(}par\PYG{p}{)}\PYG{p}{)}\PYG{p}{,} nrow \PYG{o}{=} nrow\PYG{p}{(}par\PYG{p}{)}\PYG{p}{,} byrow \PYG{o}{=} \PYG{k+kc}{TRUE}\PYG{p}{)}
    tmp.ev \PYG{o}{\PYGZlt{}\PYGZhy{}} yvar \PYG{o}{\PYGZhy{}} qi\PYG{o}{\PYGZdl{}}ev
    tmp.pr \PYG{o}{\PYGZlt{}\PYGZhy{}} yvar \PYG{o}{\PYGZhy{}} qi\PYG{o}{\PYGZdl{}}pr
    qi\PYG{o}{\PYGZdl{}}ate.ev \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}apply\PYG{p}{(}tmp.ev\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} mean\PYG{p}{)}\PYG{p}{,} nrow \PYG{o}{=} nrow\PYG{p}{(}par\PYG{p}{)}\PYG{p}{)}
    qi\PYG{o}{\PYGZdl{}}ate.pr \PYG{o}{\PYGZlt{}\PYGZhy{}} matrix\PYG{p}{(}apply\PYG{p}{(}tmp.pr\PYG{p}{,} \PYG{l+m}{1}\PYG{p}{,} mean\PYG{p}{)}\PYG{p}{,} nrow \PYG{o}{=} nrow\PYG{p}{(}par\PYG{p}{)}\PYG{p}{)}
    qi.name\PYG{o}{\PYGZdl{}}ate.ev \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Average Treatment Effect: Y \PYGZhy{} EV\PYGZdq{}}
    qi.name\PYG{o}{\PYGZdl{}}ate.pr \PYG{o}{\PYGZlt{}\PYGZhy{}} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Average Treatment Effect: Y \PYGZhy{} PR\PYGZdq{}}
  \PYG{p}{\PYGZcb{}}
  list\PYG{p}{(}qi\PYG{o}{=}qi\PYG{p}{,} qi.name\PYG{o}{=}qi.name\PYG{p}{)}
\PYG{p}{\PYGZcb{}}
\end{Verbatim}

There are five lines of code commented above. By changing these five
lines in the following \emph{four} ways, you can write qi() function
appropriate to almost any model:
\begin{enumerate}
\item {} 
Extract any systematic parameters by substituting the name of your
systematic parameter (defined in describe.mymodel()).

\item {} 
Extract any ancillary parameters (defined in describe.mymodel()) by
substituting their names here.

\item {} 
Calculate the expected value using the inverse link function and
. (For the normal model, this is linear.) You
will need to make this change in two places, at Comment {[}3a{]} and
{[}3b{]}.

\item {} 
Replace rnorm() with a function that takes random draws from the
stochastic component of your model.

\end{enumerate}


\subsubsection{Getting Ready for the GUI}
\label{docs/dev_guide:getting-ready-for-the-gui}
Zelig can work with a variety of graphical user interfaces (GUIs). GUIs
work by knowing \emph{a priori} what a particular model accepts, and
presenting only those options to the user in some sort of graphical
interface. Thus, in order for your model to work with a GUI, you must
describe your model in terms that the GUI can understand. For models
written using the guidelines in Chapter {[}s:new{]}, your model will be
compatible with (at least) the GUI. For pre-existing models, you will
need to create a describe.*() function for your model following the
examples in .


\subsubsection{Formatting Reference Manual Pages}
\label{docs/dev_guide:formatting-reference-manual-pages}
One of the primary advantages of Zelig is that it fully documents the
included models, in contrast to the programming-orientation of R
documentation which is organized by function. Thus, we ask that Zelig
contributors provide similar documentation, including the syntax and
arguments passed to zelig(), the systematic and stochastic components to
the model, the quantities of interest, the output values, and further
information (including references). There are several ways to provide
this information:
\begin{itemize}
\item {} 
If you have an existing package documented using the .Rd help format,
help.zelig() will automatically search R-help in addition to Zelig
help.

\item {} 
If you have an existing package documented using on-line HTML files
with static URLs (like Zelig or MatchIt), you need to provide a
PACKAGE.url.tab file which is a two-column table containing the name
of the function in the first column and the url in the second. (Even
though the file extension is .url.tab, the file should be a tab- or
space-delimited text file.) For example:

\begin{Verbatim}[commandchars=\\\{\}]
command       http\PYG{o}{:}\PYG{o}{/}\PYG{o}{/}gking.harvard.edu\PYG{o}{/}zelig\PYG{o}{/}docs\PYG{o}{/}Main\PYGZus{}Commands.html
model         http\PYG{o}{:}\PYG{o}{/}\PYG{o}{/}gking.harvard.edu\PYG{o}{/}zelig\PYG{o}{/}docs\PYG{o}{/}Specific\PYGZus{}Models.html
\end{Verbatim}

If you wish to test to see if your .url.tab files works, simply place
it in your R library/Zelig/data/ directory. (You do not need to
reinstall Zelig to test your .url.tab file.)

\item {} 
Preferred method: You may provide a  .tex file. This document uses
the book style and supports commands from the following packages:
graphicx, natbib, amsmath, amssymb, verbatim, epsf, and html. Because
model pages are incorporated into this document using
include\{\}, you should make sure that your
document compiles before submitting it. Please adhere to the
following conventions for your model page:
\begin{enumerate}
\item {} 
All mathematical formula should be typeset using the equation*
and array, eqnarray*, or align environments. Please avoid
displaymath. (It looks funny in html.)

\item {} 
All commands or R objects should use the texttt environment.

\item {} 
The model begins as a subsection of a larger document, and
sections within the model page are of sub-subsection level.

\item {} 
For stylistic consistency, please avoid using the description
environment.

\end{enumerate}

Each LaTeX model page should include the following elements. Let
contrib specify the new model.

\begin{Verbatim}[commandchars=\\\{\}]
\PYGZbs{}subsection\PYG{p}{\PYGZob{}}\PYG{p}{\PYGZob{}}\PYGZbs{}tt contrib\PYG{p}{\PYGZcb{}}\PYG{o}{:} Full Name \PYG{k+kr}{for} \PYG{p}{[}type\PYG{p}{]} Dependent Variables\PYG{p}{\PYGZcb{}}
\PYGZbs{}label\PYG{p}{\PYGZob{}}contrib\PYG{p}{\PYGZcb{}}

\PYGZbs{}subsubsection\PYG{p}{\PYGZob{}}Syntax\PYG{p}{\PYGZcb{}}

\PYGZbs{}subsubsection\PYG{p}{\PYGZob{}}Examples\PYG{p}{\PYGZcb{}}
\PYGZbs{}begin\PYG{p}{\PYGZob{}}enumerate\PYG{p}{\PYGZcb{}}
\PYGZbs{}item First Example
\PYGZbs{}item Second Example
\PYGZbs{}end\PYG{p}{\PYGZob{}}enumerate\PYG{p}{\PYGZcb{}}

\PYGZbs{}subsubsection\PYG{p}{\PYGZob{}}Model\PYG{p}{\PYGZcb{}}
\PYGZbs{}begin\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
\PYGZbs{}item The observation mechanism\PYG{p}{,} \PYG{k+kr}{if} applicable.
\PYGZbs{}item The stochastic component.
\PYGZbs{}item The systematic component.
\PYGZbs{}end\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}

\PYGZbs{}subsubsection\PYG{p}{\PYGZob{}}Quantities of Interest\PYG{p}{\PYGZcb{}}
\PYGZbs{}begin\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
\PYGZbs{}item The expected value of your distribution\PYG{p}{,} including the formula
  \PYG{k+kr}{for} the expected value as a \PYG{k+kr}{function} of the systemic component and
  ancillary paramters.
\PYGZbs{}item The predicted value drawn from the distribution defined by the
       corresponding expected value.
\PYGZbs{}item The first difference \PYG{k+kr}{in} expected values\PYG{p}{,} given when x1 is specified.
\PYGZbs{}item Other quantities of interest.
\PYGZbs{}end\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}

\PYGZbs{}subsubsection\PYG{p}{\PYGZob{}}Output Values\PYG{p}{\PYGZcb{}}
\PYGZbs{}begin\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
\PYGZbs{}item From the \PYG{p}{\PYGZob{}}\PYGZbs{}tt zelig\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}} output stored \PYG{k+kr}{in} \PYG{p}{\PYGZob{}}\PYGZbs{}tt z.out\PYG{p}{\PYGZcb{}}\PYG{p}{,} you may
  extract\PYG{o}{:}
   \PYGZbs{}begin\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
   \PYGZbs{}item
   \PYGZbs{}item
   \PYGZbs{}end\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
\PYGZbs{}item From \PYG{p}{\PYGZob{}}\PYGZbs{}tt summary\PYG{p}{(}z.out\PYG{p}{)}\PYG{p}{\PYGZcb{}}\PYG{p}{,} you may extract\PYG{o}{:}
   \PYGZbs{}begin\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
   \PYGZbs{}item
   \PYGZbs{}item
   \PYGZbs{}end\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
\PYGZbs{}item From the \PYG{p}{\PYGZob{}}\PYGZbs{}tt sim\PYG{p}{(}\PYG{p}{)}\PYG{p}{\PYGZcb{}} output stored \PYG{k+kr}{in} \PYG{p}{\PYGZob{}}\PYGZbs{}tt s.out\PYG{p}{\PYGZcb{}}\PYG{o}{:}
   \PYGZbs{}begin\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
   \PYGZbs{}item
   \PYGZbs{}item
   \PYGZbs{}end\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}
\PYGZbs{}end\PYG{p}{\PYGZob{}}itemize\PYG{p}{\PYGZcb{}}

\PYGZbs{}subsubsection\PYG{p}{\PYGZob{}}Further Information\PYG{p}{\PYGZcb{}}

\PYGZbs{}subsubsection\PYG{p}{\PYGZob{}}Contributors\PYG{p}{\PYGZcb{}}
\end{Verbatim}

\end{itemize}


\section{Contributing}
\label{docs/contributing:contributing}\label{docs/contributing::doc}
Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?


\section{Frequently Asked Questions}
\label{docs/faq:faq}\label{docs/faq::doc}\label{docs/faq:frequently-asked-questions}\setbox0\vbox{
\begin{minipage}{0.95\linewidth}
\begin{itemize}
\item {} 
{\hyperref[docs/faq:for-all-zelig-users]{For All Zelig Users}}
\begin{itemize}
\item {} 
{\hyperref[docs/faq:how-do-i-cite-zelig]{How do I cite Zelig?}}

\item {} 
{\hyperref[docs/faq:why-cant-i-install-zelig]{Why can’t I install Zelig?}}

\item {} 
{\hyperref[docs/faq:why-cant-i-install-r]{Why can’t I install R?}}

\item {} 
{\hyperref[docs/faq:why-cant-i-load-data]{Why can’t I load data?}}

\item {} 
{\hyperref[docs/faq:where-can-i-find-old-versions-of-zelig]{Where can I find old versions of Zelig?}}

\item {} 
{\hyperref[docs/faq:some-zelig-functions-dont-work-for-me]{Some Zelig functions don’t work for me!}}

\item {} 
{\hyperref[docs/faq:who-can-i-ask-for-help-how-do-i-report-bugs]{Who can I ask for help? How do I report bugs?}}

\item {} 
{\hyperref[docs/faq:how-do-i-increase-the-memory-for-r]{How do I increase the memory for R?}}

\item {} 
{\hyperref[docs/faq:why-doesnt-the-pdf-print-properly]{Why doesn’t the pdf print properly?}}

\item {} 
{\hyperref[docs/faq:r-is-neat-how-can-i-find-out-more]{R is neat. How can I find out more?}}

\end{itemize}

\item {} 
{\hyperref[docs/faq:for-zelig-contributors]{For Zelig Contributors}}
\begin{itemize}
\item {} 
{\hyperref[docs/faq:where-can-i-find-the-source-code-for-zelig]{Where can I find the source code for Zelig?}}

\item {} 
{\hyperref[docs/faq:how-can-i-make-my-r-programs-run-faster]{How can I make my R programs run faster?}}

\item {} 
{\hyperref[docs/faq:which-compilers-can-i-use-with-r-and-zelig]{Which compilers can I use with R and Zelig?}}

\end{itemize}

\end{itemize}
\end{minipage}}
\begin{center}\setlength{\fboxsep}{5pt}\shadowbox{\box0}\end{center}


\subsection{For All Zelig Users}
\label{docs/faq:for-all-zelig-users}

\subsubsection{How do I cite Zelig?}
\label{docs/faq:how-do-i-cite-zelig}
We would appreciate if you would cite Zelig as:
\begin{quote}

Imai, Kosuke, Gary King and Olivia Lau. 2006. “Zelig: Everyone’s
Statistical Software,” \href{http://GKing.Harvard.Edu/zelig}{http://GKing.Harvard.Edu/zelig}.
\end{quote}

Please also cite the contributors for the models or methods you are
using. These citations can be found in the contributors section of each
model or command page.


\subsubsection{Why can’t I install Zelig?}
\label{docs/faq:why-cant-i-install-zelig}
You must be connected to the internet to install packages from web
depositories. In addition, there are a few platform-specific reasons why
you may have installation problems:
\begin{itemize}
\item {} 
\textbf{On Windows}: If you are using the very latest version of R, you
may not be able to install Zelig until we update Zelig to work on the
latest release of R. If you wish to install Zelig in the interim,
check the Zelig release notes () and download the appropriate version
of R to work with the last release of Zelig. You may have to manually
download and install Zelig.

\item {} 
\textbf{On Mac}: If the latest version of Zelig is not yet available at
CRAN but you would like to install it on your Mac, try typing the
following at your R prompt:

\begin{Verbatim}[commandchars=\\\{\}]
install.packages\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{Zelig\PYGZdq{}}\PYG{p}{,} repos \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{http://gking.harvard.edu\PYGZdq{}}\PYG{p}{,} type \PYG{o}{=} \PYG{l+s}{\PYGZdq{}}\PYG{l+s}{source\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

\item {} 
\textbf{On Mac or Linux systems}: If you get the following warning message
at the end of your installation:

\begin{Verbatim}[commandchars=\\\{\}]
Installation of package VGAM had non\PYG{o}{\PYGZhy{}}zero exit status \PYG{k+kr}{in} \PYG{k+kc}{...}
\end{Verbatim}

this means that you were not able to install VGAM properly. Make sure
that you have the g77 Fortran compiler. For PowerPC Macs, download
g77 from ). For Intel Macs, download the Apple developer tools. After
installation, try to install Zelig again.

\end{itemize}


\subsubsection{Why can’t I install R?}
\label{docs/faq:why-cant-i-install-r}
If you have problems installing R (rather than Zelig), you should check
the for your platform. If you still have problems, you can search the
for the R help mailing list, or email the list directly at .


\subsubsection{Why can’t I load data?}
\label{docs/faq:why-cant-i-load-data}
When you start R, you need to specify your working directory. In linux
R, this is done pretty much automatically when you start R, whether
within ESS or in a terminal window. In Windows R, you may wish to
specify a working directory so that you may load data without typing in
long directory paths to your data files, and it is important to remember
that \emph{Windows} R uses the \emph{Linux} directory delimiter. That is, if you
right click and select the “Properties” link on a Windows file, the
slashes are backslashes (), but Windows R uses forward
slashes (/) in directory paths. Thus, the Windows link may be
C:Program
FilesR,
but you would type C:/Program Files/R// in Windows R.

When you start R in Windows, the working directory is by default the
directory in which the R executible is located.

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{c+c1}{\PYGZsh{} Print your current working directory.}
\PYG{o}{\PYGZgt{}} getwd\PYG{p}{(}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} To read data not located in your working directory.}
\PYG{o}{\PYGZgt{}} data \PYG{o}{\PYGZlt{}\PYGZhy{}} read.table\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{C:/Program Files/R/newwork/mydata.tab\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} To change your working directory.}
\PYG{o}{\PYGZgt{}} setwd\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{C:/Program Files/R/newwork\PYGZdq{}}\PYG{p}{)}

\PYG{c+c1}{\PYGZsh{} Reading data in your working directory.}
\PYG{o}{\PYGZgt{}} data \PYG{o}{\PYGZlt{}\PYGZhy{}} read.data\PYG{p}{(}\PYG{l+s}{\PYGZdq{}}\PYG{l+s}{mydata.tab\PYGZdq{}}\PYG{p}{)}
\end{Verbatim}

Once you have set the working directory, you no longer need to type the
entire directory path.


\subsubsection{Where can I find old versions of Zelig?}
\label{docs/faq:where-can-i-find-old-versions-of-zelig}
For some replications, you may require older versions of Zelig.
\begin{itemize}
\item {} 
\textbf{Windows} users may find old binaries at
\href{http://gking.harvard.edu/bin/windows/contrib/}{http://gking.harvard.edu/bin/windows/contrib/} and selecting the
appropriate version of R.

\item {} 
\textbf{Linux} and \textbf{MacOSX} users may find source files at
\href{http://gking.harvard.edu/src/contrib/}{http://gking.harvard.edu/src/contrib/}

\end{itemize}

If you want an older version of Zelig because you are using an older
version of R, we strongly suggest that you update R and install the
latest version of Zelig.


\subsubsection{Some Zelig functions don’t work for me!}
\label{docs/faq:some-zelig-functions-dont-work-for-me}
If this is a new phenomenon, there may be functions in your namespace
that are overwriting Zelig functions. In particular, if you have a
function called zelig, setx, or sim in your workspace, the corresponding
functions in Zelig will not work. Rather than deleting things that you
need, R will tell you the following when you load the Zelig library:

\begin{Verbatim}[commandchars=\\\{\}]
Attaching package\PYG{o}{:} \PYG{l+s}{\PYGZsq{}}\PYG{l+s}{Zelig\PYGZsq{}}
        The following object\PYG{p}{(}s\PYG{p}{)} are masked \PYGZus{}by\PYGZus{} .GlobalEnv \PYG{o}{:}
         sim
\end{Verbatim}

In this case, simply rename your sim function to something else and load
Zelig again:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} mysim \PYG{o}{\PYGZlt{}\PYGZhy{}} sim
\PYG{o}{\PYGZgt{}} detach\PYG{p}{(}package\PYG{o}{:}Zelig\PYG{p}{)}
\PYG{o}{\PYGZgt{}} library\PYG{p}{(}Zelig\PYG{p}{)}
\end{Verbatim}


\subsubsection{Who can I ask for help? How do I report bugs?}
\label{docs/faq:who-can-i-ask-for-help-how-do-i-report-bugs}
If you find a bug, or cannot figure something out, please follow these
steps: (1) Reread the relevant section of . (2) if you don’t have the
current version. (3) Rerun the same code and see if the bug has been
fixed. (4) Check our list of . (5) to find a discussion of your issue on
the zelig listserv.

If none of these work, then if you haven’t already, please (6) and (7)
send your question to the listserv at \code{zelig@lists.gking.harvard.edu}.
Please explain exactly what you did and include the full error message,
including the traceback(). You should get an answer from the developers
or another user in short order.


\subsubsection{How do I increase the memory for R?}
\label{docs/faq:how-do-i-increase-the-memory-for-r}
Windows users may get the error that R has run out of memory.

If you have R already installed and subsequently install more RAM, you
may have to reinstall R in order to take advantage of the additional
capacity.

You may also set the amount of available memory manually. Close R, then
right-click on your R program icon (the icon on your desktop or in your
programs directory). Select “Properties”, and then select the “Shortcut”
tab. Look for the “Target” field and after the closing quotes around the
location of the R executible, add

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}max\PYG{o}{\PYGZhy{}}mem\PYG{o}{\PYGZhy{}}size\PYG{o}{=}\PYG{l+m}{500}M
\end{Verbatim}

as shown in the figure below. You may increase this value up to 2GB or
the maximum amount of physical RAM you have installed.

\includegraphics{docs/figs/increase}

If you get the error that R cannot allocate a vector of length x, close
out of R and add the following line to the “Target” field:

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZhy{}}\PYG{o}{\PYGZhy{}}max\PYG{o}{\PYGZhy{}}vsize\PYG{o}{=}\PYG{l+m}{500}M
\end{Verbatim}

or as appropriate.

You can always check to see how much memory R has available by typing at
the R prompt

\begin{Verbatim}[commandchars=\\\{\}]
\PYG{o}{\PYGZgt{}} round\PYG{p}{(}memory.limit\PYG{p}{(}\PYG{p}{)}\PYG{o}{/}\PYG{l+m}{2}\PYG{o}{\PYGZca{}}\PYG{l+m}{20}\PYG{p}{,} \PYG{l+m}{2}\PYG{p}{)}
\end{Verbatim}

which gives you the amount of available memory in MB.


\subsubsection{Why doesn’t the pdf print properly?}
\label{docs/faq:why-doesnt-the-pdf-print-properly}
Zelig uses several special LaTeX environments. If the pdf looks right on
the screen, there are two possible reasons why it’s not printing
properly:
\begin{itemize}
\item {} 
Adobe Acrobat isn’t cleaning up the document. Updating to Acrobat
Reader 6.0.1 or higher should solve this problem.

\item {} 
Your printer doesn’t support PostScript Type 3 fonts. Updating your
print driver should take care of this problem.

\end{itemize}


\subsubsection{R is neat. How can I find out more?}
\label{docs/faq:r-is-neat-how-can-i-find-out-more}
R is a collective project with contributors from all over the world.
Their website () has more information on the R project, R packages,
conferences, and other learning material.

In addition, there are several canonical references which you may wish
to peruse:
\begin{quote}

\begin{DUlineblock}{0em}
\item[] Venables, W.N. and B.D. Ripley. 2002. {\color{red}\bfseries{}*}Modern Applied Statistics
\end{DUlineblock}

with S.* 4th Ed. Springer-Verlag.
\textbar{} Venables, W.N. and B.D. Ripley. 2000. \emph{S Programming.}
Springer-Verlag.
\end{quote}


\subsection{For Zelig Contributors}
\label{docs/faq:for-zelig-contributors}

\subsubsection{Where can I find the source code for Zelig?}
\label{docs/faq:where-can-i-find-the-source-code-for-zelig}
Zelig is distributed under the . After installation, the source code is
located in your R library directory. For Linux users who have followed
our installation example, this is \textasciitilde{}/.R/library/Zelig/. For Windows users
under R , this is by default C:Program
FilesRlibraryZelig.
For Macintosh users, this is \textasciitilde{}/Library/R/library/Zelig/.

In addition, you may download the latest Zelig source code as a
tarball’ed directory from . (This makes it easier to distinguish
functions which are run together during installation.)


\subsubsection{How can I make my R programs run faster?}
\label{docs/faq:how-can-i-make-my-r-programs-run-faster}
Unlike most commercial statistics programs which rely on precompiled and
pre-packaged routines, R allows users to program functions and run them
in the same environment. If you notice a perceptible lag when running
your R code, you may improve the performance of your programs by taking
the following steps:
\begin{itemize}
\item {} 
Reduce the number of loops. If it is absolutely necessary to run
loops in loops, the inside loop should have the most number of cycles
because it runs faster than the outside loop. Frequently, you can
eliminate loops by using vectors rather than scalars. Most R
functions deal with vectors in an efficient and mathematically
intuitive manner.

\item {} 
Do away with loops altogether. You can vectorize functions using the
apply, mapply(), sapply(), lapply(), and replicate() functions. If
you specify the function passed to the above apply() functions
properly, the R consensus is that they should run significantly
faster than loops in general.

\item {} 
You can compile your code using C or Fortran. R is not compiled, but
can use bits of precompiled code in C or Fortran, and calls that code
seamlessly from within R wrapper functions (which pass input from the
R function to the C code and back to R). Thus, almost every
regression package includes C or Fortran algorithms, which are
locally compiled in the case of Linux systems or precompiled in the
case of Windows distributions. The recommended Linux compilers are
gcc for C and g77 for Fortran, so you should make sure that your code
is compatible with those standards to achieve the widest possible
distribution.

\end{itemize}


\subsubsection{Which compilers can I use with R and Zelig?}
\label{docs/faq:which-compilers-can-i-use-with-r-and-zelig}
In general, the C or Fortran algorithms in your package should compile
for any platform. While Windows R packages are distributed as compiled
binaries, Linux R compiles packages locally during installation. Thus,
to ensure the widest possible audience for your package, you should make
sure that your code will compile on gcc (for C and C++), or on g77 (for
Fortran).


\section{Release Notes}
\label{docs/release_notes:release-notes}\label{docs/release_notes::doc}\label{docs/release_notes:id1}

\subsection{v 5.0 (Jul 2014)}
\label{docs/release_notes:v-5-0-jul-2014}
Sed ut perspiciatis unde omnis iste natus error sit voluptatem accusantium doloremque laudantium, totam rem aperiam, eaque ipsa quae ab illo inventore veritatis et quasi architecto beatae vitae dicta sunt explicabo. Nemo enim ipsam voluptatem quia voluptas sit aspernatur aut odit aut fugit, sed quia consequuntur magni dolores eos qui ratione voluptatem sequi nesciunt. Neque porro quisquam est, qui dolorem ipsum quia dolor sit amet, consectetur, adipisci velit, sed quia non numquam eius modi tempora incidunt ut labore et dolore magnam aliquam quaerat voluptatem. Ut enim ad minima veniam, quis nostrum exercitationem ullam corporis suscipit laboriosam, nisi ut aliquid ex ea commodi consequatur? Quis autem vel eum iure reprehenderit qui in ea voluptate velit esse quam nihil molestiae consequatur, vel illum qui dolorem eum fugiat quo voluptas nulla pariatur?


\chapter{Technical Vision}
\label{index:technicalvision}\label{index:technical-vision}
Zelig adds considerable infrastructure to improve the use of existing
methods. It generalizes the program Clarify (for Stata), which
translates hard-to-interpret coefficients into quantities of interest;
combines multiply imputed data sets (such as output from Amelia) to
deal with missing data; automates bootstrapping for all models; uses
sophisticated nonparametric matching commands which improve parametric
procedures (via MatchIt); allows one-line commands to run analyses in
all designated strata; automates the creation of replication data
files so that you (or, if you wish, anyone else) can replicate the
results of your analyses (hence satisfying the replication standard);
makes it easy to evaluate counterfactuals (via WhatIf); and allows
conditional population and superpopulation inferences. Zelig includes
many specific methods, based on likelihood, frequentist, Bayesian,
robust Bayesian, and nonparametric theories of inference.  Developers
make their R packages usable from Zelig by writing a few simple bridge
functions.


\chapter{Contact}
\label{index:contact}\label{index:id1}
For questions, please join the Zelig mailing list:
\href{https://groups.google.com/forum/\#!forum/zelig-statistical-software}{https://groups.google.com/forum/\#!forum/zelig-statistical-software}


\chapter{License}
\label{index:license}
GPL-2 \textbar{} GPL-3 {[}expanded from: GPL (≥ 2){]}



\renewcommand{\indexname}{Index}
\printindex
\end{document}
